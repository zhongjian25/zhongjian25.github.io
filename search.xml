<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[supervisor]]></title>
    <url>%2Fsupervisor.html</url>
    <content type="text"><![CDATA[参考资料http://liyangliang.me/posts/2015/06/using-supervisor/https://www.jianshu.com/p/0b9054b33db3 一、supervisor简介 Supervisor是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用 supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。 Supervisor能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。 二、安装Supervisor 可以运行在 Linux、Mac OS X 上。如前所述，supervisor 是 1、Python 编写的，所以安装起来也很方便，可以直接用 pip :1sudo pip install supervisor 2、配置好yum源后，可以直接安装1yum install supervisor 3、如果是 Ubuntu 系统，还可以使用 apt-get 安装。1apt-get install supervisor 三、supervisor使用supervisor配置文件：/etc/supervisord.conf 注：supervisor的配置文件默认是不全的，不过在大部分默认的情况下，上面说的基本功能已经满足。 子进程配置文件路径：/etc/supervisord.d/ 注：默认子进程配置文件为ini格式，可在supervisor主配置文件中修改。 四、supervisord 配置Supervisor 相当强大，提供了很丰富的功能，不过我们可能只需要用到其中一小部分。安装完成之后，可以编写配置文件，来满足自己的需求。为了方便，我们把配置分成两部分：supervisord（supervisor 是一个 C/S 模型的程序，这是 server 端，对应的有 client 端：supervisorctl）和应用程序（即我们要管理的程序）。 supervisor.conf 配置文件说明首先来看 supervisord 的配置文件。安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件里： echo_supervisord_conf &gt; /etc/supervisord.conf去除里面大部分注释和“不相关”的部分，我们可以先看这些配置：123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码[supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini 我们把上面这部分配置保存到 /etc/supervisord.conf（或其他任意有权限访问的文件），然后启动 supervisord（通过 -c 选项指定配置文件路径，如果不指定会按照这个顺序查找配置文件：$CWD/supervisord.conf, $CWD/etc/supervisord.conf, /etc/supervisord.conf）： supervisord -c /etc/supervisord.conf查看 supervisord 是否在运行：1ps aux | grep supervisord program 配置上面我们已经把 supervisrod 运行起来了，现在可以添加我们要管理的进程的配置文件。这些配置可以都写到 supervisord.conf 文件里，如果应用程序很多，最好通过 include 的方式把不同的程序（组）写到不同的配置文件里。 为了举例，我们新建一个目录 /etc/supervisor/ 用于存放这些配置文件，相应的，把 /etc/supervisord.conf 里 include 部分的的配置修改一下： [include]files = /etc/supervisor/*.conf假设有个用 Flask 开发的用户系统 usercenter, 生产环境使用 gunicorn 运行。项目代码位于 /home/leon/projects/usercenter，WSGI 对象位于 wsgi.py。在命令行启动的方式是这样的： cd /home/leon/projects/usercentergunicorn -w 8 -b 0.0.0.0:17510 wsgi:app对应的配置文件可能是：12345678910111213[program:usercenter]directory = /home/leon/projects/usercenter ; 程序的启动目录command = gunicorn -w 8 -b 0.0.0.0:17510 wsgi:app ; 启动命令autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = leon ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/usercenter_stdout.log 其中 [program:usercenter] 中的 usercenter 是应用程序的唯一标识，不能重复。对该程序的所有操作（start, restart 等）都通过名字来实现。 五、注意事项1、Python 环境有两种方式指定程序使用的 Python 环境： command 使用绝对路径。假设使用 pyenv 来管理 Python 环境，上面例子中的 gunicorn 路径可以替换为 /home/leon/.pyenv/versions/usercenter/bin/gunicorn. 这种方式一目了然，推荐。通过 environment 配置 PYTHONPATH. environment=PYTHONPATH=$PYTHONPATH:/home/leon/.pyenv/versions/usercenter/bin/. environment 这个配置项非常有用，可以用来给程序传入环境变量。 2、后台进程Supervisor 只能管理在前台运行的程序，所以如果应用程序有后台运行的选项，需要关闭。 3、子进程有时候用 Supervisor 托管的程序还会有子进程（如 Tornado），如果只杀死主进程，子进程就可能变成孤儿进程。通过这两项配置来确保所有子进程都能正确停止： stopasgroup=truekillasgroup=true 4、先启动supervisord使用supervisor进程管理命令之前先启动supervisord，否则程序报错。使用命令supervisord -c /etc/supervisord.conf启动。若是centos7： 12systemctl start supervisord.service //启动supervisor并加载默认配置文件systemctl enable supervisord.service //将supervisor加入开机启动项 六、使用 supervisorctlSupervisorctl 是 supervisord 的一个命令行客户端工具，启动时需要指定与 supervisord 使用同一份配置文件，否则与 supervisord 一样按照顺序查找配置文件。 supervisorctl -c /etc/supervisord.conf上面这个命令会进入 supervisorctl 的 shell 界面，然后可以执行不同的命令了： status # 查看程序状态stop usercenter # 关闭 usercenter 程序start usercenter # 启动 usercenter 程序restart usercenter # 重启 usercenter 程序reread ＃ 读取有更新（增加）的配置文件，不会启动新添加的程序update ＃ 重启配置文件修改过的程序上面这些命令都有相应的输出，除了进入 supervisorctl 的 shell 界面，也可以直接在 bash 终端运行：123456$ supervisorctl status$ supervisorctl stop usercenter$ supervisorctl start usercenter$ supervisorctl restart usercenter$ supervisorctl reread$ supervisorctl update 七、常见问题1、unix:///var/run/supervisor/supervisor.sock no such file 问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错 解决办法：supervisord -c /etc/supervisord.conf 2、command中指定的进程已经起来，但supervisor还不断重启 问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，这里使用的是elasticsearch，command指定的是$path/bin/elasticsearch -d 解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个 3、启动了多个supervisord服务，导致无法正常关闭服务 问题描述：在运行supervisord -c /etc/supervisord.conf之前，直接运行过supervisord -c /etc/supervisord.d/xx.conf导致有些进程被多个superviord管理，无法正常关闭进程。 解决办法：使用ps -fe | grep supervisord查看所有启动过的supervisord服务，kill相关的进程。 4、&lt;踩坑&gt;supervisor中的minfds及minprocs参数用途 问题描述：程序报错 1ConnectionError: Error 24 connecting to 127.0.0.1:6379. Too many open files. 第一反应系统参数配置不够 12345678910111213141516171819系统ulimit配置（红色部分为调整配置）：$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 15060max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 65535 ###够了pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 65535 ###够了virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited supervisor配置参数： 12minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200 解决方案： 12minfds=65535 ; 可以打开的文件描述符的最小值，默认 1024minprocs=65535 ; 可以打开的进程数的最小值，默认 200 重启 1$ systemctl restart supervisord 八、其它除了 supervisorctl 之外，还可以配置 supervisrod 启动 web 管理界面，这个 web 后台使用 Basic Auth 的方式进行身份认证。 除了单个进程的控制，还可以配置 group，进行分组管理。 经常查看日志文件，包括 supervisord 的日志和各个 pragram 的日志文件，程序 crash 或抛出异常的信息一半会输出到 stderr，可以查看相应的日志文件来查找问题。 Supervisor 有很丰富的功能，还有其他很多项配置，可以在官方文档获取更多信息：http://supervisord.org/index.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac-install]]></title>
    <url>%2Fmac-install.html</url>
    <content type="text"><![CDATA[参考资料 https://www.jianshu.com/p/3d4a6433c998 1、制作优盘启动盘：优盘要求是8G或者8G以上的，准备好优盘后需要在电脑上下载系统安装程序，咱们直接下载最新版的 macOS Mojave，具体操作步骤如下： ####（1）获取系统包 打开https://support.apple.com/zh-cn/macos/mojave 链接 从 App Store 获取 macOS Mojave 点击查看，再点击获取。等待下载完成，下载完成后先不要启动安装，如果下载速度较慢可以到网盘或者其他地方找下载资源，但一定要注意安全。 （2） 制作U盘系统安装程序下载完之后，将准备好的优盘插到电脑上（桌面会显示优盘的名称），打开“应用程序—&gt;其他—&gt;磁盘工具”，如下图： 打开磁盘工具之后，将优盘抹掉（格式化）成「Mac OS X 扩展（日志式）」格式、GUID 分区图，并将优盘命名为「Mojave」如下图所示：按照途图中顺序依次检查，检查没问题后点抹掉。 （3）优盘抹掉之后，打开“应用程序—&gt;其他—&gt;终端”，如下图： 打开终端之后 将下列代码一字不差的粘贴到终端里面去 1sudo /Applications/Install\ macOS\ Mojave.app/Contents/Resources/createinstallmedia --volume /Volumes/Mojave /Applications/Install\ macOS\ Mojave.app --nointeraction 粘贴进去之后按回车键，会提示你输入密码，这个密码是你电脑的开机密码，输入的过程因为输入密码是加密的所以屏幕不会有任何反应，输完密码回车即可，然后是漫长漫长漫长的等待，等待的时间长短取决于你电脑的配置。如下图： 出现0%…10%…说明正在制作启动盘,那是制作进度，进度条君到100%并出现下图Install media now 的字样 说明优盘启动制作成功了。 优盘启动盘可以一直留着，可以随时帮助别人或者随时给自己的电脑重装系统。 2、重装启动盘制作好之后，就可以用它给电脑重装系统了，首先 把电脑里的重要文件进行备份，有移动硬盘拷贝出来或者上传网盘。 （1）再重复一次，给电脑重要信息备份 （2）将制作好的启动盘插到电脑上，如果制作好没拔就查着吧，给电脑关机。 （3）确认电脑关机之后，按下电源键，听到“当”的一声后，按住Option键不放，就是电脑键盘最后一排从左往右数第三个键，按住不放，直到出现启动菜单选项，如下图： 选择之后 会计入到Mac实用工具界面，如下界面： （如果需要将硬盘格式化可以选择磁盘工具，然后将硬盘格式化，操作跟抹掉优盘是一样的，抹掉之后点击左上角的✘就可以回到下图界面） 选择，安装Mac OS 然后是漫长的等待，具体等待多少长时间看你电脑的配置了，装完系统，开机会有提示根据提示操作即可。漫长的等待之后，系统就重装完成了。教程到此为止，你学会了吗？]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>MAC install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[passwd-error]]></title>
    <url>%2Fpasswd-error.html</url>
    <content type="text"><![CDATA[Linux 修改root密码报错情况一认证的地方出问题了。现象：123[root@x ~]# passwd rootChanging password for user root.passwd: Authentication token manipulation error 检查/etc/pam.d/passwd、/etc/pam.d/system-auth以下配置是否存在：123456789101112131415161718192021222324cat /etc/pam.d/system-auth#%PAM-1.0# This file is auto-generated.# User changes will be destroyed the next time authconfig is run.auth required pam_env.soauth required pam_faildelay.so delay=2000000auth sufficient pam_unix.so nullok try_first_passauth requisite pam_succeed_if.so uid &gt;= 1000 quiet_successauth required pam_deny.soaccount required pam_unix.soaccount sufficient pam_localuser.soaccount sufficient pam_succeed_if.so uid &lt; 1000 quietaccount required pam_permit.so#password requisite pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type=password sufficient pam_unix.so sha512 shadow nullok try_first_pass use_authtokpassword required pam_deny.sosession optional pam_keyinit.so revokesession required pam_limits.so-session optional pam_systemd.sosession [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uidsession required pam_unix.so 发现设置密码复杂被人注释了1password requisite pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type= 修复去掉# 就可以了。如果没有文件，或者文件被改动比较大，可以去同系统版本的操作系统上把这两个文件copy过来覆盖。 这条是设置密码,设置口令复杂度, 参数意思。 difok= ：此选项用来定义新密码中必须要有几个字符和旧密码不同 minlen=：此选项用来设置新密码的最小长度 ucredit= ：此选项用来设定新密码中可以包含的大写字母的最大数目。-1 至少一个 lcredit=：此选项用来设定新密码中可以包含的小写字母的最大数目 dcredit=：此选项用来设定新密码中可以包含的数字的最大数目 情况二/etc/passwd, /etc/shadow文件被锁住，不允许修改。现象：1234[root@x ~]# lsattr /etc/passwd----i-------- /etc/passwd[root@x ~]# lsattr /etc/shadow----i-------- /etc/shadow 情况123456[root@x ~]# passwd rootChanging password for user root.New UNIX password:BAD PASSWORD: it is based on a dictionary wordRetype new UNIX password:passwd: Authentication token manipulation error 解决方法：123456[root@x ~]# chattr -i /etc/shadow[root@x ~]# chattr -i /etc/passwd[root@x ~]# lsattr /etc/passwd------------- /etc/passwd[root@x ~]# lsattr /etc/shadow------------- /etc/shadow 情况三磁盘空间满了,检查下，并清理磁盘空间12345678[root@x ~]# df -lFilesystem 1K-blocks Used Available Use% Mounted on/dev/vda1 20960256 20960256 0 100% /devtmpfs 980108 0 980108 0% /devtmpfs 990780 0 990780 0% /dev/shmtmpfs 990780 106996 883784 11% /runtmpfs 990780 0 990780 0% /sys/fs/cgrouptmpfs 198156 0 198156 0% /run/user/0]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>passwd error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vpn-use]]></title>
    <url>%2Fvpn-use.html</url>
    <content type="text"><![CDATA[适用情况 下班或者放假期间在家或者出差时, 要访问公司内网服务, 比如gitlab、svn、以及公司后台n.m.gao7.com。 申请流程一、申请帐号和权限 1、登入云知道 https://ceo.yd.cc –工作台–申请单及审批。 2、点击提交申请，选择内部权限。 3、填写相关信息申请，提交申请。 二、等运维开通权限 1、云知道审批流程通过后，运维会把VPN相关的资料发给你。 2、解压zip包。 3、文件结构说明。 文件名 说明 base 配置文件目录，不可修改 home_vpn_use.bat 在家使用脚本 vpn_use.bat 在公司使用脚本 mac_add_vpn_route.sh mac 系统添加路由 README.txt 说明文件 vpn_Create.bat 创建VPN脚本 首先运行运行后重启电脑.reg window机器要先跑这个注册表，然后重启 三、使用VPNwindow 系统 第一步、双击 《首先运行运行后重启电脑.reg》 然后重启电脑。（如果没有这个文件，点击下载 ) 第二步、vpn_Create.bat 双击-回车-回车至结束。 第三步、根据自己在家还是在公司，运行不同的脚本，在家跑home_vpn_use.bat，在公司跑vpn_use.bat。 第四步、公司管理后台在家(需要拨VPN) n.m.gao7.com，在公司(不需要拨VPN)用m.m.gao7.com 第五步、拨完VPN后，浏览器测试是否可以访问到后台 Mac系统（苹果电脑） 第一步、创建vpn连接12345系统偏好设置-&gt;网络-&gt;左下方点&quot;+&quot;-&gt;接口选&quot;vpn&quot;类型选&quot;IPSec上的L2TP&quot;-&gt;名称填&quot;``天志VPN``&quot;-&gt;点&quot;创建&quot; 服务器地址填 ``uc.vpn1.gao7.com`` 帐号名称填你的vpn帐号 点&quot;鉴定设置&quot;, 填入你的vpn密码, 点&quot;好&quot; VPN的帐号密码，编辑器打开 home_vpn_use.bat 脚本中获取12345@echo onrasdial uc-vpn vpn帐号 vpn密码 ............ 第二步 创建options 创建一个options文件放到/etc/ppp目录下, options文件内容 vi 编辑存入下面内容并保存。 1plugin L2TP.ppp l2tpnoipsec 或者直接跑命令1sudo echo &quot;plugin L2TP.ppp l2tpnoipsec&quot; &gt; /etc/ppp/options 也可以直接下载文件 点击下载 到这个目录/etc/ppp 第三步, 使用vpn连接 打开网络偏好设置-选择创建的天志VPN-&gt;右键连接。 第四步, 运行mac添加路由脚本 mac_add_vpn_route.sh 给脚本提权, 放到path中去12sudo chmod 775 mac_add_vpn_route.shsudo sh -x mac_add_vpn_route.sh 第五步、拨完VPN后，浏览器测试是否可以访问到后台]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>vpn use</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-GTID]]></title>
    <url>%2Fmysql-gtid.html</url>
    <content type="text"><![CDATA[Write by lyc at 2018-09-19概念参考博文《MySQL-5.6版本GTID的主从复制》https://www.cnblogs.com/abobo/p/4242417.html配置参考博文《散尽浮华：Mysql5.6主从同步引用新特性-GTID》https://www.cnblogs.com/kevingrace/p/5569753.html综合参考博文《阿里云：MySQL5.7杀手级新特性：GTID原理与实战》https://yq.aliyun.com/articles/57731 一、GTID复制基础1.什么是GTIDGTID即全局事务ID（global transaction identifier），MySQL-5.6.2开始支持，MySQL-5.6.10后完善，GTID 分成两部分： UUID：MySQL实例的唯一标识，UUID保存在mysql数据目录的auto.cnf文件中，这是一个非常重要的文件，不能删除，这一部分是不会变的。 TID：事务ID，代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。 所以GTID能够保证每个MySQL实例事务的执行（不会重复执行同一个事务，并且会补全没有执行的事务）。下面是一个GTID的具体形式： 1234567891011mysql&gt; show master status;+---------------------+----------+--------------+------------------+------------------------------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+---------------------+----------+--------------+------------------+------------------------------------------+| log-bin-3306.000007 | 720 | | | a3fad9de-a5f9-11e8-8881-000c2900f08d:1-2 |+---------------------+----------+--------------+------------------+------------------------------------------+1 row in set (0.01 sec)# UUID:a3fad9de-a5f9-11e8-8881-000c2900f08d# TID:1-2# GTID:a3fad9de-a5f9-11e8-8881-000c2900f08d:1-2 ==在整个复制架构中GTID是不变化的，即使在多个连环主从中也不会变。==例如： ServerA —&gt;ServerB —-&gt;ServerC ，GTID从在ServerA ,ServerB,ServerC 中都是一样的。 2.GTID的概述 全局事物标识：global transaction identifieds。 ==GTID事务唯一性的，且一个事务对应一个GTID==。 一个GTID在一个服务器上只执行一次，避免重复执行导致数据混乱或者主从不一致。 GTID用来代替classic的复制方法，不在使用binlog+pos开启复制。而是==使用master_auto_postion=1的方式自动匹配GTID断点进行复制==。 MySQL-5.6.5开始支持的，MySQL-5.6.10后开始完善。 在传统的slave端，binlog是不用开启的，但是==在GTID中，slave端的binlog是必须开启的，目的是记录执行过的GTID（强制）==。 3.GTID复制的优点 更简单的实现failover，不用以前那样在需要找log_file和log_Pos。 更简单的搭建主从复制。 比传统复制更加安全。 GTID是连续没有空洞的，因此主从库出现数据冲突时，可以用添加空事物的方式进行跳过。 4.GTID复制的工作原理 master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。 slave端的i/o 线程将变更的binlog，写入到本地的relay log中。 sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。 如果有记录，说明该GTID的事务已经执行，slave会忽略。 如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。 在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。 ==要点：== slave在接受master的binlog时，会校验master的GTID是否已经执行过（一个服务器只能执行一次）。 为了保证主从数据的一致性，多线程只能同时执行一个GTID。 5.GTID复制的限制 ==不支持非事务引擎（MyISAM）== 不支持create table … select 语句复制(主库直接报错)原理：（ 会生成两个sql，一个是DDL创建表SQL，一个是insert into 插入数据的sql。由于DDL会导致自动提交，所以这个sql至少需要两个GTID，但是GTID模式下，只能给这个sql生成一个GTID ） 不允许一个SQL同时更新一个事务引擎表和非事务引擎表 ==在一个复制组中，必须要求统一开启GTID或者是关闭GTID== 开启GTID需要重启（5.7除外） ==开启GTID后，就不再使用原来的传统复制方式== 对于create temporary table 和 drop temporary table语句不支持 不支持sql_slave_skip_counter 二、GTID复制参数GTID相关参数解析1234567891011121314mysql&gt; show variables like &quot;%gtid%&quot;; +----------------------------------+-----------+| Variable_name | Value |+----------------------------------+-----------+| binlog_gtid_simple_recovery | ON || enforce_gtid_consistency | ON | # enforce_gtid_consistency=ON,保证GTID安全的参数，对于出现GTID复制的限制从库会报错，即便是gtid_mode=OFF也会校验限制（必须ON）| gtid_executed_compression_period | 1000 | # gtid_executed,执行过的所有GTID，全局和seeeion级别都可以用。贴士：show master status\G;输出结果中的Executed_Gtid_Set和gitd_executed一致。reset master时，此值会被清空。| gtid_mode | ON | # gtid_mode=ON,是否开启GTID功能（必须ON）| gtid_next | AUTOMATIC | # gtid_next,这个时session级别的参数：[master]&gt;show session variables like &apos;%gtid_next%&apos;;| gtid_owned | | # gtid_owned,正在运行的gtid，全局和session级别都可用，全局表示所有服务器拥有GTIDs，session级别表示当前client拥有所有GTIDs。（此功能用的少）| gtid_purged | | # gtid_purged,丢弃掉的GTID，全局参数，设置在binlog中，已经purged的GTIDs，并且purged掉的GTIDs会包含到gtid_executed中。贴士：从而导致slave不会再去master请求这些GTIDs，并且Executed_Gtid_Set为空时，才可以设置此值。| session_track_gtids | OFF |+----------------------------------+-----------+8 rows in set (0.01 sec) 关于GTID_MODE的4中模式 综合参考博文《阿里云：MySQL5.7杀手级新特性：GTID原理与实战》https://yq.aliyun.com/articles/57731 归纳总结： 当master产生Normal_GTID的时候（ON_PERMISSIVE，ON），如果slave的gtid_mode（OFF）不能接受Normal_GTID，那么就会报错 当master产生ANONYMOUS_GTID的时候（OFF_PERMISSIVE，OFF），如果slave的gtid_mode（ON）不能接受ANONYMOUS_GTID，那么就会报错 ==设置auto_position的条件： 当master gtid_mode=ON时，slave可以为OFF_PERMISSIVE，ON_PERMISSIVE，ON。除此之外，都不能设置auto_position = on== 三、通过备份搭建GTID slave开启GTID的必备条件 master,slave都配置的参数 5.6gtid参数都是静态参数，需要重启mysqld 12345678[mysqld]gtid_mode = ON # 打开gtid模式log_bin = ON # 所有节点都要记录binloglog-slave-updates = ON # 开启记录binlogenforce_gtid_consistency = ON # gtid复制安全性参数# 建议binlog改成行级模式，确保主从复制的一致性binlog_format = row 1.通过mysqldump123456789101112131415# master mysqldump#mysqldump -uroot -p -S /data/mysql_data_3306/mysql_3306.sock -A --master-data=2 --single-transaction --set-gtid-purged -B &gt; mysql207.sqlmysqldump -uroot -p -S /data/mysql_data_3306/mysql_3306.sock -A --master-data=2 --single-transaction --set-gtid-purged -B &gt; mysql207.sql# 导入sql到新实例后，CHANGE MASTER TOstop slave;CHANGE MASTER TOMASTER_HOST=&apos;192.168.x.x&apos;,MASTER_PORT=3306,MASTER_USER=&apos;newslave&apos;,MASTER_PASSWORD=&apos;123456&apos;,MASTER_AUTO_POSITION=1;start slave;# MASTER_AUTO_POSITION=1; # 这条命令是重点，1开启GTID复制 GTID复制错误1.关于enforce_gtid_consistency=1引起的GTID复制错误故障描述[ERROR] Slave SQL: Error ‘CREATE TABLE … SELECT is forbidden when @@GLOBAL’ Error_code: 1786 这套YD的高可用数据库是gtid_mode=OFF的，主库enforce_gtid_consistency=0，从库enforce_gtid_consistency=1 enforce_gtid_consistency是校验GTID复制安全性的参数，即便gtid_mode=OFF，把该参数设置成1仍然会检测主从复制过程中对GTID不安全的因素(CREATE TABLE ... SELECT)，所以会报这个错误。 总结ucloud高可用是基于file+pos的传统复制，而高可用下再挂的从库才是基于GTID的复制。所以控制台创建的机器是强制要求gtid_mode=ON，enforce_gtid_consistency=1 虽然没再建从库，两个GTID的开关开着，能够在主从复制的过程中暴露出从库同步失败的错误，如sql语句，不支持事务的MyISAM引擎等，从而去优化。 再联想到自建库，若要从传统的赋值升级成GTID的复制，同样也要采用这种方式，打开GTID，只要Auto_Position: 0都是传统复制，让主从复制暴露出问题，进而优化。 千万不能直接上，否则可能会经常出现主从复制异常的隐患。 enforce_gtid_consistency参数何时才能开？==enforce_gtid_consistency是静态参数，重启服务生效。== gtid_mode=on,enforce_gtid_consistency必须为1，否则服务起不来 gtid_mode=off,enforce_gtid_consistency可以为1，用于校验GTID安全性，意义不大，因为都是静态参数要么就全开。1234567891011121314151617mysql&gt; show variables like &quot;%gtid%&quot;;+----------------------------------+------------------------------------------+| Variable_name | Value |+----------------------------------+------------------------------------------+| binlog_gtid_simple_recovery | ON || enforce_gtid_consistency | ON || gtid_executed_compression_period | 1000 || gtid_mode | OFF || gtid_next | AUTOMATIC || gtid_owned | || gtid_purged | a3fad9de-a5f9-11e8-8881-000c2900f08d:1-2 || session_track_gtids | OFF |+----------------------------------+------------------------------------------+8 rows in set (0.01 sec)# 一开一关根本没意义，因为两个都是静态参数# 校验完你以后要用呢？还得重启去开gtid_mode=ON 2.mysql5.7 gtid_mode-&gt;dynamic 在mysql5.7是支持动态修改GTID_MODE的 需要注意的是GTID_MODE需要逐级修改 1234567mysql&gt; set global gtid_mode=ON;ERROR 1788 (HY000): The value of @@GLOBAL.GTID_MODE can only be changed one step at a time: OFF &lt;-&gt; OFF_PERMISSIVE &lt;-&gt; ON_PERMISSIVE &lt;-&gt; ON. Also note that this value must be stepped up or down simultaneously on all servers. See the Manual for instructions.mysql&gt; set @@GLOBAL.GTID_MODE=ON;ERROR 1788 (HY000): The value of @@GLOBAL.GTID_MODE can only be changed one step at a time: OFF &lt;-&gt; OFF_PERMISSIVE &lt;-&gt; ON_PERMISSIVE &lt;-&gt; ON. Also note that this value must be stepped up or down simultaneously on all servers. See the Manual for instructions.set @@GLOBAL.GTID_MODE=ON;OFF &lt;-&gt; OFF_PERMISSIVE &lt;-&gt; ON_PERMISSIVE &lt;-&gt; ON]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>mysql gtid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es-shard]]></title>
    <url>%2Fes-shard.html</url>
    <content type="text"><![CDATA[参考资料 ES 的填坑经验。主要是关于集群恢复过程中，数据量过大，使用的是普通盘1T,最大的index 大概在50多g ,分片恢复并发数默认是2个，同时2个50g 分片同时恢复，IO吃不消，导致集群 hang 住的问题。 场景描述 线上ES 5台 8核24g 普通盘（事实证明，ES 还是要用ssd,不然数据量在大点就抗不住），通用型云主机。某台主机挂了，开始恢复，CPU会越来越大。最后整个集群卡死。 基本概念ES 线程池（thread pool） ES 中每个节点有多种线程池，各有用途。重要的有： generic ：通用线程池，后台的 node discovery，上述的分片恢复（node recovery）等等一些通用后台的操作都会用到该线程池。该线程池线程数量默认为配置的处理器数量（processors） 4，最小128，最大512。index ：index/delete 等索引操作会用到该线程池，包括自动创建索引等。默认线程数量为配置的处理器数量，默认队列大小：200.search ：查询请求处理线程池。默认线程数量：int((# of available_processors 3) / 2) + 1，默认队列大小：1000.get ：get 请求处理线程池。默认线程数量为配置的处理器数量，默认队列大小：1000.write ：单个文档的 index/delete/update 以及 bulk 请求处理线程。默认线程数量为配置的处理器数量，默认队列大小：200，在写多的日志场景我们一般会将队列调大。还有其它线程池，例如备份回档（snapshot）、analyze、refresh 等，这里就不一一介绍了。 详细可参考官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html 集群恢复之分片恢复 我们知道 ES 集群状态分为三种，green、yellow、red。green 状态表示所有分片包括主副本均正常被分配；yellow 状态表示所有主分片已分配，但是有部分副本分片未分配；red 表示有部分主分片未分配。 一般当集群中某个节点因故障失联或者重启之后，如果集群索引有副本的场景，集群将进入分片恢复阶段（recovery）。此时一般是 master 节点发起更新集群元数据任务，分片的分配策略由 master 决定，各节点收到集群元数据更新请求，检查分片状态并触发分片恢复流程，根据分片数据所在的位置，有多种恢复的方式，主要有以下几种： EXISTING_STORE ： 数据在节点本地存在，从本地节点恢复。PEER ：本地数据不可用或不存在，从远端节点（源分片，一般是主分片）恢复。SNAPSHOT ： 数据从备份仓库恢复。LOCAL_SHARDS ： 分片合并（缩容）场景，从本地别的分片恢复。PEER 场景分片恢复并发数主要由如下参数控制： cluster.routing.allocation.node_concurrent_incoming_recoveries ：节点上最大接受的分片恢复并发数。一般指分片从其它节点恢复至本节点。 cluster.routing.allocation.node_concurrent_outgoing_recoveries ：节点上最大发送的分片恢复并发数。一般指分片从本节点恢复至其它节点。 cluster.routing.allocation.node_concurrent_recoveries ：该参数同时设置上述接受发送分片恢复并发数为相同的值。 详细参数可参考官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html集群卡住的主要原因就是从远端节点恢复（PEER）的并发数过多，导致 generic 线程池被用完。涉及目标节点（target）和源节点（source）的恢复交互流程，后面分析问题时我们再来详细讨论。 解决问题 6.x 版本之后引入了 seqNo，恢复会涉及到 seqNo+translog，这也是6.x提升恢复速度的一大改进。我们重点关注流程中第 2、4、5、7、10、12 步骤中的远程调用，他们的作用分别是： 第2步：分片分配的目标节点向源节点（一般是主分片）发起分片恢复请求，携带起始 seqNo 和 syncId。第4步：发送数据文件信息，告知目标节点待接收的文件清单。第5步：发送 diff 数据文件给目标节点。第7步：源节点发送 prepare translog 请求给目标节点，等目标节点打开 shard level 引擎，准备接受 translog。第10步：源节点发送指定范围的 translog 快照给目标节点。第12步：结束恢复流程。 我们可以看到除第5步发送数据文件外，多次远程交互 submitRequest 都会调用 txGet，这个调用底层用的是基于 AQS 改造过的 sync 对象，是一个同步调用。 如果一端 generic 线程池被这些请求打满，发出的请求等待对端返回，而发出的这些请求由于对端 generic 线程池同样的原因被打满，只能 pending 在队列中，这样两边的线程池都满了而且相互等待 修改默同步分片数为1，只能让他慢慢恢复了。1234567curl -X PUT &quot;http://10.19.174.22:9200/_cluster/settings&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;persistent&quot;: &#123; &quot;cluster.routing.allocation.node_concurrent_recoveries&quot;: 1, &quot;indices.recovery.max_bytes_per_sec&quot;: &quot;60mb&quot; &#125;&#125; cluster.routing.allocation.node_concurrent_recoveries 设置在节点中最大允许同时进行分片分布的个数，默认为2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>单台CPU高 ES异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows-KB4512506]]></title>
    <url>%2Fwindows-KB4512506.html</url>
    <content type="text"><![CDATA[参考资料 系统windows 2008 r2 64 现象错误：代码 80092004 补丁KB4512506 在 2019 年 8 月 13日，微软公司披露了两个远程桌面服务中存在的远程代码执行安全漏洞，编号分别为 CVE-2019-1181 和 CVE-2019-1182。相关网址是：https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2019-1181 https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2019-1182这两个安全漏洞的危害性极大，微软发布了相关的安全补丁，在 Win7 上对应的补丁是 2019 年 8 月的 Windows 7 月度安全质量汇总 KB4512506： 解决 在一个国外的博客上有对该问题的说明及解决办法：https://borncity.com/win/2019/08/14/windows-updates-kb4512506-kb4512486-drops-error-0x80092004/ 1、搜索下https://www.catalog.update.microsoft.com/Search.aspx?q=KB4490628 2、 在两台计算机上试验，发现以前均已使用 Windows Update 成功安装过 KB4474419 补丁，所以只需要手动下载并安装 KB4490628 补丁，如下图所示： 3、安装完 KB4490628 补丁之后，接下来就可以成功安装 KB4512506 补丁了。]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>补丁KB4512506无法安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu-safe]]></title>
    <url>%2FUbuntu-safe.html</url>
    <content type="text"><![CDATA[提高Ubuntu服务器系统安全原文出处 Ubuntu服务器全新安装后的基本安全设置当你创建一个新的 Ubuntu server 时，有若干个基本配置需要做，这可以提高系统安全性和可用性，为你后续工作打造坚实的基础。 任何暴露主机都是黑客潜在的攻击对象，下面的几个简单的技巧就可以提高系统安装。 保持系统最新，封堵已知漏洞 设置复杂密码 使用最严格的访问控制，不要图方便 使用防火墙 第一步－root登录ssh root@SERVER_IP_ADDRESS root用户是linux系统中的管理员账户，有非常高的权限。由于它的权限过高，所以不建议是使用root用户操作linux系统。一不小就悲剧了。 第二步－创建新用户用root登录之后我们创建一个新用户，下面命令创建一个demo用户： # adduser demo 设置一个复杂的密码 第三步－Root 权限现在我们有了一个普通权限的新用户，但是我们有时需要执行管理员权限的任务。为了避免在普通用户和root用户之间来回切换，我们可以赋予普通用户执行root权限任务的权限，也就是在命令前加 sudo。 为了赋予新用户权限，我们需要把新用户加入到 “sudo” 组。在ubuntu14.04默认设置下，在‘sudo’组的可以执行sudo命令。 用root执行下面命令，把新用户加入打sudo组 # gpasswd -a demo sudo 现在 demo 用户可以执行root权限命令了。 第四步-公开密钥认证(Public Key Authentication)首先，不需要通过网络传输ssh key其次，ssh key是经过加密后保存的，即使让人偷了还需要有加密串才能解密。相反，如果密码被偷了，可以直接用来登陆的。这样还可以避免别人对我们的ssh服务器进行暴力破解。 我们这边提到的ssh key实际上是一对key，分别保存在两个文件中。其中私钥也就是我们所谓的密钥保存在客户端的机器上，并使用密窜加密。而公钥则存储在服务器上。在创建ssh链接时，客户端和服务端之间使用公钥和私钥进行协商，如果它们之间匹配（当然是在加密状态下），则成功创建链接。 生成一对key，在本地计算机终端执行： $ ssh-keygen 回车使用默认文件（或输入名称），下一要你输入密码 生成两个文件：其中id_rsa是私钥，id_rsa.pub是公钥。注意私钥不要分享给别人。 拷贝公钥到服务器我们介绍两种方法： 方法一：ssh-copy-id： $ ssh-copy-id demo@SERVER_IP_ADDRESS 执行完这条命令之后，公钥被拷贝到服务器的 .ssh/authorized_keys 文件，现在你可以用对应的私钥登录服务器。 方法二：手动安装： 你现在可以通过ftp或scp将公钥传到远程的ssh服务器上。 $ scp id_rsa.pub demo@SERVER_IP_ADDRESS (当然，现在你们还是使用密码认证，而不是公钥认证，还没完成呢） 远程登陆到ssh服务器 $ ssh -l demo@SERVER_IP_ADDRESS 在远程服务器上的用户当前目录，看看有没有.ssh目录，通常都会有的，如果没有，则创建。 mkdir -p ~/.ssh chmod 700 ~/.ssh 把公钥文件id_rsa.pub的内容附加到 ~/.ssh/authorized_keys $ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys $ chmod 600 ~/.ssh/authorized_keys 第五步：配置后台SSH驻留进程现在有了一个新用户，我们可以通过修改ssh配置稍微提要以下服务器安全：禁用ssh登录root用户。 $ vi /etc/ssh/sshd_config PermitRootLogin yes 改为 PermitRootLogin on 强烈建议关闭root登录。 重启SSH： $ service ssh restart]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu 安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-safe]]></title>
    <url>%2FLinux-safe.html</url>
    <content type="text"><![CDATA[怎么尽量消除Linux服务器系统安全风险，预防攻击原文链接 一个系统有很多功能，易遭攻击点也很多。原则上讲单一功能的系统比多功能的系统更安全。减少可用攻击点，典型的包括卸载不必要的软件，不必要的登录用户名，关闭或移除不必要的服务。其他的还有给kernel打补丁，重编译kernel，关闭打开的网络接口，安装侵入侦察系统，防火墙，入侵预防系统。 第一步，通过服务器的想要功能来决定安装什么服务。例如，如果要搭建web服务器你应该安装Linux, Apache, MySQL, 和 Perl/ PHP/ Python (LAMP)服务，其他的东西都不要安装，因为安装额外的软件或运行额外的服务创造了不必要的易攻击点。 你需要决定你是否需要图形用户界面。Linux管理员可以通过命令行管理网络和服务，但是一些新手管理员倾向于用GUI，GUI占用了大量系统资源，运行不必要的服务。如果要用，在用完之后可以杀掉GUI进程。 一些通用安全优化步骤： 数据加密通讯 避免用不安全的协议发送明文信息或密码 最小化服务器中不必要的软件 关闭不需要的 SUID 和 SGID 的特殊权限 保持系统为最新，尤其是安全补丁 使用安全扩展 考虑用SELinux 提要用户密码复杂度 定期更改密码，避免重复使用同一个密码 当用户登录错误次数太多时，锁定用户 不允许使用空密码 SSH 关闭不必要的服务 提高 /tmp /var/tmp /dev/shm 目录的安全性 隐藏 BIND DNS 服务版本和 apache 版本 提高 sysctl.conf 安全 安装 Root Kit Hunter and ChrootKit Hunter 最小化开放网络端口 配置系统防火墙 更安全合理的分区 关闭不需要的文件权限 维护系统日志，把日志镜像到分离的日志服务器 安装Logwatch并每天查看Logwatch emails 使用侵入侦察系统 安装linux Socket 监控 安装Mod_security 限制用户权限 备份 服务器物理安全 服务器物理安全 配置 BIOS，关闭从CD/DVD和外部设备启动。启用 BIOS 密码和GRUB密码防治在物理上访问你的系统。 保持系统最新# apt-get update # apt-get upgrade 无人看管的升级系统自动更新，你需要安装几个软件包，用root运行： # apt-get install unattended-upgrades apt-listchanges unattended-upgrades 软件的默认配置文件是 /etc/apt/apt.conf.d/50unattended-upgrades，默认配置可以很好的工作，但是你可以根据需要做些修改。 $ vi /etc/apt/apt.conf.d/50unattended-upgrades 设置哪些软件包需要升级： Unattended-Upgrade::Origins-Pattern { // ... }; 取消注释下面这行： Unattended-Upgrade::Mail &quot;root&quot;; 为了激活unattended-upgrades，你需要确认/etc/apt/apt.conf.d/20auto-upgrades 包含如下行： $ vi /etc/apt/apt.conf.d/20auto-upgrades $ APT::Periodic::Update-Package-Lists &quot;1&quot;; $ APT::Periodic::Unattended-Upgrade &quot;1&quot;; /etc/apt/apt.conf.d/20auto-upgrades 文件可以手动创建或root执行如下命令： # dpkg-reconfigure -plow unattended-upgrades 最小化服务器中不必要的软件$ dpkg --list $ dpkg --info packageName $ apt-get remove packageName su确保只有在 sudo 组里的用户可以运行su $ dpkg-statoverride --update --add root sudo 4750 /bin/su 关闭root用户出于安全原因，可以在不需要root用户操作服务器时将其关闭 $ passwd -l root //锁定 $ passwd -u root //解锁 关闭 Shell 用户查看激活的用户： $ cat /etc/passwd | egrep -v &apos;/false|/nologin|/shutdown|/halt&apos; | cut -d&apos;:&apos; -f 1,7 关闭用户命令： $ usermod -s /usr/sbin/nologin &quot;username&quot; //注意 没有引号 控制台（console）在默认下，许多终端都是激活的，如下 $ vi /etc/securetty 注释掉不需要的终端 tty1 #tty2 #tty3 #tty4 # ... securetty文件确保只有root用户可以修改 /etc/securetty 文件 $ chown root:root /etc/securetty $ chmod 0600 /etc/securetty 共享内存（Shared memory）共享内存可以用来攻击运行的服务 如apahce2 $ vi /etc/fstab 加入行如下 #secure shared memory tmpfs /run/shm tmpfs defaults,noexec,nosuid 0 0 重启生效 $ mount -a 提高IP安全在 /etc/sysctl.conf 文件中加入 # Ignore ICMP broadcast requests net.ipv4.icmp_echo_ignore_broadcasts = 1 # Disable source packet routing net.ipv4.conf.all.accept_source_route = 0 net.ipv6.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 net.ipv6.conf.default.accept_source_route = 0 # Ignore send redirects net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 # Block SYN attacks net.ipv4.tcp_max_syn_backlog = 2048 net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_syn_retries = 5 # Log Martians net.ipv4.conf.all.log_martians = 1 net.ipv4.icmp_ignore_bogus_error_responses = 1 # Ignore ICMP redirects net.ipv4.conf.all.accept_redirects = 0 net.ipv6.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv6.conf.default.accept_redirects = 0 # Ignore Directed pings net.ipv4.icmp_echo_ignore_all = 1 关闭 Open DNS Recursion 和版本信息终端中执行： $ vi /etc/bind/named.conf.options 在Options段中加入： recursion no; version &quot;Not Disclosed&quot;; 重启 BIND DNS 服务 $ /etc/init.d/bind9 restart 关闭IPv6如果你不需要IPv6，建议关闭 $ vi /etc/sysctl.conf 增加或修改以下行： #disable ipv6 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 重新加载配置 $ sysctl -p 关闭IPv6 Bind9 监听$ vi /etc/default/bind9 增加或修改以下行： # run resolvconf? RESOLVCONF=yes # startup options for the server OPTIONS=&quot;-4 -u bind&quot; - 关闭IRQ平衡（Balance）irq balance用于优化中断分配，它会自动收集系统数据以分析使用模式，并依据系统负载状况将工作状态置于 Performance mode 或 Power-save mode。处于Performance mode 时，irqbalance 会将中断尽可能均匀地分发给各个 CPU core，以充分利用 CPU 多核，提升性能。 $ vi /etc/default/irqbalance 把ENABLED改为0 ENABLED=0 TCP WrapperTCP Wrapper是基于规则的访问列表，包含以下2个文件 /etc/hosts.allow /etc/hosts.deny 两个文件的语法相似定义如下 daemon : client [:option1:option2:...] 例如，如果你想允许指定IP（或IP范围）而拒绝其他IP通过SSH访问 在 /etc/hosts.allow 文件中加入 shd : 111.111, 222.222.222.222 在/etc/hosts.deny 文件中加入 sshd : ALL 注意： 每个服务在hosts.allow和hosts.deny只能有一个规则 在hosts.allow和hosts.deny的设置立即生效 在两个文件中的最后一行必须以新的一行结束 /tmp 和 /var/tmp临时存储目录临时存储目录/tmp, /var/tmp 和 /dev/shm 给攻击者提供了存储空间。 /tmp给/tmp分区提供一个1G的文件系统 $ dd if=/dev/zero of=/usr/tmpDSK bs=1024 count=1024000 创建一个当前/tmp的备份 $ cp -Rpfv /tmp /tmpbackup 挂载/tmp分区并设置正确的访问权限 $ mount -t tmpfs -o loop,noexec,nosuid,rw /usr/tmpDSK /tmp $ chmod 1777 /tmp 恢复备份文件 并 删除备份文件： $ cp -Rpf /tmpbackup/* /tmp/ $ rm -rf /tmpbackup/* 在fbtab文件中设置/tmp $ /usr/tmpDSK /tmp tmpfs loop,nosuid,noexec,rw 0 0 检测fbtab $ mount -o remount /tmp 如果你想在/tmp中执行脚本或可执行文件，你会得到一个permission denied /var/tmp$ mv /var/tmp /var/tmpold $ ln -s /tmp /var/tmp $ cp -prfv /var/tmpold/* /tmp/ 关闭autofs阻止自动挂载可移动媒体和NFS文件系统，你可以写一条udev规则关闭autofs，首先创建/etc/udev/rules.d/85-no-automount.rules文件 $ vi /etc/udev/rules.d/85-no-automount.rules 写入 SUBSYSTEM==&quot;usb&quot;, ENV{UDISKS_AUTO}=&quot;0&quot; 重启服务 $ service udev restart 设置security limits设置进程限制防止fork炸弹攻击 $ vi /etc/security/limits.conf 例子： cyberpunk hard nproc 100 @cybergroup hard nproc 20 关闭不需要的服务Linux系统安装了很多服务，服务过多将导致资源耗尽。为了提高性能和安全，关闭无用服务。 查看正在运行的服务 $ initctl list | grep running 你可以移除启动脚本来关闭服务，或者彻底移除它。大部分的服务都可以用下面的命令来关闭。 $ echo &quot;manual&quot; &gt; /etc/init/service.override $ update-rc.d -f service_name remove 卸载命令 $ apt-get purge service_name 关闭anacronanacron子系统设计用来为系统提供cron自动任务功能，这是非常有用的功能，但是如果你没打算用，你可以关闭此服务。 如果你想关闭anacron服务，简单的注释掉 /etc/crontab 文件的以下行 # 25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily ) # 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly ) # 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 锁定CronjobsCron有一个内建功能，可以允许谁可以执行任务，谁不可以。这个功能由两个文件控制/etc/cron.allow 和 /etc/cron.deny。为了禁止一个用户使用cron，在cron.deny加入此用户名。如果想禁止所有用户运行cron，在cron.deny文件中加入‘ALL’ $ echo ALL &gt;&gt;/etc/cron.deny 关闭ApportApport是内部错误报告程序，它收集系统崩溃信息。关闭方法如下： $ vi /etc/default/apport 把enabled改为0 # set this to 0 to disable apport, or to 1 to enable it # you can temporarily override this with # sudo service apport start force_start=1 enabled=0 移除Apport$ apt-get purge apport 关闭atdat命令用来定时执行命令，但是不同于cron，at任务只执行一次。如果你用cron，你也许不需要这个服务。 $ echo &apos;manual&apos; &gt; /etc/init/atd.override 移除at$ apt-get purge at 关闭AvahiAvahi 是 zeroconf 协议的实现。它可以在没有 DNS 服务的局域网里发现基于 zeroconf 协议的设备和服务。它跟mDNS 一样。 $ cd /etc/init $ touch avahi-daemon.override $ echo &quot;manual&quot; &gt; avahi-daemon.override 移除Avahi$ apt-get remove avahi-daemon avahi-utils 关闭蓝牙（Bluetooth） 第一种关闭方法 $ vi /etc/rc.local 在exit 0之前加入 $ rfkill block bluetooth 第二种关闭方法 $ vi /etc/bluetooth/main.conf 设置InitiallyPowered为false InitiallyPowered = false 禁用Ctrl+Alt+Delete你不想以外重启服务器，编辑control-alt-delete.conf关闭 $ vi /etc/init/control-alt-delete.conf 删除或注释掉下面一行 #exec shutdown -r now &quot;Control-Alt-Delete pressed&quot; 关闭CupsCUPS给Unix/Linux用户提供了一种可靠有效的方法来管理打印。它支持IPP，并提供了LPD，SMB（服务消息块，如配置为微软WINDOWS的打印机）、JetDirect等接口。CUPS还可以浏览网络打印机。 $ echo &quot;manual&quot; &gt; /etc/init/cups.override 卸载Cups$ capt-get remove cups 关闭DovecotDovecot 是一个开源的 IMAP 和 POP3 邮件服务器，支持 Linux/Unix 系统。 POP / IMAP 是 MUA 从邮件服务器中读取邮件时使用的协议。 $ apt-get purge dovecot-* 关闭NFSNFS是Unix/Linux/BSD操作系统的网络文件分享程序。无用的服务 NFS服务包含如下几个包： nfs-kernel-server nfs-common portmap rpcbind autofs $ apt-get purge nfs-kernel-server nfs-common portmap rpcbind autofs 关闭SNMP服务简单网络管理协议（SNMP），由一组网络管理的标准组成，包含一个应用层协议（application layer protocol）、数据库模型（database schema）和一组资源对象。该协议能够支持网络管理系统。如果你不需要这个服务，你可以移除它： $ apt-get purge --auto-remove snmp 关闭TelnetTelnet默认没有安装，最好不要安装。 $ apt-get purge telnetd inetutils-telnetd telnetd-ssl 关闭WhoopsieWhoopsie这个服务使用来发送崩溃log到ubuntu。为了关闭它，编辑文件： $ vi /etc/default/whoopsie 把report_crashes参数改为false report_crashes=false 卸载Whoopsie$ apt-get purge whoopsie 关闭Wireless现在主流的主板都集成了Wireless适配器，在服务器环境中是没有用的。 $ vi /etc/network/interfaces 加入下面一行 iface wlan0 inet manual $ service network-manager restart 关闭 ZeitgeistZeitgeist 是 Ubuntu 上用来记录用户行为和事件的服务,包括文件打开、网站访问、对话等等,其他应用程序可访问这些记录下来的信息。 $ apt-get purge zeitgeist-core zeitgeist-datahub python-zeitgeist rhythmbox-plugin-zeitgeist zeitgeist 禁用编译器编译器可以被攻击者用来编译攻击你服务器的恶意软件。生产环境通常不需要它。 chmod 000 /usr/bin/byacc chmod 000 /usr/bin/yacc chmod 000 /usr/bin/bcc chmod 000 /usr/bin/kgcc chmod 000 /usr/bin/cc chmod 000 /usr/bin/gcc chmod 000 /usr/bin/*c++ chmod 000 /usr/bin/*g++ 如果你需要使用编译器，执行： chmod 755 /usr/bin/byacc chmod 755 /usr/bin/yacc chmod 755 /usr/bin/bcc chmod 755 /usr/bin/kgcc chmod 755 /usr/bin/cc chmod 755 /usr/bin/gcc chmod 755 /usr/bin/*c++ chmod 755 /usr/bin/*g++ 实现IP检测如果有人hack进入到你的账户，确保你可以得到通知信息，并得到黑客的地址。 为了实现这个，简单的编辑.bash_profile 或 .profile: $ vi .bash_profile 加入以下文本： $ echo &apos;ALERT - ACCESS GRANTED on:&apos; `date` `who` | mail -s &quot;ALERT - ACCESS GRANTED from `who | awk &apos;{print $6}&apos;`&quot; admin@domain.com 安装Fail2Ban带有最基本的SSH配置是不安全的。Fail2Ban提供了一个方法自动检测和保护服务器被攻击者攻击。这个程序通过扫描log文件并对不信任的行为作出反应，想登录尝试失败。 安装Fail2Ban $ apt-get install fail2ban 创建config配置文件 Fail2Ban运行需要正确的配置文件，默认配置文件在/etc/fail2ban/jail.conf，但是这个文件并不是你需要的。你应该自己创建 .local文件。 $ cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local $ vi /etc/fail2ban/jail.local Fail2Ban SSH 配置[ssh] enabled = true port = your port number or ssh filter = sshd logpath = /var/log/auth.log maxretry = 2 [ssh-ddos] enabled = true port = your port number or ssh filter = sshd-ddos logpath = /var/log/auth.log maxretry = 2 邮件通知 destemail = admin@domain.com action = %(action_mwl)s 重启Fail2Ban $ service fail2ban restart 检查状态 $ fail2ban-client status 检查iptables规则 $ iptables -L 安装PSAD端口扫描攻击检测(psad)是一个很好的可以检测很多扫描攻击的软件。它分析iptables log信息检测端口扫描和其他可疑流量。 安装PSAD $ apt-get install psad 编辑配置文件 $ vi /etc/psad/psad.conf 在你做任何改变之前，确保HOSTNAME参数设置正确。然后更新下面参数： EMAIL_ADDRESSES: 你的email地址 HOSTNAME: 你的hostname ENABLE_AUTO_IDS：改成Y，如果你想让PSAD自己做决定 ENABLE_AUTO_IDS_EMAILS：Y，接收邮件 加入iptables规则 iptables -A INPUT -j LOG iptables -A FORWARD -j LOG 重启psad $ psad -R $ psad --sig-update $ psad -H 查看psad状态 $ psad --Status Postfix确保Postfix以非root用户运行 $ ps aux | grep postfix | grep -v &apos;^root&apos; 改变权限和所有者 $ chmod 755 /etc/postfix $ chmod 644 /etc/postfix/*.cf $ chmod 755 /etc/postfix/postfix-script* $ chmod 755 /var/spool/postfix $ chown root:root /var/log/mail* $ chmod 600 /var/log/mail* 配置更新 $ vi /etc/postfix/main.cf 修改myhostname myhostname = server.domain.com 配置Postfix接口监听地址 mydestination = $myhostname, localhost.$mydomain, localhost inet_interfaces = localhost 配置网络 mynetworks = 10.0.0.0/16, 192.168.1.0/24, 127.0.0.1 配合SMTP服务 mydomain = domain.com myorigin = domain.com relay_domains = domain.com smtpd_banner = $myhostname 限制拒绝服务攻击 Limit Denial of Service Attacks: default_process_limit = 100 smtpd_client_connection_count_limit = 10 smtpd_client_connection_rate_limit = 30 queue_minfree = 20971520 header_size_limit = 51200 message_size_limit = 10485760 smtpd_recipient_limit = 100 关闭 SMTP VRFY 命令 disable_vrfy_command = yes smtpd_delay_reject = yes smtpd_helo_required = yes smtpd_helo_restrictions = permit_mynetworks, reject_non_fqdn_hostname smtpd_helo_restrictions = reject_invalid_hostname 限制 Postfix SMTP 服务申请 RCPT TO 命令 smtpd_recipient_restrictions = reject_invalid_hostname, // Reject email if it not valid hostname reject_non_fqdn_hostname, // Reject email if it not valid FQDN reject_non_fqdn_sender, // Reject the request when the MAIL FROM address is not in fully-qualified domain form. For example email send from xyz or abc is rejected. reject_non_fqdn_recipient, // Reject the request when the RCPT TO address is not in fully-qualified domain form reject_unknown_sender_domain, // Reject email, if sender domain does not exists reject_unknown_recipient_domain, // Reject email, if recipient domain does not exists permit_mynetworks, reject_rbl_client list.dsbl.org, // Configure spam black lists reject_rbl_client sbl.spamhaus.org, reject_rbl_client cbl.abuseat.org, reject_rbl_client dul.dnsbl.sorbs.net, permit 设置错误睡眠时间，软硬错误限制 smtpd_error_sleep_time = 1s smtpd_soft_error_limit = 10 smtpd_hard_error_limit = 20 Forward emails $ vi /etc/postfix/virtual 一行中两个email地址 email1@domain.com email2@domain.com email1@domain.com的所有邮件转到email2@domain.com 重启Postfix $ service postfix restart Apache用户和组 $ groupadd webuser $ useradd -d /var/www/ -g webuser -s /bin/nologin webuser 编辑 etc/apache2/envvars $ vi etc/apache2/envvars User webuser Group webuser 限制本地访问 $ chown -R 750 /etc/apache2/bin /etc/apache2/conf $ chmod 511 /usr/sbin/apache2 $ chmod 750 /var/log/apache2/ $ chmod 750 /etc/apache2/conf/ $ chmod 640 /etc/apache2/conf/* $ chgrp -R &lt;MyApacheUser&gt; /etc/apache2/conf 限制目录访问 $ vi /etc/apache2/apache2.conf 增加 &lt;Directory /&gt; Options None Order deny,allow Deny from all &lt;/Directory&gt; 重启apache $ /etc/init.d/apache2 restart 关闭目录清单 &lt;Directory /var/www/html&gt; Options -Indexes &lt;/Directory&gt; XSS 保护 $ vi /etc/apache2/apache2.conf &lt;IfModule mod_headers.c&gt; Header set X-XSS-Protection &quot;1; mode=block&quot; &lt;/IfModule&gt; 重启Apache $ /etc/init.d/apache2 restart 点击劫持攻击 点击劫持是一种视觉上的欺骗手段。攻击者使用一个透明的、不可见的iframe，覆盖在一个网页上，然后诱使用户在该网页上进行操作，此时用户将在不知情 的情况下点击透明的iframe页面。通过调整iframe页面的位置，可以诱使用户恰好点击在iframe页面的一些功能性按钮上。 $ vi /etc/apache2/apache2.conf &lt;IfModule mod_headers.c&gt; Header always append X-Frame-Options SAMEORIGIN &lt;/IfModule&gt; 关闭 Etag Etag 允许远程攻击者获取敏感信息 FileETag None 关闭老协议 RewriteEngine On RewriteCond %{THE_REQUEST} !HTTP/1.1$ RewriteRule .* - [F] 关闭SSI SSI是英文Server Side Includes的缩写,翻译成中文就是服务器端包含的意思。从技术角度上说,SSI就是在HTML文件中,可以通过注释行调用的命令或指针。SSI允许攻击者远程注入恶意脚本。 &lt;Directory /path/to/htdocs&gt; Options -Indexes -Includes Order allow,deny Allow from all &lt;/Directory&gt; 关闭CGI &lt;Directory /path/to/htdocs&gt; Options -Indexes -Includes -ExecCGI Order allow,deny Allow from all &lt;/Directory&gt; 关闭追踪HTTP请求 $ vi /etc/apache2/apache2.conf TraceEnable off 关闭不需要的模块 列出所有打开的模块命令 $ apache2 -l 关闭模块可以用 a2dismod 命令，打开用a2enmod命令 a2dismod &lt;module&gt; 关闭apache的符号链接 &lt;Directory /path/to/www&gt; Options -FollowSymLinks &lt;/Directory&gt;l; 如果你想在特定的网站打开符号链接，在网站的.htaccess写入： &lt;Directory /path/to/some_www&gt; Options +FollowSymLinks &lt;/Directory&gt;l; 限制http请求大小 apache没有限制http请求大小，这就是说，无限大的数据可以发送给apache服务器。hacker可以用这个实现拒绝服务攻击。 &lt;Directory &quot;/path/to/www/&quot;&gt; LimitRequestBody 512000 &lt;/Directory&gt; 配置超时时间（Timeout） 默认300秒，可以适当减少 Timeout 45 隐藏Apache信息 $ vi /etc/apache2/apache2.conf ServerTokens Prod ServerSignature Off &lt;IfModule mod_headers.c&gt; Header unset Server Header unset X-Powered-By &lt;/IfModule&gt; 重启apache $ /etc/init.d/apache2 restart HTTP请求方法 $ vi /etc/apache2/apache2.conf &lt;LimitExcept GET POST HEAD&gt; deny from all &lt;/LimitExcept&gt; 例如： &lt;Location /&gt; Order allow,deny Allow from all &lt;LimitExcept HEAD POST GET&gt; Deny from all &lt;/LimitExcept&gt; &lt;/Location&gt; 重启； HTTPOnly Cookie $ vi /etc/apache2/apache2.conf &lt;IfModule mod_headers.c&gt; Header edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure &lt;/IfModule&gt; 重启； 屏蔽IP地址 &lt;Limit GET POST PUT&gt; Order Allow,Deny Allow from all Deny from 1.1.1.1 &lt;/Limit&gt; ModSecurityModSecurity是一个开源的网络应用防火墙。它可以嵌入到web服务或做为独立的网络应用工作，检测并阻止攻击者攻击web服务。 在安装 ModSecurity 之前，先要安装依赖： 32位： $ apt-get install libxml2 libxml2-dev libxml2-utils $ apt-get install libaprutil1 libaprutil1-dev 64位： $ ln -s /usr/lib/x86_64-linux-gnu/libxml2.so.2 /usr/lib/libxml2.so.2 $ apt-get install libapache-mod-security 配置 ModSecurity 规则 激活默认规则： $ mv /etc/modsecurity/modsecurity.conf-recommended /etc/modsecurity/modsecurity.conf 你可以根据需要配置规则，ModSecurity的规则目录在/etc/modsecurity/。 $ vi /etc/modsecurity/modsecurity.conf SecRuleEngine On SecRequestBodyAccess On SecRequestBodyLimit 131072 SecRequestBodyNoFilesLimit 131072 SecRequestBodyInMemoryLimit 131072 SecRequestBodyLimitAction ProcessPartial SecResponseBodyAccess Off 下载安装 OWASP Core Rule Set $ cd /tmp $ wget -O SpiderLabs-owasp-modsecurity-crs.tar.gz https://github.com/SpiderLabs/owasp-modsecurity-crs/tarball/master $ tar -zxvf SpiderLabs-owasp-modsecurity-crs.tar.gz $ cp -R SpiderLabs-owasp-modsecurity-crs-*/* /etc/modsecurity/ $ rm SpiderLabs-owasp-modsecurity-crs.tar.gz $ rm -R SpiderLabs-owasp-modsecurity-crs-* $ mv /etc/modsecurity/modsecurity_crs_10_setup.conf.example /etc/modsecurity/modsecurity_crs_10_setup.conf $ cd /etc/modsecurity/base_rules $ for f in * ; do ln -s /etc/modsecurity/base_rules/$f /etc/modsecurity/activated_rules/$f ; done $ cd /etc/modsecurity/optional_rules $ for f in * ; do ln -s /etc/modsecurity/optional_rules/$f /etc/modsecurity/activated_rules/$f ; done $ vi /etc/apache2/mods-available/mod-security.conf Include &quot;/etc/modsecurity/activated_rules/*.conf&quot; 检查 ModSecurity 是否开启并重启apache a2enmod headers a2enmod mod-security $ /etc/init.d/apache2 restart 安装ModEvasive$ apt-get install libapache2-mod-evasive 为 mod_evasive 创建log目录 $ mkdir /var/log/mod_evasive 改目录权限 $ chown www-data:www-data /var/log/mod_evasive/ // www or user 配置ModEvasive $ vi /etc/apache2/mods-available/mod-evasive.conf &lt;ifmodule mod_evasive20.c&gt; DOSHashTableSize 3097 DOSPageCount 2 DOSSiteCount 50 DOSPageInterval 1 DOSSiteInterval 1 DOSBlockingPeriod 10 DOSLogDir /var/log/mod_evasive DOSEmailNotify email@domain.com DOSWhitelist 127.0.0.1 &lt;/ifmodule&gt; 修复Mod-Evasive 邮件bug $ ln -s /etc/alternatives/mail /bin/mail/ 检查ModEvasive状态 a2enmod mod-evasive 重启apache $ /etc/init.d/apache2 restart Ubuntu 防火墙安装UFW： $ apt-get install ufw 允许SSH和HTTP服务 $ ufw allow ssh $ ufw allow http $ ufw deny 23 $ ufw default deny 打开防火墙 $ ufw enable 查看防火墙状态 $ ufw status verbose 查看iptable设置 $ iptables -L 配置UFW： $ vi /etc/ufw/before.rules 在 *filter 下加入 :ufw-http - [0:0] :ufw-http-logdrop - [0:0] 在COMMIT之前加入 ### Start HTTP ### # Enter rule -A ufw-before-input -p tcp --dport 80 -j ufw-http -A ufw-before-input -p tcp --dport 443 -j ufw-http # Limit connections per Class C -A ufw-http -p tcp --syn -m connlimit --connlimit-above 50 --connlimit-mask 24 -j ufw-http-logdrop # Limit connections per IP -A ufw-http -m state --state NEW -m recent --name conn_per_ip --set -A ufw-http -m state --state NEW -m recent --name conn_per_ip --update --seconds 10 --hitcount 20 -j ufw-http-logdrop # Limit packets per IP -A ufw-http -m recent --name pack_per_ip --set -A ufw-http -m recent --name pack_per_ip --update --seconds 1 --hitcount 20 -j ufw-http-logdrop # Finally accept -A ufw-http -j ACCEPT # Log -A ufw-http-logdrop -m limit --limit 3/min --limit-burst 10 -j LOG --log-prefix &quot;[UFW HTTP DROP] &quot; -A ufw-http-logdrop -j DROP ### End HTTP ### 防止Ping Flood 攻击，在COMMIT之前加入 -A INPUT -p icmp -m limit --limit 6/s --limit-burst 1 -j ACCEPT -A INPUT -p icmp -j DROP 关闭IPv6 $ vi /etc/default/ufw IPV6=no 重新加载ufw配置 $ ufw reload IP SpoofingIP Spoofing技术是指一种获取对计算机未经许可的访问的技术,即攻击者通过伪 IP 地址向计算机发送信息,并显示该信息来自于真实主机。 为防止IP Spoofing，编辑 $ vi /etc/host.conf 增加 order bind,hosts nospoof on PHP$ vi /etc/php5/apache2/php.ini 安全模式 safe_mode = On safe_mode_gid = On sql.safe_mode=On 如果你想限制可执行文件的目录，加入 safe_mode_include_dir = /path/to/dir safe_mode_exec_dir = /path/to/exec/dir 关闭Globals register_globals = Off 隐藏PHP信息 expose_php = Off track_errors = Off html_errors = Off 隐藏PHP的所有错误信息 display_errors = Off 关闭Functionalities： disable_functions = php_uname, getmyuid, getmypid, passthru, leak, listen, diskfreespace, tmpfile, link, ignore_user_abord, shell_exec, dl, set_time_limit, exec, system, highlight_file, source, show_source, fpaththru, virtual, posix_ctermid, posix_getcwd, posix_getegid, posix_geteuid, posix_getgid, posix_getgrgid, posix_getgrnam, posix_getgroups, posix_getlogin, posix_getpgid, posix_getpgrp, posix_getpid, posix, _getppid, posix_getpwnam, posix_getpwuid, posix_getrlimit, posix_getsid, posix_getuid, posix_isatty, posix_kill, posix_mkfifo, posix_setegid, posix_seteuid, posix_setgid, posix_setpgid, posix_setsid, posix_setuid, posix_times, posix_ttyname, posix_uname, proc_open, proc_close, proc_get_status, proc_nice, proc_terminate, phpinfo 关闭远程文件包含 allow_url_fopen = Off allow_url_include = Off 限制文件上传 file_uploads = Off 如果你需要这个上传功能，你应该限制文件大小和上传目录 upload_tmp_dir = /var/php_tmp upload_max_filezize = 2M 资源控制 max_execution_time = 10 max_input_time = 30 memory_limit = 40M 控制POST大小 post_max_size=1K 保护Sessions session.cookie_httponly = 1 session.referer_check = domain.com magic_quotes_gpc magic_quotes_gpc=Off 重启apache SuhosinSuhosin是php的保护系统。 安装suhosin $ apt-get install php5-suhosin 配置suhosin $ vi /etc/php5/conf.d/suhosin.ini 打开suhosin extension=suhosin.so 关闭session加密 suhosin.session.encrypt = Off 日志所有错误 suhosin.log.syslog=511 最大traversal，设置最深路径 suhosin.executor.include.max_traversal=4 关闭eval suhosin.executor.disable_eval=On 关闭 /e modifier suhosin.executor.disable_emodifier=On suhosin.mail.protect=2 sql错误静音 suhosin.sql.bailout_on_error=On 过滤选项 suhosin.cookie.max_vars = 2048 suhosin.get.max_array_index_length = 256 suhosin.post.max_array_index_length = 256 suhosin.post.max_totalname_length = 8192 suhosin.post.max_vars = 2048 suhosin.request.max_totalname_length = 8192 suhosin.request.max_varname_length = 256 iptables限制SSH的接入连接 下面这个例子忽略22端口在60秒内尝试超过5次连接 iptables -I INPUT -p tcp --dport 22 -i eth0 -m state --state NEW -m recent --set iptables -I INPUT -p tcp --dport 22 -i eth0 -m state --state NEW -m recent --update --seconds 60 --hitcount 5 -j DROP 使用端口碰撞 iptables -N stage1 iptables -A stage1 -m recent --remove --name knock iptables -A stage1 -p tcp --dport 3456 -m recent --set --name knock2 iptables iptables -N stage2 iptables -A stage2 -m recent --remove --name knock2 iptables -A stage2 -p tcp --dport 2345 -m recent --set --name heaven iptables iptables -N door iptables -A door -m recent --rcheck --seconds 5 --name knock2 -j stage2 iptables -A door -m recent --rcheck --seconds 5 --name knock -j stage1 iptables -A door -p tcp --dport 1234 -m recent --set --name knock iptables iptables -A INPUT -m --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp --dport 22 -m recent --rcheck --seconds 5 --name heaven -j ACCEPT iptables -A INPUT -p tcp --syn -j doo 阻止端口扫描 试图进行端口扫描的锁定一天 iptables -A INPUT -m recent --name portscan --rcheck --seconds 86400 -j DROP iptables -A FORWARD -m recent --name portscan --rcheck --seconds 86400 -j DROP iptables -A INPUT -m recent --name portscan --remove iptables -A FORWARD -m recent --name portscan --remove 把扫描者加入扫描列表并log iptables -A INPUT -p tcp -m tcp --dport 139 -m recent --name portscan --set -j LOG --log-prefix &quot;Portscan:&quot; iptables -A INPUT -p tcp -m tcp --dport 139 -m recent --name portscan --set -j DROP iptables -A FORWARD -p tcp -m tcp --dport 139 -m recent --name portscan --set -j LOG --log-prefix &quot;Portscan:&quot; iptables -A FORWARD -p tcp -m tcp --dport 139 -m recent --name portscan --set -j DROP 强制SYN包检查 iptables -A INPUT -p tcp ! --syn -m state --state NEW -j DROP drop空包 iptables -A INPUT -p tcp --tcp-flags ALL NONE -j DROP drop ping iptables -A OUTPUT -p icmp -o eth0 -j ACCEPT iptables -A INPUT -p icmp --icmp-type echo-reply -s 0/0 -i eth0 -j ACCEPT iptables -A INPUT -p icmp --icmp-type destination-unreachable -s 0/0 -i eth0 -j ACCEPT iptables -A INPUT -p icmp --icmp-type time-exceeded -s 0/0 -i eth0 -j ACCEPT iptables -A INPUT -p icmp -i eth0 -j DROP 屏蔽IP iptables -A INPUT -s 1.1.1.1 -j DROP iptables -A INPUT -s 192.168.0.0/24 -j DROP 备份规则 iptables-save &gt; /root/my.active.firewall.rules 修复规则 iptables-restore &lt; /root/my.active.firewall.rules 获取（D）D0S更多信息netstat -ntu | awk &apos;{print $5}&apos; | cut -d: -f1 | sort | uniq -c | sort -n 加固SSHSSH加固是服务器安全重要一步，所有配置都在 /etc/ssh/sshd_config $ vi /etc/ssh/sshd_config 限制用户访问 AllowUsers user1 user2 //允许 DenyUser user3 user_4 //拒绝 关闭root登录 PermitRootLogin no 在系统中所有空密码的用户禁止登录 PermitEmptyPasswords no 不允许用户设置环境变量 PermitUserEnvironment no 隐藏最后一次登录 PrintLastLog no 指定Ip可以用SSH访问 ListenAddress 1.1.1.1 只用协议2 Protocol 2 更改默认端口 Port 2345 关闭UseDNS UseDNS no 设置空闲超时时间 ClientAliveInterval 300 ClientAliveCountMax 0 关闭 .rhosts 文件 IgnoreRhosts yes RhostsAuthentication no RhostsRSAAuthentication no RSAAuthentication yes 关闭Host-Based Authentication HostbasedAuthentication no LoginGraceTime LoginGraceTime 300 MaxStartups，防止暴力脚本攻击 MaxStartups 2 关闭Forwarding AllowTcpForwarding no X11Forwarding no 严厉模式 StrictModes yes 使用TCP Wrappers sshd : 192.168.1.2 1.1.1.1 查看logs：一些重要的日志信息 /var/log/messages 系统主日志 /var/log/auth.log 验证日志 /var/log/kern.log 内核日志 /var/log/cron.log 计划任务日志 /var/log/maillog 邮件服务日志 /var/log/boot.log 系统启动日志 /var/log/mysqld.log mysql数据库服务日志 /var/log/secure 验证日志 /var/log/ufw.log 防火墙日志 /var/log/utmp 或 /var/log/wtmp 登录记录文件 用 LogWatch 分析日志 $ apt-get install logwatch libdate-manip-perl 查看报告 $ logwatch | less]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux 安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-IIS7-backup]]></title>
    <url>%2Fwindow-IIS7-backup.html</url>
    <content type="text"><![CDATA[为了快速迁移，部署服务器，需要将IIS7配置备份出来，在新的服务器上进行还原。通过appcmd命令来管理备份。 一、在IIS7+上导出所有应用程序池的方法:1%windir%\system32\inetsrv\appcmd list apppool /config /xml &gt; c:\apppools.xml 这个命令会将服务器上全部的应用程序池都导出来,但有些我们是我们不需要的,要将他们删掉.比如: DefaultAppPoolClassic .Net AppPool 如果在导入时发现同名的应用程序池已经存在,那么导入就会失败. 二、导入应用程序池的方法:1%windir%\system32\inetsrv\appcmd add apppool /in &lt; c:\apppools.xml 这样就可以将全部的应用程序池都导入到另一个服务器中了. 三、导出全部站点的方法:1%windir%\system32\inetsrv\appcmd list site /config /xml &gt; c:\sites.xml 同样,我们需要编辑sites.xml文件删除不需要的站点.如: Default Website 四、导入站点的方法:1%windir%\system32\inetsrv\appcmd add site /in &lt; c:\sites.xml 至此,导入工作完成了,看看两台服务器的IIS配置一样了吧. 五、另外,介绍下单独导出导入一个站点的方法1）导出单独应用程序池:1%windir%\system32\inetsrv\appcmd list apppool “应用程序池名称” /config /xml &gt; c:\myapppool.xml 导出的应用程序池名称 2) 导入单独应用程序池:1%windir%\system32\inetsrv\appcmd add apppool /in &lt; c:\myapppool.xml 3)导出单独站点:12%windir%\system32\inetsrv\appcmd list site “站点名称” /config /xml &gt; c:\mywebsite.xml 黄色字体的就是要导出的站点名称 4)导入单独站点:1%windir%\system32\inetsrv\appcmd add site /in &lt; c:\mywebsite.xml]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>IIS7 配置备份还原</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-2018-mster]]></title>
    <url>%2Fwindow-2018-mster.html</url>
    <content type="text"><![CDATA[有的时候我们远程希望能多个人同时进行操作，在系统默认的情况下是不能了。 所以我们要进行下设置。具体操作如下： 一、安装远程桌面服务；cmd 运行 1appwiz.cpl 添加功能 等待安装完成 二、在远程桌面会话主机配置中将”限制每个用户只能进行一个会话”的勾去掉。 三、确认自己的计算机开启了远程连接 四、限制连接数量cmd 运行 gpedit.msc， -- 本地计算机 策略 计算机配置\管理模板\Windows 组件\远程桌面服务\远程桌面会话主机\连接 限制连接数量中进行配置； 五、记得更新一下策略，使设置尽快生效。1gpupdte /force]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Win2008 R2实现多用户远程连接设置方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-hook]]></title>
    <url>%2Fsvn-hook.html</url>
    <content type="text"><![CDATA[在做版本更新的时候，需要SVN做一些自动化的事情，比如提交前自动更新；提交一些文件后关联着提交另一些。所以需要写一点自动化脚本。 1.什么是svn钩子官方说法：钩子是通过版本库事件触发，例如新版本的创建或一个未版本化属性的修改。一些钩子（叫做“pre hooks”）在事件发生前运行，可以用来报告发生了什么以及防止它发生。还有一些钩子（“post hooks”）在版本库事件之后发生，只是用来报告。每个钩子能够获得事件的足够信息，例如提出的（或完成的）版本库修改细节，还有触发事件的用户名。 svn钩子分为：服务器钩子和客户端钩子。 svn服务器钩子： 经常提到的svn hooks是一组“外挂”脚本程序，是svn提供的一组由svn事件触发的特别有用的程序。这些程序在服务器端执行，可以提供svn之外的一些附加功能。钩子可以调用批处理文件、可执行文件或者一些类似于perl、python等的脚本。 svn客户端钩子： 如果使用tortoise svn（海龟svn，常用的svn客户端），它也提供钩子机制，这些和svn hooks有本质区别，它是在本地（客户端）执行的。 2.svn服务端hooks分类9种A类-关于锁定的2种： post-lock：对文件进行加锁操作之后执行该脚本 pre-lock：对文件进行加锁操作之前执行该脚本 B类-关于解锁的2种： post-unlock：对文件进行解锁操作之后执行该脚本 pre-unlock：对文件进行解锁操作之前执行该脚本 C类-关于提交的3种： post-commit：在提交完成，成功创建版本之后执行该钩子，提交已经完成，不可更改，因此本脚本的返回值被忽略。 pre-commit：在 Subversion transaction 完毕之后，在提交之前，执行该脚本 start-commit：在客户端还没有向服务器提交数据之前，即还没有建立Subversion transaction（缩写为txn）之前，执行执行该脚本 D类-关于属性的2种： post-revprop-change：在修改 revision 属性之后，执行该脚本。因为修改稿已经完成，不可更改，因此本脚本的返回值被忽略（不过实际上的实现似乎是该脚本的正确执行与否影响属性修改） pre-revprop-change：在修改 revision 属性之前，执行该脚本 3.svn钩子脚本pre-commit脚本客户端提交前规则检查： 功能1：提交的文件名不能包含空格 功能2：提交的注释必须大于10个字符 11代表注释必须大于10个字符，因为末尾有个\n算一个字符 一个汉字代表16个字符，如果需要至少输入4个汉字，那么数字需要改成48 钩子默认变量说明：REPOS=”$1” ,表示仓库绝对路径TXN=”$2”，提交的版本号例如：/data/svn_data/sadoc 17-17 1234567891011121314151617181920212223242526272829303132333435[root@192 hooks]# cat pre-commit#!/bin/sh# PRE-COMMIT HOOKREPOS=&quot;$1&quot;TXN=&quot;$2&quot;SVNLOOK=/usr/bin/svnlook# -------------------------------------------------------------------------------------------------# count commited file numcheck=$($SVNLOOK changed -t $TXN $REPOS |awk &apos;NF!=2&#123;for(i=2;i&lt;=NF;i++)if(i!=NF)printf $i&quot; &quot;;if(i=NF)printf $i&quot;,&quot;&#125;&apos;)# compare filesif [ &quot;$check&quot; != &quot;&quot; ]then check_del=$($SVNLOOK changed -t $TXN $REPOS | awk &apos;&#123;for(i=1;i&lt;NF;i++)if($i==&quot;D&quot;)print $1&#125;&apos;) if [ &quot;$check_del&quot; == &quot;&quot; ] then echo &quot;The file name contains spaces.Please fix it and try again!.&quot; 1&gt;&amp;2 echo &quot;不允许文件名存在空格！&quot; 1&gt;&amp;2 exit 1 fifi# -------------------------------------------------------------------------------------------------# Make sure that the log message contains some text.#SVNLOOK=/usr/local/subversion-1.8.11/bin/svnlookSVNLOOK=/usr/bin/svnlookLOGMSG=`$SVNLOOK log -t &quot;$TXN&quot; &quot;$REPOS&quot; | grep &quot;[a-zA-Z0-9]&quot; | wc -c`if [ &quot;$LOGMSG&quot; -lt 11 ]; then echo &quot;Log message can&apos;t be empty! you must input more than 10 chars as comment!.&quot; 1&gt;&amp;2 echo &quot;注释必须大于10个字符！&quot; 1&gt;&amp;2 exit 1fiexit 0 post-commit 在svn客户端执行commit提交后执行改钩子脚本 实现svn提交成功后，自动发布到yd jeknins测试环境 注意，根据svn实际的路径来更改脚本的传参值，$p必须为Jenkins项目名称 12345678910111213141516171819202122232425262728293031[root@INNER-099030 hooks]# cat post-commit#!/bin/bash# Writer: 858zjc# Date: 20170523# 云顶自动发布用，SVN有提交就自动触发jenkins构建并发布到测试环境# 每个一级子目录代表一个项目REPOS=&quot;$1&quot;REV=&quot;$2&quot;#SVNLOOK=&quot;/usr/bin/svnlook&quot;SVNLOOK=&quot;/usr/local/subversion-1.8.11/bin/svnlook&quot;CURL=&quot;/usr/bin/curl&quot;dirs=()for i in `$&#123;SVNLOOK&#125; dirs-changed -r &quot;$REV&quot; &quot;$REPOS&quot;`;do d=$(awk -F &apos;/&apos; &apos;&#123;print $2&#125;&apos; &lt;&lt;&lt; $i) # 通过调整$2列，来调整绝对路径匹配svn项目名=Jenkins项目名 dirs=(&quot;$&#123;dirs[@]&#125;&quot; &quot;$&#123;d&#125;&quot;)doneprojects=($(awk -vRS=&apos; &apos; &apos;!a[$1]++&apos; &lt;&lt;&lt; $&#123;dirs[@]&#125;))for p in &quot;$&#123;projects[@]&#125;&quot;;do $&#123;CURL&#125; -XGET &quot;http://admin:25087fe97bcf0a7ad370a7c21c8410ad@192.168.99.28:8080/job/$&#123;p&#125;/buildWithParameters?token=b6c2901e49894712ef149dc1b92b15a2&amp;cause=SVN+trigger+build&amp;deploy_server=test&quot;doneexit 0 pre-revprop-change 在修改 revision 属性之前，执行该脚本 用于svn备服务器，svn主执行svnsync init时，此钩子必须存在，可以为空。]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn hook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-submin]]></title>
    <url>%2Fsvn-submin.html</url>
    <content type="text"><![CDATA[参考文档《Submin 部署SVN服务器WEB管理端 CentOS7》http://blog.51cto.com/990487026/1974106官方网站：https://github.com/mjholtkamp/submin操作系统：CentOS7.6Subversion：1.8Apache：2.4Python：2.7 一、submin介绍1.介绍submin - 类似于svnmanager的svn用户与仓库管理的web管理平台，用python2开发的，比svnmanager轻量，部署非常容易，环境只需要python2+apache即可。数据库用sqlit3存储。 2.关于svn从备份 备份可以参考rsync svn主从备份，即备份物理数据目录：/data/svn，/etc/apache/conf.d，/data/wwwroot/svn.test.com/submin /data/wwwroot/svn.test.com/submin/conf/submin.db，这个是sqlit3的数据库备份文件，很重要，要备份。 二、submin部署1.安装submin123456yum install -y subversion-python mod_dav_svn apr-util-sqlitecd /usr/local/src/wget https://github.com/mjholtkamp/submin/archive/master.zipunzip master.zipcd submin-master/python setup.py install 2.创建svn仓库根目录123cd /data/svnmkdir -p &#123;submin_data,submin_pass,submin_log,submin_trash&#125;chown -R apache.apache ./submin* 3.交互式配置submin123456[root@localhost svn]# submin2-admin /data/wwwroot/svn.test.com/submin/ initenv 18059084323@163.com # 管理员的邮箱地址（任意），/data/wwwroot/svn.test.com/submin/ 为 submin 配置目录Which features do you want to enable? [svn, git, apache, nginx]&gt; svn, apache # 启用的特性Path to the repository? [svn]&gt; /data/svn/submin_data # svn 仓库根目录Hostname? [localhost.localdomain]&gt; 192.168.99.207 # 主机名，输入本机 ipHTTP base? [/]&gt; # http 根路径，直接回车Email from envelope? [Submin &lt;root@localhost.localdomain&gt;]&gt; 18059084323@163.com # 发送邮件时使用的邮箱地址，不需要，回车 4.submin 配置为使用 svn(默认为 git)1submin2-admin /data/wwwroot/svn.test.com/submin/ config set vcs_plugins svn 5.设置 submin web端账账户密码：admin:admin：123[root@localhost svn]# sqlite3 /data/wwwroot/svn.test.com/submin/conf/submin.dbsqlite&gt; update users set password=&quot;$apr1$IipSX7q0$9RMBxwVmSnLu18We252Ko.&quot; where name=&quot;admin&quot;;sqlite&gt; .quit 6.配置apache生成用于 apache 的配置文件1submin2-admin /data/wwwroot/svn.test.com/submin/ apacheconf create all apache2.4以上拷贝两个配置文件123cd /data/wwwroot/svn.test.com/submin/conf/cp apache-2.4-webui-cgi.conf /etc/httpd/conf.d/ # mv重命名成subversion.confcp apache-2.4-svn.conf /etc/httpd/conf.d/ 配置vhosts123456789101112131415161718192021222324252627282930313233[root@localhost conf.d]# cat subversion.confLoadModule dav_svn_module modules/mod_dav_svn.soLoadModule authz_svn_module modules/mod_authz_svn.so&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/svn.test.com&quot; ServerName svn.test.com ServerAlias svn.test.com ErrorLog &quot;/data/httplogs/svn.test.com-error.log&quot; CustomLog &quot;/data/httplogs/svn.test.com-access.log&quot; complex&lt;IfModule !mod_authn_dbd.c&gt; AliasMatch &quot;^/svn&quot; /usr/lib/python2.7/site-packages/submin/static/www/nomodauthndbd.html &lt;Location &quot;/svn&quot;&gt; Require all granted &lt;/Location&gt;&lt;/IfModule&gt;&lt;IfModule mod_authn_dbd.c&gt; DBDriver sqlite3 DBDParams &quot;/data/wwwroot/svn.test.com/submin/conf/submin.db&quot; &lt;IfModule mod_dav_svn.c&gt; &lt;Location &quot;/subsvn&quot;&gt; DAV svn SVNParentPath /data/svn/submin_data AuthType Basic AuthName &quot;Subversion repository&quot; AuthBasicProvider dbd AuthDBDUserPWQuery &quot;SELECT password FROM users WHERE name=%s&quot; AuthzSVNAccessFile /data/wwwroot/svn.test.com/submin/conf/authz Satisfy Any Require valid-user &lt;/Location&gt; &lt;/IfModule&gt;&lt;/IfModule&gt;&lt;/VirtualHost&gt; relaod12apache -tapache graceful 7.访问submin账号密码：amdin:admin]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn submin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-slave]]></title>
    <url>%2Fsvn-slave.html</url>
    <content type="text"><![CDATA[服务器信息 角色 IP svn主 192.168.99.207 svn备 192.168.99.208 一、部署思路 经过测试，将svn主的数据目录整个通过rsync物理的方式推到svn备上，svn备通过http的方式是可以正常使用svn的。 所以本实例是以rsync的方式做的svn主从备份。 1.基础环境 svn主/备：svn1.8 + apache2.4 + php5.4 + mysql5.7 + svnmanager1.10 2. MySQL svn数据库主/备：主从复制，主要是用于svnmanager记录相关用户及仓库信息。 svn从数据库：配置Read_only主要是防止svn从上误登陆往svn从的svnmanager写入数据，造成主从数据不一致。 复制结构：GTID复制 3.实时同步 实时同步主要涉及3个路径：/data/svn/，/data/wwwroot/svn.test.com/，/etc/httpd/conf.d/ 同步我这边测试环境用的是rsync + crontab，也可以换成sersync或者rsync + inotify的实时同步 如果对从库的实时性要求没那么高，可以增加crontab的同步时间，好处是对人为的误操作，有响应恢复的时间（推荐svn的从库不要做成实时的） 这三个目录可以每天再备一份到另外的一台服务器上。 123*/1 * * * * /usr/bin/rsync --delete -avzP /data/svn/ 192.168.99.208::svnsync &gt;/dev/null 2&gt;&amp;1*/1 * * * * /usr/bin/rsync --delete -avzP --exclude=&#123;index.html,svnmanager/config.php&#125; /data/wwwroot/svn.test.com/ 192.168.99.208::wwwroot &gt;/dev/null 2&gt;&amp;1*/1 * * * * /usr/bin/rsync --delete -avzP /etc/httpd/conf.d/ 192.168.99.208::httpd &gt;/dev/null 2&gt;&amp;1 4.svn备stand bysvn备两个stand by策略，目的是平时不让访问： svn备apache服务器不要启动，或者iptables封锁httpd端口 mysql配置read_only 二、故障切换切换步骤 彻底断开主的实时同步rsync，关闭rsync或sersync服务，目的是防止svn主起来后影响svn被的数据 svn备mysql关闭read only svn备开启apache或http端口，允许访问svnmanager 域名切到svn备 测试]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn master slave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-svnsync]]></title>
    <url>%2Fsvn-svnsync.html</url>
    <content type="text"><![CDATA[参考博文：https://www.cnblogs.com/zydev/p/5370512.html 测试服务器： 192.168.99.207 - 主svn 192.168.99.208 - 备份svn 一、svn主配置1.创建备份账号添加svnsync备份账号sync_user，该账号在svn主/备的所有仓库根目录的读写权限。 用户名：sync_user 密码：sync_user321 2.配置文件同步到svn备svn备上：所有其他用户只有读权限，sync_user用户有读写权限。 同步配置文件 把authz的其他用户改成只读，暂存放在/root/tdserver/svn/yd_2018/authz 1cat /data/svn_pass/yd_2018/authz | sed &apos;s/ rw/ r/g&apos; | sed &apos;/sync_user/s/ r/ rw/g&apos; &gt; /root/tdserver/svn/yd_2018/authz 同步用户配置到svn备。 123456789mkdir -p /root/svn_synccp /data/svn_passwd/authz /root/svn_synccat /data/svn_passwd/authz |sed &apos;s/ rw/ r/g&apos;| sed &apos;/sync_user/s/ r/ rw/g&apos; &gt; /root/svn_sync/authz# 同步配置文件、权限文件、服务管理脚本/usr/bin/rsync -e &apos;ssh -p 57321&apos; -avzP /root/svn_sync/authz 192.168.99.208:/data/svn_passwd//usr/bin/rsync -e &apos;ssh -p 57321&apos; -avzP /data/svn_passwd/passwd 192.168.99.208:/data/svn_passwd//usr/bin/rsync -e &apos;ssh -p 57321&apos; -avzP /data/svn_passwd/svnserve.conf 192.168.99.208:/data/svn_passwd//usr/bin/rsync -e &apos;ssh -p 57321&apos; -avzP /etc/init.d/svnserve 192.168.99.208:/etc/init.d/ 二、svn备配置1.部署svn基础环境svn的部署过程略，创建与svn主一致的空仓库。 2.svn备份机创建空库创建和主svn同名仓库，保持空，不要上传任何文件，否则会引起主从同步失败。 12svnadmin create /data/svn_data/sadocsvnadmin create /data/svn_data/sbdoc 3.配置svnsync备份用的钩子 pre-revprop-change 12345678cd /data/svn_data/sadoc/hooks/cp pre-revprop-change.tmpl pre-revprop-changechmod 755 pre-revprop-change# 前两行，第二行加个exit 0，这个钩子脚本要存在，svnsync启动时调用。可以没有内容。vim pre-revprop-change 1 #!/bin/sh 2 exit 0 三、svn主：开始svnsync备份1.svnsync初始化语法： 123svnsync init &#123;备份svn库url/库名&#125; &#123;源库url/库名&#125; svnsync init svn://192.168.99.208/sadoc svn://192.168.99.207/sadoc --username sync_user --password 123456 12345678910111213141516171819202122[root@192 hooks]# svnsync init svn://192.168.99.208/sadoc svn://192.168.99.207/sadocAuthentication realm: &lt;svn://192.168.99.207:3690&gt; f228a13e-7f01-4ded-bd0b-62835f02763cPassword for &apos;root&apos;: Authentication realm: &lt;svn://192.168.99.207:3690&gt; f228a13e-7f01-4ded-bd0b-62835f02763cUsername: sync_userPassword for &apos;sync_user&apos;: -----------------------------------------------------------------------ATTENTION! Your password for authentication realm: &lt;svn://192.168.99.207:3690&gt; f228a13e-7f01-4ded-bd0b-62835f02763ccan only be stored to disk unencrypted! You are advised to configureyour system so that Subversion can store passwords encrypted, ifpossible. See the documentation for details.You can avoid future appearances of this warning by setting the valueof the &apos;store-plaintext-passwords&apos; option to either &apos;yes&apos; or &apos;no&apos; in&apos;/root/.subversion/servers&apos;.-----------------------------------------------------------------------Store password unencrypted (yes/no)? yesCopied properties for revision 0. 2.开始备份语法：1svnsync sync &#123;备份svn库url/库名&#125; --no-auth-cache --username sync_user --password 123456 1234567891011121314151617[root@192 hooks]# svnsync sync svn://192.168.99.208/sadocTransmitting file data .Committed revision 1.Copied properties for revision 1.Transmitting file data .Committed revision 2.Copied properties for revision 2.Transmitting file data .Committed revision 3.Copied properties for revision 3.Transmitting file data ..Committed revision 4.Copied properties for revision 4.Transmitting file data .Committed revision 5.Copied properties for revision 5.Transmitting file data . 四、YD svn主从环境参考1.svn主crontab15 1 * * * /bin/sh -xv /root/tdserver/svn/sync_svn_yd2018.sh &gt; /var/log/svn/`date +\%Y\%m\%d`_sync_svn_yd2018.log 2&gt;&amp;1 2.sync_svn_yd2018.sh同步脚本1234567891011121314151617181920212223242526272829303132333435363738394041shell &gt; cat /root/tdserver/svn/sync_svn_yd2018.sh#!/bin/bash#fucntion: rsync /data/svn_data repository to 192.168.99.22.day=$(date +%Y%m%d)t=$(date +%H%M%S)TIMESTAMP=$(&quot;date +%Y-%m-%d %H:%M:%S&quot;)log=/data/svn_log/yd_2018/$&#123;day&#125;_init_sync.log# change slave authz user only have read permissions.cat /data/svn_pass/yd_2018/authz | sed &apos;s/ rw/ r/g&apos; | sed &apos;/sync_user/s/ r/ rw/g&apos; &gt; /root/tdserver/svn/yd_2018/authz/usr/bin/rsync -e &apos;ssh -p 57321&apos; -avH /root/tdserver/svn/yd_2018/authz 192.168.99.22:/data/svn_pass/yd_2018/authz/usr/bin/rsync -e &apos;ssh -p 57321&apos; -avH /data/svn_pass/yd_2018/http_users 192.168.99.22:/data/svn_pass/yd_2018/http_usersfor repo in `ls /data/svn_data/yd_2018/`do cp -rp /root/tdserver/svn/pre-revprop-change /data/svn_data/yd_2018/$&#123;repo&#125;/hooks /usr/bin/rsync -e &apos;ssh -p 57321&apos; -avH /root/tdserver/svn/pre-revprop-change 192.168.99.22:/data/svn_data/yd_2018/$&#123;repo&#125;/hooks # svnsync command. # check if repo already init,if not init,then do init then put to init_repo file. if [ -z &quot;`grep $&#123;repo&#125; /root/tdserver/svn/yd_2018/init_repo`&quot; ];then /usr/local/subversion/bin/svnsync init http://192.168.99.22:8080/yd2018/$&#123;repo&#125; http://192.168.99.30:8080/yd2018/$&#123;repo&#125; --allow-non-empty --username sync_user --password sync_user321 if [ $? -eq 0 ];then echo &quot;$&#123;repo&#125;&quot; &gt;&gt; /root/tdserver/svn/yd_2018/init_repo else echo &quot;$&#123;TIMESTAMP&#125; $&#123;repo&#125; init to 192.168.99.22 error.&quot; &gt;&gt; $&#123;log&#125; fi fi # check if repo already init,if yes init,then do synchronize to slave. if [ -n &quot;`grep $&#123;repo&#125; /root/tdserver/svn/yd_2018/init_repo`&quot; ];then /usr/local/subversion/bin/svnsync sync --steal-lock http://192.168.99.22:8080/yd2018/$&#123;repo&#125; --no-auth-cache --username sync_user --password sync_user321 if [ $? -ne 0 ];then echo &quot;$&#123;TIMESTAMP&#125; $&#123;repo&#125; sync to 192.168.99.22 error.&quot; &gt;&gt; $&#123;log&#125; else echo &quot;$&#123;TIMESTAMP&#125; $&#123;repo&#125; sync to 192.168.99.22 is ok.&quot; &gt;&gt; $&#123;log&#125; fi fidone 3.check_svn_sync.sh Nagios监控脚本 /usr/local/nagios/libexec/check_svn_sync.sh 123456789101112131415161718192021222324252627282930313233cat /usr/local/nagios/libexec/check_svn_sync.sh#!/bin/sh#function: monitor subversion master and slve synchronize.#Modify by lyc at 2018-08-15STATE_OK=0STATE_WARNING=1STATE_CRITICAL=2TIMESTAMP=`date +%Y%m%d`LOG_PATH=&quot;/data/svn_log&quot;log_dir_array=( by_2018 yd_2018)function main()&#123; for i in $&#123;log_dir_array[*]&#125; do log=$&#123;LOG_PATH&#125;/$&#123;i&#125;/$&#123;TIMESTAMP&#125;_init_sync.log echo $log if [ ! -e $&#123;log&#125; ];then echo &apos;$i have no svnsync log&apos; exit $&#123;STATE_CRITICAL&#125; elif [ `grep &apos;error&apos; $&#123;log&#125;|wc -l` -gt 0 ];then cat $&#123;log&#125; exit $&#123;STATE_CRITICAL&#125; else cat $&#123;log&#125; fi done exit $&#123;STATE_OK&#125;&#125; main]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-svnmanger]]></title>
    <url>%2Fsvn-svnmanger.html</url>
    <content type="text"><![CDATA[官网：http://svnmanager.sourceforge.net/ 软件版本1234567操作系统：CentOS7.6Subversion：1.8.19Apache:httpd-2.4.6MySQL：5.7.24PHP：5.4svnmanager：1.10VersionControl_SVN：0.3.4 一、安装php1.安装php及模块1yum install -y php php-mysql php-pear php-mbstring 配置php.ini 12# 配置时区date.timezone = &quot;Asia/Shanghai&quot; 2.配置apache + php 参考文档《Apache和PHP结合》https://blog.csdn.net/aoli_shuai/article/details/78847700 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@localhost conf]# cat httpd.confServerRoot &quot;/etc/httpd&quot;Listen 80Include conf.modules.d/*.confUser apacheGroup apacheServerAdmin root@localhostServerName svn.test.com:80 # 改这里：配置一个域名&lt;Directory /&gt; AllowOverride none Require all granted # 改这里：允许访问根目录&lt;/Directory&gt;DocumentRoot &quot;/data/wwwroot/svn.test.com&quot; # 改这里：根目录&lt;Directory &quot;/var/www&quot;&gt; AllowOverride None Require all granted&lt;/Directory&gt;&lt;Directory &quot;/var/www/html&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex index.html index.php # 改这里：增加index.php&lt;/IfModule&gt;&lt;Files &quot;.ht*&quot;&gt; Require all denied&lt;/Files&gt;ErrorLog &quot;logs/error_log&quot;LogLevel warn&lt;IfModule log_config_module&gt; LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; common &lt;IfModule logio_module&gt; LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot; %I %O&quot; combinedio &lt;/IfModule&gt; CustomLog &quot;logs/access_log&quot; combined&lt;/IfModule&gt;&lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/var/www/cgi-bin/&quot;&lt;/IfModule&gt;&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options None Require all granted&lt;/Directory&gt;&lt;IfModule mime_module&gt; TypesConfig /etc/mime.types AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType application/x-httpd-php .php # 改这里：apache调用php AddType text/html .shtml AddOutputFilter INCLUDES .shtml&lt;/IfModule&gt;AddDefaultCharset UTF-8&lt;IfModule mime_magic_module&gt; MIMEMagicFile conf/magic&lt;/IfModule&gt;EnableSendfile on 3.查看apache加载php模块12[root@localhost conf]# apachectl -M|grep php php5_module (shared) 4.phpinfo.php测试访问12345[root@localhost conf]# cat /data/wwwroot/192.168.99.207/phpinfo.php &lt;?phpphpinfo();?&gt;[root 二、安装MySQL1.安装（略）2.配置MySQL1234create database svnmanager;create user &apos;svnmanager&apos;@&apos;localhost&apos; identified by &apos;svnmanager&apos;;grant all privileges on svnmanager.* to &apos;svnmanager&apos;@&apos;localhost&apos;; flush privileges; 三、安装svnmanager1.下载svnmanager1234567891011## 部svnmanager-1.10cd /usr/local/src/wget http://prdownloads.sourceforge.net/svnmanager/svnmanager-1.10.zipunzip svnmanager-1.10.zip mv svnmanager-1.10 /data/wwwroot/192.168.99.207/svnmanager## 部署VersionControl_SVN-0.3.4.tgzwget http://download.tdtech.gao7.com/linux/tools/tarball/VersionControl_SVN-0.3.4.tgztar xvf VersionControl_SVN-0.3.4.tgz -C /data/wwwroot/192.168.99.207/svnmanager/cd /data/wwwroot/192.168.99.207/svnmanager/mv VersionControl_SVN-0.3.4 VersionControl 2.配置config.php1234567891011121314151617181920cd /data/wwwroot/192.168.99.207/svnmanager/cp config.php.linux config.php&gt;config.phpcat config.php&lt;?php$lang = &quot;en_US.UTF-8&quot;;$htpassword_cmd = &quot;/usr/bin/htpasswd&quot;;$svn_cmd = &quot;/usr/bin/svn&quot;;$svnadmin_cmd = &quot;/usr/bin/svnadmin&quot;;$svn_config_dir = &quot;/data/svn/svn_pass&quot;;$svn_repos_loc = &quot;/data/svn/svn_data&quot;;$svn_passwd_file = &quot;/data/svn/svn_pass/http_users&quot;;$svn_access_file = &quot;/data/svn/svn_pass/auth&quot;;$svn_trash_loc = &quot;/data/svn/svn_trash&quot;;$svnserve_user_file = &quot;&quot;;$smtp_server = &quot;smtp.mailserver.net&quot;;$dsn = &quot;mysqli://svnmanager:svnmanager@localhost/svnmanager&quot;;$admin_name = &quot;admin&quot;;$admin_temp_password = &quot;admin&quot;;?&gt; 3.授权站点目录12cd /data/chown -R apache.apache wwwroot 四、访问svnmanager1.访问测试1http://192.168.99.207/svnmanager/ 找不到mysql sock文件 2.配置MySQL socket软链接12mkdir -p /var/lib/mysql/ln -s /data/mysql_data_3306/mysql_3306.sock /var/lib/mysql/mysql.sock 3.再次访问测试 4.登陆初始账号：admin:admin 5.首次登陆配置 第一次用admin登陆无法创建仓库，需要再创建过另一个管理员账户，而后admin的账户被废弃 创建一个administartor:123456的超级管理员账户，而后用该账户配置用户与仓库即可。]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svnmanger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-http]]></title>
    <url>%2Fsvn-http.html</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/gne-hwz/p/8563982.html svn http访问注意点： 用http://方式访问，要配合apache的svn模块。 用http://方式访问的svn服务端的守护进程不用启动，是通过apache的svn模块来调用svn命令操作svn检入检出的。 访问方式不同，对应账户文件不同： passwd文件 - svn://方式访问 - 使用的是自带的明文账户文件 http_users文件 - http://方式访问 - 使用的是apache创建的密文账户文件 SVNPath 与 SVNParentPath 的区别 新创建的仓库根目录要记得给apache用户授权 记得添加auth文件里的用户权限及版本库权限 http方式访问的优点： http_users文件密码文件是密文 使用者使用http协议访问，更直接易懂 可以配合域名使用 服务端不用起svnserver守护进程 http方式访问的不足： http_users文件、auth文件都要手工加，配置麻烦，容易出错 需要配合svnmanage或submin前端web来管理可以解决这个问题。==转到对应的web工具文档查看部署过程== 一、安装与配置apache1.安装apache与svn模块 安装 12yum install httpd mod_dav_svn -ysystemctl enable httpd 查看版本号 123[root@localhost svn]# rpm -qa|grep httphttpd-2.4.6-88.el7.centos.x86_64httpd-tools-2.4.6-88.el7.centos.x86_64 查看svn模块 123[root@localhost svn]# ll /etc/httpd/modules/|grep svn-rwxr-xr-x. 1 root root 24200 Aug 11 2017 mod_authz_svn.so-rwxr-xr-x. 1 root root 192928 Aug 11 2017 mod_dav_svn.so 2.配置httpd.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@localhost conf]# cat httpd.confServerRoot &quot;/etc/httpd&quot;Listen 80Include conf.modules.d/*.confUser apacheGroup apacheServerAdmin root@localhostServerName svn.test.com:80 # 改这里：配置一个域名&lt;Directory /&gt; AllowOverride none Require all granted # 改这里：允许访问根目录&lt;/Directory&gt;DocumentRoot &quot;/data/wwwroot/svn.test.com&quot; # 改这里：根目录&lt;Directory &quot;/var/www&quot;&gt; AllowOverride None Require all granted&lt;/Directory&gt;&lt;Directory &quot;/var/www/html&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex index.html index.php # 改这里：增加index.php&lt;/IfModule&gt;&lt;Files &quot;.ht*&quot;&gt; Require all denied&lt;/Files&gt;ErrorLog &quot;logs/error_log&quot;LogLevel warn&lt;IfModule log_config_module&gt; LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; common &lt;IfModule logio_module&gt; LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot; %I %O&quot; combinedio &lt;/IfModule&gt; CustomLog &quot;logs/access_log&quot; combined&lt;/IfModule&gt;&lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/var/www/cgi-bin/&quot;&lt;/IfModule&gt;&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options None Require all granted&lt;/Directory&gt;&lt;IfModule mime_module&gt; TypesConfig /etc/mime.types AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType application/x-httpd-php .php # 改这里：apache调用php AddType text/html .shtml AddOutputFilter INCLUDES .shtml&lt;/IfModule&gt;AddDefaultCharset UTF-8&lt;IfModule mime_magic_module&gt; MIMEMagicFile conf/magic&lt;/IfModule&gt;EnableSendfile on 3.配置vhostsSVNPath 与 SVNParentPath 区别： SVNPath 用于只有一个项目的情况,后面加这个项目的绝对路径。此时如果在主目录下面再建新项目，则不能访问，提示没有权限，需要再单独增加一个Location SVNParentPath 通来设置所有项目的父目录，这个父目录下可以有多个项目仓库，而一条Location可以匹配所有的项目仓库。 SVNParentPath 配置匹配多个项目仓库 /usr/local/apache/conf/extra/httpd-vhosts.conf 12345678910111213141516171819[root@localhost conf.d]# cat subversion.conf LoadModule dav_svn_module modules/mod_dav_svn.soLoadModule authz_svn_module modules/mod_authz_svn.so # 两个svn模块&lt;VirtualHost *:80&gt; # 虚拟主机域名:端口号 DocumentRoot &quot;/data/wwwroot/svn.test.com&quot; # 根目录 ServerName svn.test.com ServerAlias svn.test.com ErrorLog &quot;/data/httplogs/svn.test.com-error.log&quot; CustomLog &quot;/data/httplogs/svn.test.com-access.log&quot; complex&lt;Location /svn&gt; # uri DAV svn SVNParentPath /data/svn/svn_data # 项目仓库父目录 AuthType Basic AuthName &apos;test SVN REPOSITORY&apos; AuthUserFile /data/svn/svn_pass/http_users # 用户账户文件： 所有仓库共用一套权限配置 AuthzSVNAccessFile /data/svn/svn_pass/authz # 用户账户文件： 所有仓库共用一套权限配置 Require valid-user&lt;/Location&gt;&lt;/VirtualHost&gt; 父目录结构 12345[root@localhost svn]# ll /data/svn_data/svntotal 12drwxr-xr-x. 6 www www 4096 Jan 24 15:04 test1 # 多个仓库drwxr-xr-x. 6 www www 4096 Jan 24 15:04 test2drwxr-xr-x. 6 www www 4096 Jan 24 15:04 test3 http访问 123http://192.168.100.158/svn/test1/ # 访问仓库test1http://192.168.100.158/svn/test2/http://192.168.100.158/svn/test3/ SVNPath 配置单个项目仓库 一个localtion对应一个项目仓库 SVNPath后跟具体的项目仓库的绝对路径 12345678910111213141516171819202122232425262728293031323334353637&lt;VirtualHost 192.168.100.158:80&gt; DocumentRoot &quot;/data/svn_data&quot; ServerName 192.168.100.158 ServerAlias 192.168.100.158 ErrorLog &quot;/data/httplogs/192.168.100.158-error.log&quot; CustomLog &quot;/data/httplogs/192.168.100.158-access.log&quot; complex#&lt;Location /svn/&gt;# DAV svn# #SVNPath /data/svn_data/svn/test1# SVNParentPath /data/svn_data/svn/# AuthType Basic# AuthName &apos;test SVN REPOSITORY&apos;# AuthUserFile /data/svn_pass/http_users# AuthzSVNAccessFile /data/svn_pass/authz# Require valid-user#&lt;/Location&gt;&lt;Location /svn/test1&gt; DAV svn SVNPath /data/svn_data/svn/test1 #SVNParentPath /data/svn_data/svn/ AuthType Basic AuthName &apos;test SVN REPOSITORY&apos; AuthUserFile /data/svn_pass/http_users AuthzSVNAccessFile /data/svn_pass/authz Require valid-user&lt;/Location&gt;&lt;Location /svn/test2&gt; DAV svn SVNPath /data/svn_data/svn/test2 #SVNParentPath /data/svn_data/svn/ AuthType Basic AuthName &apos;test SVN REPOSITORY&apos; AuthUserFile /data/svn_pass/http_users AuthzSVNAccessFile /data/svn_pass/authz Require valid-user&lt;/Location&gt;&lt;/VirtualHost&gt; 3.http_users文件创建账户 第一次创建 1234htpasswd -c -m /data/svn/svn_pass/http_users admin# -c 第一次使用时-c生成文件# -m md5密文 而后添加用户 1htpasswd -m /data/svn/svn_pass/http_users lyc 4.授权版本库根目录1chown -R apache.apache /data/svn/svn_data 5.apache reload123apachectl -t # 检查配置文件apachectl graceful # reload#/usr/local/apache-2.2.29/bin/httpd -k start # 启动服务 二、配置svn123456789101112131415161718192021## 创建版本库test2svnadmin create /data/svn/svn_data/test2## 配置权限authz[groups]ops_test = 1330lyc,admin,lyc # 新加的账户记得授权[/]@ops_test = rw[test:/]@ops_test = rw[test2:/] # 新加的这个版本库要记得授权@ops_test = rw[root@localhost svn_pass]# cat http_users admin:$apr1$WKnJgxtp$z55zr6KfdvmT09Tztf8/b/lyc:$apr1$sK0DIpyK$kBvV8vJV6gROebJ.K5u6O. 三、客户端http://方式访问 http://192.168.100.158/test2]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-install]]></title>
    <url>%2Fredis-install.html</url>
    <content type="text"><![CDATA[Redis官网: https://redis.io/参考博文《Redis源码编译》https://www.920430.com/archives/649a48c5.html 一、安装Redis-4.0.111.下载安装12345cd /usr/local/src/wget http://download.redis.io/releases/redis-4.0.14.tar.gztar xvf redis-4.0.14.tar.gz &amp;&amp; cd redis-4.0.14make PREFIX=/usr/local/redis-4.0.14 installcd /usr/local/ &amp;&amp; ln -s redis-4.0.14 redis 2.创建6379实例目录1234mkdir -p /usr/local/redis/&#123;var,conf&#125;mkdir -p /var/log/redismkdir -p /data/redis_data/6379mkdir -p /data/redis_log 3.拷贝配置文件12# 默认配置文件cp /usr/local/src/redis-4.0.14/redis.conf /usr/local/redis-4.0.14/conf/redis-6379.conf 4.配置启动脚本 启动脚本仅有start,stop功能 1234567cp /usr/local/src/redis-4.0.14/utils/redis_init_script /etc/init.d/redis_6379sed -i &quot;/^EXEC/s/bin/redis\/bin/g&quot; /etc/init.d/redis_6379sed -i &quot;/^CLIEXEC/s/bin/redis\/bin/g&quot; /etc/init.d/redis_6379sed -i &quot;/^CONF/s/etc\/redis\//usr\/local\/redis\/conf\/redis-/g&quot; /etc/init.d/redis_6379chmod +x /etc/init.d/redis_6379chkconfig --add redis_6379chkconfig --level 2345 redis_6379 on 5.Redis-6379.conf 配置 同时打开RDB和AOF持久化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849daemonize yespidfile /var/run/redis_6379.pidport 6379bind 0.0.0.0timeout 0loglevel noticelogfile /data/redis_log/redis-6379.logdatabases 32#save 900 1save 300 100#save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump-6379.rdbdir /data/redis_data/6379maxclients 10000maxmemory 10GBmaxmemory-policy volatile-lrumaxmemory-samples 3appendonly yesappendfsync everysecappendfilename appendonly-6379.aofno-appendfsync-on-rewrite yesauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mblua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 1024## Special encoding of small aggregate data typeshash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60slave-serve-stale-data yesslave-read-only noslave-priority 100 6.启动服务启动Redis1234# 指定配置文件启动redis服务/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-6379.conf &amp;或/etc/init.d/redis_6379 start 关闭Redis1234# 关闭redis服务,关闭指定端口的redis/usr/local/redis/bin/redis-cli -h 192.168.xx.xx -p 6379 shutdown或/etc/init.d/redis_6379 stop 二、redis-6379.log 可能遇到的警告1.net.core.somaxconn警告111268:M 12 Aug 16:11:13.026 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 原因分析 net.core.somaxconn 是linux中的一个kernel参数，表示socket监听（listen）的backlog上限。backlog是socket的监听队列，当一个请求（request）尚未被处理或建立时，他会进入backlog。而socket server可以一次性处理backlog中的所有请求，处理后的请求不再位于监听队列中。当server处理请求较慢，以至于监听队列被填满后，新来的请求会被拒绝。 所以说net.core.somaxconn限制了接收新 TCP 连接侦听队列的大小。对于一个经常处理新连接的高负载 web服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。 解决措施1234vim /etc/sysctl.conf # 增加内核参数net.core.somaxconn = 1024sysctl -p # 立即生效 2.overcommit_memory警告111268:M 12 Aug 16:11:13.026 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect. 原因分析设置内存分配策略（可选，根据服务器的实际情况进行设置）/proc/sys/vm/overcommit_memory 可选值：0、1、2： 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存注意：redis在dump数据的时候，会fork出一个子进程，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为8G，这个时候也要同样分配8G的内存给child,如果内存无法负担，往往会造成redis服务器的down机或者IO负载过高，效率下降。所以这里比较优化的内存分配策略应该设置为 1（表示内核允许分配所有的物理内存，而不管当前的内存状态如何）。 解决措施1234vim /etc/sysctl.conf # 增加内核参数vm.overcommit_memory= 1sysctl -p # 立即生效 3.transparent_hugepage警告111392:M 12 Aug 16:17:16.429 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 解决措施12# 如下配置，同时追加到/etc/rc.localecho never &gt; /sys/kernel/mm/transparent_hugepage/enabled 三、Redis 客户端连接1.linux redis-cli 连接123456# Redis主备版连接/usr/local/redis/redis-cli -h 192.168.xx.xx -p 6379/usr/local/redis/redis-cli -h 192.168.xx.xx -p 6379 -a password # 带密码登陆# Redis集群版连接/usr/local/redis/redis-cli -c -h 192.168.xx.xx -p 6379 2.telnet 连接1234567# 不带密码telnet 10.19.xx.xx 6379info# 带密码telnet 10.19.xx.xx 6379auth Xxxxxxxxxxxxxxxxxxx]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-key]]></title>
    <url>%2Fredis-key.html</url>
    <content type="text"><![CDATA[参考博文1《Redis内存满了的几种解决方法》https://blog.csdn.net/u014590757/article/details/79788076参考博文2《关于Redis数据过期策略》https://www.cnblogs.com/chenpingzhao/p/5022467.html参考博文3《为什么Redis内存不宜过大》https://blog.csdn.net/houyongqian88/article/details/53866641 Redis三种过期键删除策略 ==被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key== 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key maxmemory：当前已用内存超过maxmemory限定时，触发主动清理策略maxmemory-policy 1.被动删除被动删除介绍 被动删除的条件：1.key设置了过期时间；2.key过期了；3.key有被访问到 这种删除策略对CPU是友好的，删除操作只有在不得不的情况下才会进行，不会其他的expire key上浪费无谓的CPU时间。 但是这种策略对内存不友好，一个key已经过期，但是在它被操作之前不会被删除，仍然占据内存空间。==如果有大量的过期键存在但是又很少被访问到，那会造成大量的内存空间浪费。== 被动删除的缺点 可能存在一些key永远不会被再次访问到，这些设置了过期时间的key也是需要在过期后被删除的，我们甚至可以将这种情况看作是一种内存泄露 无用的垃圾数据占用了大量的内存，而服务器却不会自己去释放它们，这对于运行状态非常依赖于内存的Redis服务器来说，肯定不是一个好消息。 2.主动删除 hz2.1 serverCron先说一下时间事件，对于持续运行的服务器来说， 服务器需要定期对自身的资源和状态进行必要的检查和整理， 从而让服务器维持在一个健康稳定的状态， 这类操作被统称为常规操作（cron job） serverCron 实现， 它主要执行以下操作 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 对不合理的数据库进行大小调整。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主节点的话，对附属节点进行定期同步。 如果处于集群模式的话，对集群进行定期同步和连接测试。 Redis 将 serverCron 作为时间事件来运行， 从而确保它每隔一段时间就会自动运行一次， 又因为 serverCron 需要在 Redis 服务器运行期间一直定期运行， 所以它是一个循环时间事件： serverCron 会一直定期执行，直到服务器关闭为止。 在 Redis 2.6 版本中， 程序规定 serverCron 每秒运行 10 次， 平均每 100 毫秒运行一次。 从 Redis 2.8 开始， 用户可以通过修改 hz选项来调整 serverCron 的每秒执行次数。123127.0.0.1:6530&gt; config get hz1) &quot;hz&quot;2) &quot;10&quot; # 次数/秒 默认10 2.2 定期删除Redis会周期性的随机测试一批设置了过期时间的key并进行处理。测试到的已过期的key将被删除。典型的方式为,Redis每秒做10次如下的步骤： 随机测试100个设置了过期时间的key 删除所有发现的已过期的key 若删除的key超过25个则重复步骤1 ==当REDIS运行在主从模式时，只有主结点才会执行上述这两种过期删除策略，然后把删除操作”del key”同步到从结点。== 3.maxmemory3.1 动态增加内存1234567# 查看当前最大内存10.19.19.82:6530&gt; config get maxmemory1) &quot;maxmemory&quot;2) &quot;26843545600&quot; # 25G：25*1024*1024*1024# 设置成30Gconfig set maxmemory 32212254720 # 30G：30*1024*1024*1024 3.2 Redis内存淘汰策略 maxmemory-policy 当前已用内存超过maxmemory限定时，触发内存淘汰策略。默认值noeviction 当mem_used内存已经超过maxmemory的设定，对于所有的读写请求，都会触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。==所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。== 清理时会根据用户配置的maxmemory-policy来做适当的清理（一般是LRU或TTL），这里的LRU或TTL策略并不是针对redis的所有key，而是以配置文件中的maxmemory-samples个key作为样本池进行抽样清理。 maxmemory-samples在redis-3.0.0中的默认配置为5，如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间，建议： 尽量不要触发maxmemory，最好在mem_used内存占用达到maxmemory的一定比例后，需要考虑调大hz以加快淘汰，或者进行集群扩容。 如果能够控制住内存，则可以不用修改maxmemory-samples配置；如果Redis本身就作为LRU cache服务（这种服务一般长时间处于maxmemory状态，由Redis自动做LRU淘汰），可以适当调大maxmemory-samples。 关于LRU算法 LRU算法，least RecentlyUsed，最近最少使用算法。也就是说默认删除最近最少使用的键。 但是一定要注意一点！redis中并不会准确的删除所有键中最近最少使用的键，而是随机抽取3个键，删除这三个键中最近最少使用的键。 那么3这个数字也是可以设置的，对应位置是配置文件中的maxmemory-samples. 序号 规则名称 规则说明 1 ==volatile-lru== 使用LRU算法删除一个键（只对设置了生存时间的键） 2 allkeys-lru 使用LRU算法删除一个键 3 volatile-random 随机删除一个键（只对设置了生存时间的键） 4 allkeys-random 随机删除一个键 5 volatile-ttl 删除生存时间最近的一个键 6 noeviction 不删除键，只返回错误（默认） 12345678127.0.0.1:6530&gt; config get maxmemory-policy1) &quot;maxmemory-policy&quot;2) &quot;volatile-lru&quot;127.0.0.1:6530&gt; config get maxmemory-samples1) &quot;maxmemory-samples&quot;2) &quot;3&quot;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis 过期 key</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis主从]]></title>
    <url>%2Fredis-master-salve.html</url>
    <content type="text"><![CDATA[精品博文《Redis主从复制学习》https://zhuanlan.zhihu.com/p/47719810精讲Redis主从全量、增量复制的原理。 1.Redis主从复制Redis主从复制原理Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 从服务器连接主服务器，发送SYNC命令； 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； Redis主从的理解 一个Master可以有多个Slaves 默认配置下，master节点可以进行读和写，slave节点只能进行读操作，写操作被禁止 不要修改配置让slave节点支持写操作，没有意义，原因一，写入的数据不会被同步到其他节点；原因二，当master节点修改同一条数据后，slave节点的数据会被覆盖掉 slave节点挂了不影响其他slave节点的读和master节点的读和写，重新启动后会将数据从master节点同步过来 master节点挂了以后，不影响slave节点的读，Redis将不再提供写服务，master节点启动后Redis将重新对外提供写服务。 对有密码的情况说明一下，当master节点设置密码时： 客户端访问master需要密码 启动slave需要密码，在配置中进行配置即可 客户端访问slave不需要密码 2.Redis主从搭建配置文件配置123# 从库配置slaveof 192.168.xx.xx 6379 # master ip portmasterauth 123456 # 若主库有设置密码 只有写入到配置文件，重启redis,主从配置才不会丢失，建议也是用这种方式，其他方式重启，主从配置会丢失。Redis命令行配置1slaveof 192.168.xx.xx 6379 并不想重启redis服务进行主从配置Redis启动加参数1在redis-server启动命令后加上--slaveof 启动生效。 3.断开主从12# 在从库断开主从slaveof no one]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis master slave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-password]]></title>
    <url>%2Fredis-password.html</url>
    <content type="text"><![CDATA[Redis 登陆密码设置1.redis-6379.conf1requirepass &quot;xxxxxxxx&quot; 2.在线配置密码1config set requirepass &quot;xxxxxxxx&quot; 3.客户端密码登陆redis-cli12345[root@localhost conf]# /usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379127.0.0.1:6379&gt; infoNOAUTH Authentication required.127.0.0.1:6379&gt; auth xxxxxxxxOK telnet12telnet 127.0.0.1 6379auth xxxxxxxx]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis 密码设置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-慢查询]]></title>
    <url>%2Fredis-slowlog.html</url>
    <content type="text"><![CDATA[参考博文《Redis慢查询设置和查询》https://www.cnblogs.com/huamei2008/p/8850047.html 1.Redis慢查询配置1234# 动态配置config set slowlog-log-slower-than 10000 # 阀值，单位ms，0.01秒config set slowlog-max-len 128 # 日志最多存个数 128-12800config rewrite # 写到文件 2.获取慢查询队列(n指定查询条数) slowlog get n12345678910116379&gt; slowlog get n # n要获取的条数 2) 1) (integer) 15087 # id 2) (integer) 1551935311 # 时间戳 3) (integer) 11449 # 耗时 4) 1) &quot;SELECT&quot; # 命令和参数 2) &quot;1&quot; 3) 1) (integer) 15086 2) (integer) 1551935239 3) (integer) 10945 4) 1) &quot;RPOP&quot; 2) &quot;FeedbackTokenQueue:PID39_PT1_CH5&quot; 3.获取慢查询队列长度 slowlog len1210.19.47.206:6379&gt; slowlog len(integer) 128 4.清空慢查询队列 slowlog reset1slowlog reset 5.建议 slowlog-log-slower-than不要设置过大,默认是10ms,通常设置1ms slowlog-max-len不要设置过小,通常设置1000左右 理解命令生命周期 定期持久化慢查询]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis slowlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-zabbix]]></title>
    <url>%2Fredis-zabbix.html</url>
    <content type="text"><![CDATA[zabbix_version:3.0.22 1.web模板zbx_export_templates_redis.xml 2.配置文件：userparameter_redis.conf12UserParameter=redis_discovery[*],sudo /bin/sh /etc/zabbix/scripts/redis_discovery.sh $1UserParameter=redis_stats[*],sudo /bin/sh /etc/zabbix/scripts/redis_check.sh $1 $2 3.自动发现脚本：redis_discovery.sh1234567891011121314151617181920212223#!/bin/bash# Modify by lyc at 2018-12-03function redis() &#123; port=($(sudo netstat -tpln | awk -F &quot;[ :]+&quot; &apos;/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;&apos;)) printf &apos;&#123;\n&apos; printf &apos;\t&quot;data&quot;:[\n&apos; for key in $&#123;!port[@]&#125; do if [[ &quot;$&#123;#port[@]&#125;&quot; -gt 1 &amp;&amp; &quot;$&#123;key&#125;&quot; -ne &quot;$(($&#123;#port[@]&#125;-1))&quot; ]];then socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F &apos;=&apos; &apos;&#123;print $10&#125;&apos;|cut -d &apos; &apos; -f 1` printf &apos;\t &#123;\n&apos; printf &quot;\t\t\t\&quot;&#123;#REDISPORT&#125;\&quot;:\&quot;$&#123;port[$&#123;key&#125;]&#125;\&quot;&#125;,\n&quot; else [[ &quot;$&#123;key&#125;&quot; -eq &quot;(($&#123;#port[@]&#125;-1))&quot; ]] socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F &apos;=&apos; &apos;&#123;print $10&#125;&apos;|cut -d &apos; &apos; -f 1` printf &apos;\t &#123;\n&apos; printf &quot;\t\t\t\&quot;&#123;#REDISPORT&#125;\&quot;:\&quot;$&#123;port[$&#123;key&#125;]&#125;\&quot;&#125;\n&quot; fi done printf &apos;\t ]\n&apos; printf &apos;&#125;\n&apos;&#125;$1 4.监控脚本：redis_check.sh1234567891011121314151617181920#!/bin/bash# Modify by lyc at 2018-12-03port=&quot;$1&quot;item=&quot;$2&quot;function getIp()&#123; if [[ -n &quot;`grep &apos;release 7&apos; /etc/redhat-release`&quot; ]];then INNER_IP=`/sbin/ifconfig |egrep &quot;inet 192\.168|inet 10\.|inet 172\.&quot;|head -1|awk &apos;&#123;print $2&#125;&apos;` else INNER_IP=`ifconfig |egrep &quot;inet addr:192\.168\.|inet addr:10\.|inet addr:172\.&quot;|head -1|awk &apos;&#123;print $2&#125;&apos;|sed &quot;s/addr://g&quot;` fi&#125;getIpif [[ &quot;$2&quot; == &quot;maxmemory&quot; ]];then value=`(echo &quot;config get maxmemory&quot;;sleep 0.1) | sudo telnet $&#123;INNER_IP&#125; $port 2&gt;/dev/null|tail -1`else value=`(echo &quot;info&quot;;sleep 0.1) | sudo telnet $&#123;INNER_IP&#125; $port 2&gt;/dev/null| grep $item |head -1|cut -d : -f2`fiecho &quot;$value&quot;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog]]></title>
    <url>%2Frsyslog-info.html</url>
    <content type="text"><![CDATA[分享博文：https://blog.csdn.net/fishmai/article/details/51838305 一、Rsyslog1.什么是syslog服务器？ syslog服务器可以用作一个网络中的日志监控中心，所有能够通过网络来发送日志的设施（包含了Linux或Windows服务器，路由器，交换机以及其他主机）都可以把日志发送给它。 通过设置一个syslog服务器，可以将不同设施/主机发送的日志，过滤和合并到一个独立的位置，这样使得你更容易地查看和获取重要的日志消息。 2.什么是rsyslog服务器？rsyslog 作为标准的syslog守护进程，预装在了大多数的Linux发行版中。在客户端/服务器架构的配置下，rsyslog同时扮演了两种角色： 作为一个syslog服务器，rsyslog可以收集来自其他设施的日志信息； 作为一个syslog客户端，rsyslog可以将其内部的日志信息传输到远程的syslog服务器。 二、Rsyslog 常用协议1.UDP 传输协议 基于传统UDP协议进行远程日志传输，也是传统syslog使用的传输协议。 可靠性比较低，但性能损耗最少，在网络情况比较差，或者接收服务器压力比较高情况下，可能存在丢日志情况。 在对日志完整性要求不是很高，在可靠的局域网环境下可以使用。 输入模块：/lib64/rsyslog/imudp.so123# 加载输入模块，在本地UDP514端口接收日志$ModLoad imudp$UDPServerRun 514 2.TCP 传输协议 基于传统TCP协议明文传输，需要回传进行确认，可靠性比较高，但在接收服务器宕机或者两者之间网络出问题的情况下，会出现丢日志情况。 这种协议相比于UDP在可靠性方面已经好很多，并且rsyslog原生支持，配置简单。 同时针对可能丢日志情况，可以进行额外配置提高可靠性，因此使用比较广。 输入模块：/lib64/rsyslog/imtcp.so 123# 加载输入模块，在本地TCP514端口接收日志$ModLoad imtcp$InputTCPServerRun 514 3.RELP 传输协议 RELP（ReliableEvent LoggingProtocol）是基于TCP封装的可靠日志消息传输协议。 是为了解决TCP 与 UDP协议的缺点而在应用层实现的传输协议，也是三者之中最可靠的。 输入模块:/lib64/rsyslog/imrelp.so 输出模块：/lib64/rsyslog/omrelp.so 安装relp模块12345# CentOSyum install rsyslog-relp# Ubuntuapt-get install rsyslog-relp 加载relp模块1234567# 加载输出模块，使用relp输出模块向rsyslog server发送日志$ModLoad omrelpuser.* :omrelp:10.10.0.19:20514# Rsyslog Server 加载输入模块，启动TCP20514端口，监听client发送来的日志$ModLoad imrelp$InputRELPServerRun 20514]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Rsyslog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog-log]]></title>
    <url>%2Frsyslog-log.html</url>
    <content type="text"><![CDATA[架构说明 rsyslog client上应用程序的原生日志不做处理，直接通过relp协议发送到rsyslog server rsyslog server接收日志队列，通过配置tag+msg配合设施（管道）识别原生日志再写到自定义的文件中分类保存。 一、Rsyslog Client CentOS 7.6 为例 1.安装relp协议模块12345# CentOSyum install rsyslog-relp# Ubuntuapt-get install rsyslog-relp 2.配置rsyslog.conf加载模块123456789101112# 加载输出模块 omrelp$ModLoad omrelp# 加载输入模块 三选一，我这边用的是 imtcp#$ModLoad imudp#$UDPServerRun 514$ModLoad imtcp$InputTCPServerRun 514#$ModLoad imrelp#$InputRELPServerRun 514 参数优化123$SystemLogRateLimitInterval 0 # Interval 设置率计算的时间间隔，0 表示关闭$SystemLogRateLimitBurst 0 # Burst 设置该间隔内允许的日志数，0 表示关闭# $MaxMessageSize 16k # 日志最大大小，太大的值需要考虑传输协议，如 UDP 配置输入设施 这边要看应用程序生产日志配置的是什么设施，推荐使用自定义设施local0-local6 但是java log4j2模块即便配置了local3，也无法识别，生产设置走的是默认的user.notice 所以这边以user.notice为设施 禁止user.*设施生产的日志写到本地 user.*设施生产的所有级别日志发送到远端rsyslog server 123456# Log anything (except mail) of level info or higher.# Don&apos;t log private authentication messages!*.info;mail.none;authpriv.none;cron.none;user.none /var/log/messages# Save boot messages also to boot.loguser.* :omrelp:10.10.0.19:20514 3.检查语法123rsyslogd -N1或rsyslogd -f /etc/rsyslog.conf -N1 4.重启rsyslogd1systemctl restart rsyslog.service 一、Rsyslog Server Ubuntu 16.04 1.安装relp协议模块12345# CentOSyum install rsyslog-relp# Ubuntuapt-get install rsyslog-relp 2.配置rsyslog.conf加载模块加载输入模块，主要是在tcp20514端口接收日志 12345$ModLoad imrelp$InputRELPServerRun 20514$ModLoad imtcp$InputTCPServerRun 514 参数优化123456$SystemLogRateLimitInterval 0 # Interval 设置率计算的时间间隔，0 表示关闭$SystemLogRateLimitBurst 0 # Burst 设置该间隔内允许的日志数，0 表示关闭# $MaxMessageSize 16k # 日志最大大小，太大的值需要考虑传输协议，如 UDP# $InputTCPMaxSessions 1024$EscapeControlCharactersOnReceive off 3.配置/etc/rsyslog.d/50-default.conf禁止来自设施user.none的日志写到本地文件。 12#*.*;auth,authpriv.none -/var/log/syslog*.*;auth,authpriv.none;local3.none;local4.none;user.none -/var/log/syslog 4.过滤切割应用程序原生日志1Aug 14 17:05:59 xxxx xxxx 2019-08-14 17:05:59,386 [LogDataUtil.java:44][INFO]:&#123;&quot;account_info&quot;:&#123;&quot;age&quot;:&quot;&quot;,&quot;aid&quot;:&quot;yyt_201908226050558812_518&quot;,&quot;area&quot;:&quot;&quot;,&quot;gamekey&quot;:&quot;notSdk&quot;,&quot;sex&quot;:&quot;0&quot;,&quot;sid&quot;:0,&quot;uid&quot;:55397&#125;,&quot;create_time&quot;:1565773559380,&quot;device_info&quot;:&#123;&quot;device_model&quot;:&quot;&quot;,&quot;device_type&quot;:&quot;&quot;,&quot;os_info&quot;:&quot;&quot;,&quot;pt&quot;:0,&quot;uuid&quot;:&quot;&quot;&#125;,&quot;ip&quot;:&quot;220.249.166.153&quot;,&quot;log_id&quot;:&quot;06b8090e-93ee-4478-b0d2-8dc8749e41e2&quot;,&quot;log_type&quot;:&quot;register_log&quot;,&quot;role_info&quot;:&#123;&quot;job&quot;:&quot;&quot;,&quot;nickname&quot;:&quot;yyt_201908226050558812_518&quot;,&quot;role_id&quot;:55397,&quot;sex&quot;:&quot;&quot;&#125;&#125; 过滤切割/etc/rsyslog.d/gamelog-pxmbd.conf123456789101112131415161718192021222324252627# $template cocsFormat, &quot;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg%\n&quot;# $template DEBUG, &quot;/data/rsyslog/%fromhost-ip%/DEBUG_%$year%%$month%%$day%.log&quot;$template xxxx_REGISTER_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_register_%$year%%$month%%$day%.log&quot;$template xxxx_LOGIN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_login_%$year%%$month%%$day%.log&quot;$template xxxx_RESOURCE_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_resource_%$year%%$month%%$day%.log&quot;$template xxxx_PAYMENT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_payment_%$year%%$month%%$day%.log&quot;$template xxxx_ACTION_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_action_%$year%%$month%%$day%.log&quot;$template xxxx_UNKNOWN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_unknown_%$year%%$month%%$day%.log&quot;$template xxxx_BUGS_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxx_bugs_%$year%%$month%%$day%.log&quot;if $programname startswith &apos;xxxx&apos; and $msg contains &apos;register_log&apos; then ?xxxx_REGISTER_LOG&amp; stopif $programname startswith &apos;xxxx&apos; and $msg contains &apos;login_log&apos; then ?xxxx_LOGIN_LOG&amp; stopif $programname startswith &apos;xxxx&apos; and $msg contains &apos;resource_log&apos; then ?xxxx_RESOURCE_LOG&amp; stopif $programname startswith &apos;xxxx&apos; and $msg contains &apos;payment_log&apos; then ?xxxx_PAYMENT_LOG&amp; stopif $programname startswith &apos;xxxx&apos; and $msg contains &apos;action_log&apos; then ?xxxx_ACTION_LOG&amp; stopif $programname startswith &apos;xxxx&apos; then ?xxxx_BUGS_LOG&amp; stopif $programname startswith &apos;xxxx&apos; and $syslogfacility-text == &apos;user&apos; and $syslogseverity &lt;= &apos;5&apos; then ?xxxx_UNKNOWN_LOG&amp; stop 5.重启rsyslogd1234567891011# 检查语法rsyslogd -N1 # 或 rsyslogd -f /etc/rsyslog.conf -N1# 授权chown -R syslog.syslog /data/rsyslog# 重启rsyslogdsystemctl restart rsyslog.service # 开机自启动echo &apos;/etc/init.d/rsyslog start&apos; &gt;&gt; /etc/rc.local 三、Client logger命令测试client12345logger -it xxxx -p user.warning 111111111register_log111111111logger -it xxxx -p user.warning 111111111login_log111111111logger -it xxxx -p user.warning 111111111resource_log111111111logger -it xxxx -p user.warning 111111111payment_log111111111logger -it xxxx -p user.warning 111111111action_log111111111 rsyslog server123456ls-rw-r----- 1 syslog adm 72 Aug 14 15:54 xxxx_user_4_xxxx_action_20190814.log-rw-r----- 1 syslog adm 142 Aug 14 15:54 xxxx_user_4_xxxx_login_20190814.log-rw-r----- 1 syslog adm 73 Aug 14 15:54 xxxx_user_4_xxxx_payment_20190814.log-rw-r----- 1 syslog adm 74 Aug 14 15:54 xxxx_user_4_xxxx_register_20190814.log-rw-r----- 1 syslog adm 74 Aug 14 15:54 xxxx_user_4_xxxx_resource_20190814.log]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Rsyslog 日志转发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog-logger]]></title>
    <url>%2Frsyslog-logger.html</url>
    <content type="text"><![CDATA[参考博文《linux命令之logger》https://blog.51cto.com/ityunwei2017/1878576 1.logger 命令 logger 用于往系统中写入日志，他提供一个shell命令接口到syslog系统模块，还可以从命令行直接向系统日志文件写入一行信息 CentOS 默认的日志保存在 /var/log/messages中。 2.logger 语法12logger [options] [messages]关键字 选项 日志内容 options 选项 -d, --udp 使用数据报(UDP)而不是使用默认的流连接(TCP) -i, --id ==逐行记录每一次logger的进程ID== -f, --file file_name 记录特定的文件 -h, --help 显示帮助文本并退出 -n， --server 写入指定的远程syslog服务器，使用UDP代替内装式syslog的例程 -s， --stderr 输出标准错误到系统日志。 -t， --tag ==tag 指定标记记录== -u， --socket socket 写入指定的socket，而不是到内置系统日志例程。 -V, --version 显示版本信息并退出 -P， --port port_num 使用指定的UDP端口。默认的端口号是514 -p， --priority ==priority_level 指定输入消息日志级别，优先级可以是数字或者指定为 “ facility.level” 的格式==。比如：” -p local3.info “ local3 这个设备的消息级别为 info。默认级别是 “user.notice” logger -p facility.level指定日志的设施和级别。 facilityfacility 是用来定义由谁产生的日志信息：那个软件、子系统运行过程中产生的日志信息。 auth 用户授权 authpriv 授权和安全 cron 计划任务 daemon 系统守护进程 kern 与内核有关的信息 lpr 与打印服务有关的信息 mail 与电子邮件有关的信息 news 来自新闻服务器的信息 syslog 由syslog生成的信息 user ==用户的程序生成的信息，默认== ftp uucp 由uucp生成的信息 local0~7 ==用来定义本地策略== levellevel 是用来定义记录什么类型的日志信息。是应用程序产生的所有信息都把它记录到日志 文件中呢，还是只记录该应用程序的错误日志信息等等。 alert 需要立即采取动作 debug(7) 调试 info(6) 正常消息 notice(5) 正常但是要注意 warning(4) error(3) 错误状态 crit(2) 临界状态 alert(1) emerg(0) 系统不可用 3.logger 测试1client1logger -it logger_test -p user.info logger_messages_text -it -i 打印进程号1723，-t指定tag logger_test rsyslog server1234# %programname%_%syslogfacility-text%_%syslogseverity%_bdgame_unknown_%$year%%$month%%$day%.log&quot;cat logger_test_user_6_bdgame_unknown_20190814.logAug 14 15:17:59 vm10-10-0-23 logger_test[1723]: logger_messages_text 全局变量对应： $programname = -t logger_test $syslogfacility-text = facility = user $syslogseverity = level = info = 6 4.logger 测试2client如果不指定-t，tag=root 12345logger -it bdgame -p user.warning 111111111register_log111111111logger -it bdgame -p user.warning 111111111login_log111111111logger -it bdgame -p user.warning 111111111resource_log111111111logger -it bdgame -p user.warning 111111111payment_log111111111logger -it bdgame -p user.warning 111111111action_log111111111 rsyslog server123456ls-rw-r----- 1 syslog adm 72 Aug 14 15:54 xxx_user_4_xxxe_action_20190814.log-rw-r----- 1 syslog adm 142 Aug 14 15:54 xxx_user_4_xxxe_login_20190814.log-rw-r----- 1 syslog adm 73 Aug 14 15:54 xxx_user_4_xxxe_payment_20190814.log-rw-r----- 1 syslog adm 74 Aug 14 15:54 xxx_user_4_xxxe_register_20190814.log-rw-r----- 1 syslog adm 74 Aug 14 15:54 xxx_user_4_xxxe_resource_20190814.log 待解决 目前传送还是 user 用户，想用localx 来传输，继续研究…..]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Rsyslog logger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-install]]></title>
    <url>%2Fsvn-install.html</url>
    <content type="text"><![CDATA[操作系统CentOS7.6 一、部署SVN服务端RPM安装subversion 1.8.19 CentOS默认的rpm仓库安装的是1.7版本。这边通过配置RPM仓库来安装1.8版本的SVN 1.配置RPM仓库 先卸载操作系统上旧版的svn 123456cat /etc/yum.repos.d/wandisco-svn.repo[WandiscoSVN]name=Wandisco SVN Repobaseurl=http://opensource.wandisco.com/centos/7/svn-1.8/RPMS/$basearch/enabled=1gpgcheck=0 2.RPM安装12rpm -qa|grep -i subversionyum -y install subversion rpm安装超时 12345如果出现错误：** [Errno 14] curl#6 - &quot;Couldn&apos;t resolve host ...&quot;** 则添加一个域名服务器：vi /etc/resolv.conf添加一条：nameserver 8.8.8.8yum clean all 二、配置版本库test（svn://方式访问）1.创建目录结构123456789mkdir -p /data/svn/&#123;svn_data,svn_log,svn_pass,svn_trash&#125;[root@localhost svn]# lltotal 0drwxr-xr-x. 3 apache apache 31 Jan 21 16:59 svn_data # 项目版本库根目录drwxr-xr-x. 2 apache apache 6 Jan 21 15:45 svn_log # 版本库日志目录drwxr-xr-x. 3 apache apache 18 Jan 21 15:49 svn_pass # 多个版本库配置文件统一放这里drwxr-xr-x. 2 apache apache 6 Jan 21 15:45 svn_trash 2.创建版本库test12# 要在版本库根目录下创建svnadmin create /data/svn/svn_data/test 3.配置文件统一配置文件把以下3个文件拷贝到/data/svn/svn_passwd路径下，目的是多个版本间库共用用户账号与主配置文件： svnserve.conf - 版本库的主配置文件 passwd - 添加用户账户、用户密码 authz - 添加用户组、项目权限 12cp /data/svn/svn_data/conf/&#123;authz,passwd,svnserve.conf&#125; /data/svn_passwd/ # 把各个仓库下的authz,passwd文件放到一起，统一授权管理chmod 700 /data/svn/svn_passwd/&#123;authz,passwd&#125; # 使用此种手工配置的SVN用户密码是明文，用svnmanage web页面来配置的密码是密文 配置svnserve.conf1234567vim /data/svn/svn_data/conf/svnserve.conf[general]anon-access=none # 不允许匿名访问auth-access=write # 允许的可以写password-db = /data/svn/svn_passwd/passwd # 指定用户-密码的文件authz-db = /data/svn/svn_passwd/authz # 指定用户权限的文件realm = test Repo # 仓库名称 配置用户账号passwd以这种passwdsvn自带的用户账号文件来启动的，svn客户端就是以svn://192.168.100.158/test这种方式来访问服务端。 123vim /data/svn/svn_pass/passwd[users]1330lyc = 123456 配置权限authz12345678[groups]ops_test = 1330lyc,admin[/]@ops_test = rw[test:/]@ops_test = rw 4.启动SVN12345svnserve -d -r /data/svn/svn_data/ --config-file /data/svn/svn_pass/svnserve.conf# -d 后台运行# -r 版本库根目录路径# --config-file 指定启动配置文件 5.配置服务启动脚本 在svn服务启动脚本的全局环境中加入以下配置: 12shell &gt; vim /etc/init.d/svnserveOPTIONS=&quot;-r /data/svn/svn_data/ --config-file /data/svn/svn_passwd/svnserve.conf&quot; 6.服务端查看svn仓库项目下的文件123svn list --verbose file:///data/svn_data/sadoc/--verbose 打印额外的信息 三、SVN客户端（svn://方式访问）Windows客户端1234567安装：下载小乌龟svn客户端在Windows上安装,安装汉化版的语言包，全部下一步直至安装完成连接：在d盘里新建一个文件夹：svn客户端---右击：选择：svn-checkout（检出，第一次操作，只有这个） 填上刚配的服务器的地址：svn://192.168.99.207/sadoc/ checkout的地址为：d:svn客户端 (推荐用域名，不用ip）采用默认：full recursive (完全递归)输入用户名和密码：lyc1330，123456 (这时就会多出个文件夹，并且里面有.svn的隐藏文件） （能出现这一步：证明能连到服务器）在这文件夹里新建一个文档（.svn文件夹的同级目录）（当成新代码提交） ，会到上级目录（svncheckout生成的目录）：右键： ,commit(提交）查看服务器上是否提交上去：右键（svncheckout生成的目录）--&gt; TortoiseSVN ---&gt; Repo-browser Linux客户端1.checkout检出在第一次使用用checkout检出 12svn checkout svn://192.168.99.207/sadoc /data/oldgirl_svn3 --username=oldgirl --password=123456svn co svn://192.168.99.207/sadoc /data/oldgirl_svn3 --username=oldgirl --password=123456 2.commit更新文件先添加，在提交 12345svn add *svn commit -m &quot;oldgirl commit 2&quot;svn ci -m &quot;oldgirl commit 2&quot;-m tag描述，可以通过钩子来控制tag 3.update下载文件1svn update svn://192.168.99.207/sadoc /data/oldgirl_svn --username=oldgirl --password=123456]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-backup]]></title>
    <url>%2Fredis-backup.html</url>
    <content type="text"><![CDATA[分享博文《学会这15点，让你分分钟拿下Redis数据库》https://mp.weixin.qq.com/s/LUgwbgtbsciuZgExrTk3xA精品博文《关于Redis持久化》https://www.cnblogs.com/chenpingzhao/p/5158791.html Redis 持久化有两种方式： Snapshotting(SAVE快照)：RDB持久化方式是在一个特定的间隔保存某个时间点的一个数据快照。 Append-only file(AOF)：AOF（Append only file）持久化方式则会记录每一个服务器收到的写操作。数据回复时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。 ==Redis的持久化是可以禁用的，两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。== 一、RDB总结： save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有 client的请求，这种方式会阻塞所有client请求，所以不推荐使用。 另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步脏数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io操作，可能会严重影响性能。 1.RDB自动备份 redis.conf配置RDB自动备份 123456789# rdb自动备份配置save 900 1， # 900 秒内如果超过 1 个 Key 被修改，则启动快照保存。save 300 10， # 300 秒内如果超过 10 个 Key 被修改，则启动快照保存。save 60 10000， # 60 秒内如果超过 10000 个 Key 被修改，则启动快照保存。# 其他rdb备份配置stop-writes-on-bgsave-error yes # yes 备份失败停止接收数据rdbcompression yes # 开启压缩rdbchecksum yes # 开启数据校验 命令行配置RDB自动备份 123config get save # 查看配置config set save &quot;&quot; # 关闭rdbconfig set save &quot;300 100&quot; # 设置 2.SAVE,BGSAVE手动备份 SAVE命令会使用同步的方式生成RDB快照文件，这意味着在这个过程中会阻塞所有其他客户端的请求。因此不建议在生产环境使用这个命令，除非因为某种原因需要去阻止Redis使用子进程进行后台生成快照（例如调用fork(2)出错）。 BGSAVE命令使用后台的方式保存RDB文件，调用此命令后，会立刻返回OK返回码。Redis会产生一个子进程进行处理并立刻恢复对客户端的服务。在客户端我们可以使用LASTSAVE命令查看操作是否成功。 12127.0.0.1:6379&gt;SAVE # SAVE 命令表示使用主进程将当前数据库快照到 dump 文件127.0.0.1:6379&gt;BGSAVE # BGSAVE 命令表示，主进程会 fork 一个子进程来进行快照备份 123456127.0.0.1:6312&gt; lastsave(integer) 1543395804 # 查看最后一次备份的时间戳infordb_last_save_time:1543395804rdb_last_bgsave_status:ok # 备份状态 3.RDB数据恢复 如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 备份目录并重新启动服务即可 两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。 二、AOF总结RDB快照并不是很可靠。如果服务器突然Crash了，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。 原理 redis调用fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加 优点 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。 AOF日志文件是一个纯追加的文件。就算服务器突然Crash，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用redis-check-aof这个工具很简单的进行修复。 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。 AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用FLUSHALL命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。 缺点 在相同的数据集下，AOF文件的大小一般会比RDB文件大。 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。 在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。 1.AOF 自动备份 AOF备份配置 1234567appendonly yesappendfsync everysec # 指定更新日志条件，共有3个可选值： # no：表示等操作系统进行数据缓存同步到磁盘（快） # always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） # everysec：表示每秒同步一次（折衷，默认值）appendfilename appendonly-6379.aof # aof持久化备份文件，指定更新日志文件名，默认为appendonly.aof 2.AOF bgrewriteaof AOF重写配置 123no-appendfsync-on-rewrite yes # 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yesauto-aof-rewrite-percentage 100 # 如果当前的aof文件大小比起上一次rewrite的aof文件大小超过指定的百分比，则会触发重写。auto-aof-rewrite-min-size 64mb # 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。 禁用aofrewrite 1auto-aof-rewrite-percentage 0 手工执行BGREWRITEAOF 1&gt;bgrewriteaof 三、总结1.AOF 与 RDB 加载顺序服务读取文件的优先顺序不同，会按照以下优先级进行启动： 如果只配置 AOF，重启时加载 AOF 文件恢复数据 如果同时 配置了 RBD 和 AOF，启动是只加载 AOF 文件恢复数据 如果只配置 RBD，启动时将加载 dump 文件恢复数据 注意：只要配置了 AOF，但是没有 AOF 文件，这个时候启动的数据库会是空的。 2.注意：save会占用2倍的内存 上面说了RDB快照的持久化，在进行快照的时候save，fork出来进行dump操作的子进程会占用与父进程一样的内存，真正的copy-on-write，对性能的影响和内存的耗用都是比较大的。 比如机器8G内存，Redis已经使用了6G内存，这时save的话会再生成6G，变成12G，大于系统的8G。这时候会发生交换；要是虚拟内存不够则会崩溃，导致数据丢失。所以在用redis的时候一定对系统内存做好容量规划。 3.主备架构通常的设计思路是利用Replication机制来弥补aof、snapshot性能上的不足，达到了数据可持久化。 即Master上Snapshot和AOF都不做，来保证Master的读写性能 而Slave上则同时开启Snapshot和AOF来进行持久化，保证数据的安全性。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-info]]></title>
    <url>%2Fredis-info.html</url>
    <content type="text"><![CDATA[参考博文：http://www.cnblogs.com/GoogleGetZ/p/6380647.html参考博文：https://blog.csdn.net/mysqldba23/article/details/68066322 INFO 查看redis服务器配置信息 127.0.0.1:6379&gt; INFO Server区块（服务器信息）12345678910111213141516171819127.0.0.1:6379&gt; INFO # 查看当前redis服务器的配置信息# Server # 一般redis服务器信息redis_version:3.0.7 # redis服务器版本号redis_git_sha1:00000000 # Git SHA1redis_git_dirty:0 # Git dirty flagredis_build_id:83e49377821bf9fbredis_mode:standalone # 运行模式：standalone单机/cluster集群os:Linux 2.6.32-642.el6.x86_64 x86_64 # redis服务器的宿主操作系统arch_bits:64 # 架构（32或64位）multiplexing_api:epoll # redis所使用的事件处理机制gcc_version:4.4.7 # 编译redis时所使用的GCC版本process_id:3024 # 服务器进程的PIDrun_id:890ee8add83a6a593c493131f6bbe9dd573d65ba # redis服务器的随机标示符（用于sentinel和集群）tcp_port:6379 # TCP/IP监听端口uptime_in_seconds:14175 # 自redis服务器启动以来，经过的秒数uptime_in_days:0 # 自redis服务启动以来，经过的天数hz:10 # redis内部调度（进行关闭timeout的客户端，删除过期key等等）频率，程序规定serverCron每秒运行10次。lru_clock:7889513 # 以分钟为单位进行自增的时钟，用于LRU管理config_file:/usr/local/redis/etc/redis-6379.conf # 主配置文件绝对路径 Clients区块12345# Clients # 已连接客户端信息connected_clients:1 # 已连接客户端的数量（不包含通过从属服务器连接的客户端）client_longest_output_list:0 # 当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 # 当前连接的客户端当中，最大输出缓存blocked_clients:0 # 正在等待阻塞命令(BLPOP、BRPOP、BRPOPLPUSH)的客户端的数量 Memory区块123456789# Memory # 内存信息used_memory:828920 # 由Redis分配器分配的内存总量，以字节（byte）为单位used_memory_human:809.49K # 以人类可读的格式返回redis的内存消耗used_memory_rss:7741440 # 从操作系统的角度，返回redis已分配的内存量（俗称常驻集大小）used_memory_peak:828976 # redis的内存消耗峰值used_memory_peak_human:809.55K # 以人类可读的格式返回redis的内存消耗峰值used_memory_lua:36864 # lua引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:9.34 # used_memory_rss和used_memory之间的比率mem_allocator:jemalloc-3.6.0 # 在编译时指定的，redis所使用的内存分配器。可以是libc、jemalloc或者tcmallor Persistence区块（rdb和aof持久化） Redis持久化存储区块 http://my.oschina.net/davehe/blog/174662 123456789101112131415# Persistence # RDB和AOF的相关信息（Redis 持久化存储）loading:0 # 当前标识正在持久化存储的个数rdb_changes_since_last_save:3 # 离最近一次成功生成rdb文件，写入命令的个数，即有多少个写入命令没有持久化rdb_bgsave_in_progress:0 # 当前标识正在RDB异步存储rdb_last_save_time:1517827227 # RDB最后成功保存的时刻rdb_last_bgsave_status:ok # 最后bgsave（异步存储）的状态rdb_last_bgsave_time_sec:0 # 最后bgsave成功的操作时间，单位为秒rdb_current_bgsave_time_sec:-1 # 当前正在bgsave操作的时间，单位为秒aof_enabled:0 # 当前有几个AOF日志在运行aof_rewrite_in_progress:0 # 表示aof重写操作正在进行aof_rewrite_scheduled:0 # 表示完成aof重写计划的个数aof_last_rewrite_time_sec:-1 # 表示最后一次重写操作完成的时间，单位秒aof_current_rewrite_time_sec:-1 # 表示当前重写操作完成的时间，单位秒aof_last_bgrewrite_status:ok # 表示最后一次异步重写操作的状态aof_last_write_status:ok # 表示最后一次重写操作的状态 Stats区块(一般统计信息)1234567891011121314151617181920# Stats # 一般统计信息total_connections_received:7 # 运行以来连接过的客户端总数量total_commands_processed:14 # 运行以来执行过的命令的总数量instantaneous_ops_per_sec:0 # 服务器每秒执行过的命令数total_net_input_bytes:347 # 运行以来输入的字节数大小total_net_output_bytes:2213 # 运行以来输出的字节数大小instantaneous_input_kbps:0.00 # 每秒写Kbpsinstantaneous_output_kbps:0.00 # 每秒读取Kbpsrejected_connections:0 # 因为最大客户端的数量限制而被拒绝的连接请求数量sync_full:0 # 主从完全同步成功次数sync_partial_ok:0 # 主从部分同步成功次数sync_partial_err:0 # 主从部分同步失败次数expired_keys:0 # 运行以来过期被删除的key的数量evicted_keys:0 # 运行以来因为最大内存容量限制而被驱逐（evict）的key的数量keyspace_hits:0 # 查找数据库键成功的次数keyspace_misses:0 # 查找数据库键失败的次数pubsub_channels:0 # 目前被订阅的频道数量pubsub_patterns:0 # 目前被订阅的模式数量latest_fork_usec:906 # 最近一次fork（）操作耗费的毫秒数migrate_cached_sockets:0 Replication区块(主从信息) master 12345678role:master # 实例的角色，是master or slaveconnected_slaves:1 # 连接的slave实例个数slave0:ip=192.168.64.104,port=9021,state=online,offset=6713173004,lag=0 # lag从库多少秒未向主库发送REPLCONF命令master_repl_offset:6713173145 # 主从同步偏移量,此值如果和上面的offset相同说明主从一致没延迟repl_backlog_active:1 # 复制积压缓冲区是否开启repl_backlog_size:134217728 # 复制积压缓冲大小repl_backlog_first_byte_offset:6578955418 # 复制缓冲区里偏移量的大小repl_backlog_histlen:134217728 # 此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小 slave 123456789101112131415role:slave # 实例的角色，是master or slavemaster_host:192.168.64.102 # 此节点对应的master的ipmaster_port:9021 # 此节点对应的master的portmaster_link_status:up # slave端可查看它与master之间同步状态,当复制断开后表示downmaster_last_io_seconds_ago:0 # 主库多少秒未发送数据到从库?master_sync_in_progress:0 # 从服务器是否在与主服务器进行同步slave_repl_offset:6713173818 # slave复制偏移量slave_priority:100 # slave优先级slave_read_only:1 # 从库是否设置只读connected_slaves:0 # 连接的slave实例个数master_repl_offset:0repl_backlog_active:0 # 复制积压缓冲区是否开启repl_backlog_size:134217728 # 复制积压缓冲大小repl_backlog_first_byte_offset:0 # 复制缓冲区里偏移量的大小repl_backlog_histlen:0 # 此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小 CPU1234used_cpu_sys:96894.66 # 将所有redis主进程在核心态所占用的CPU时求和累计起来used_cpu_user:87397.39 # 将所有redis主进程在用户态所占用的CPU时求和累计起来used_cpu_sys_children:6.37 # 将后台进程在核心态所占用的CPU时求和累计起来used_cpu_user_children:52.83 # 将后台进程在用户态所占用的CPU时求和累计起来 Cluster(集群相关信息)12# Cluster # redis集群信息cluster_enabled:0 # 实例是否启用集群模式,0未启用 Keyspace(数据库相关的统计信息)12db0:keys=194690,expires=191702,avg_ttl=3607772262 #db0的key的数量,以及设置了过期时间的key的数,平均存活时间]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis info</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn-present]]></title>
    <url>%2Fsvn-present.html</url>
    <content type="text"><![CDATA[一、SVN介绍1.什么是SVNsvn(subversion)是版本管理工具，与CVS管理工具一样，SVN是一个跨平台的开源版本控制系统。svn版本管理工具管理着时间改变的各种数据。这些数据放置在一个中央资料档案库(repository)中，这个档案库很像一个普通的文件服务器或者FTP服务器，但是，与其他服务器不同的是，svn会备份并记录每个文件每一次的修改更新变动。这样我们就可以把任意一个时间点的档案恢复到想要的某一个旧的版本，当然也可以直接浏览指定文件的更新历史记录。 2.SVN相关站点Subversion官网： http://subversion.apache.org/ svn客户端： https://tortoisesvn.net/ 官方手册：（中英都有） http://svnbook.red-bean.com/ 3.SVN和Git的区别svn集中式版本控制系统svn版本控制系统是集中式的数据管理，存在一个中央版本库，所有开发人员本地开发所使用的代码都来自这个版本库，提交代码也都必须提交到这个中央版本库。 git分布式的版本控制git是Linus开发的，所以很自然的git和linux文件系统结合的比较紧密，以至于在windows上你必须使用cygwin才能使其完美的工作。git中没有中央版本库的说法了，凡是为了开发小组的代码共享，我们通常还是会搭建一个远程的git仓库。但是和svn不同的是，本地也包含了一个完整的git仓库，从某种程度上说本地的仓库和远程的仓库在身份上是等价的，没有主从之分。如果你的项目是闭源项目，或者你习惯于以往的集中式的管理模式的话，那么git下你也可以像svn那样工作，只是流程中可能会增加一些步骤。 二、SVN服务运行模式与访问方式SVN服务端3种运行方式 独立服务器访问：svn://svn.etiantian.org/sadoc 借助apache等http服务：http://svn.etiantian.org/sadoc 单独安装apache+svn（配置复杂） CSVN(apache+svn)是一个单独的整合软件，带web界面管理的SVN软件 本地直接访问：file://data/svn_data/sadoc SVN客户端访问方式SVN客户端可以通过多种方式访问服务器端，例如：本地磁盘访问，或各种各样不同的网络协议访问，但一个版本库地址永远都是一个URL，URL反应了访问方法： 访问方式 说明 file:// 直接通过本地磁盘或者网络磁盘访问版本库。 http:// 通过WebDAV协议访问支持Subversion的Apache服务器。 https:// 与http://相似，但是用SSL加密访问。 svn:// 通过TCP/IP自定义协议访问svnserver服务器。 svn+ssh:// 通过认证并加密的TCP/IP自定义协议访问svnserver服务器。 三、SVN档案库数据格式svn存储版本数据有2种方式：DBD（一种事物安全型表类型）和FSFS（一种不需要数据库的存储系统）。因为DBD方式在服务器中断时，有可能锁住数据，所以还是FSFS方式更安全一点。 DBD伯克利DB，版本库可以使用的一种经过充分测试的后台数据库实现，不能再通过网络共享的文件系统上使用，伯克利DB是Subversion1.2版本以前的缺省版本库格式。 FSFSFSFS是一个专用于Subversion版本库的文件系统后端，可以使用网络文件系统（例如NFS或SMBFS）。是1.2版本及其后的缺省版本库格式。 SVN是基于关系数据库的（BerkleyDB）或一系列二进制文件的（FS_FS）。一方面这解决了许多问题（例如，并行读写共享文件）以及添加了许多新功能（例如运行时的事物特性），然而另一方面，数据存储由此变得不透明，不能像ftp,samba,nfs等能看到实体文件了。]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-material-x]]></title>
    <url>%2Fhexo-material-x.html</url>
    <content type="text"><![CDATA[原先的主题 hexo-theme-snippet ，更换的原因1）有点丑。2）加载图片非常卡。现在的主题 material-x ，非常简单，也不用什么图片，访问速度快，看着比较舒服，目前看是OK的。 安装material-x123456# 1、下载主题git clone https://github.com/xaoxuu/hexo-theme-material-x themes/material-x# 2、然后安装必要的依赖包npm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less# 3、在博客配置文件中将主题修改为MaterialX 根目录下 _config.ymlthemes: material-x 遇到的坑1、增加简介1&lt;!-- more --&gt; 就是文章都要写个介绍，不然他会整篇文章显示出来很丑。 2、leancloud评论的1234# 需要把key 改到 根目录下 _config.ymlleancloud: app_id: xxxx app_key: xxxx 3、独立页面12345678910111213141516关于页面 source/about/index.md分类页面 source/categories/index.md标签页面 source/tags/index.md列表页面 source/mylist/index.md...## 都要自己在source 下面创建相应的目录## 然后在去修改主题下面的配置文件- name: 分类 icon: fas fa-code-branch url: categories/- name: 友链 icon: fas fa-link url: friends/ rel: nofollow 目前遇到这些坑，还有很多细节要调整，记录下20190914，更换博客主题。]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>material-x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks]]></title>
    <url>%2FShadowsocks.html</url>
    <content type="text"><![CDATA[参考网站1https://teddysun.com/342.html Shadowsocks 主要用于翻墙、配置境外服务器。 Shadowsocks for Windows 客户端下载： 1https://github.com/shadowsocks/shadowsocks-windows/releases 使用方法： 使用root用户登录，运行以下命令： 123wget --no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log. 安装完成后，脚本提示如下： 12345678Congratulations, Shadowsocks-python server install completed!Your Server IP :your_server_ipYour Server Port :your_server_portYour Password :your_passwordYour Encryption Method:your_encryption_methodWelcome to visit:https://teddysun.com/342.htmlEnjoy it! 卸载方法： 使用root用户登录，运行以下命令： 1./shadowsocks.sh uninstall 单用户配置文件示例 配置文件路径：/etc/shadowsocks.json 12345678910&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:your_server_port, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;your_password&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;your_encryption_method&quot;, &quot;fast_open&quot;: false&#125; 多用户多端口配置文件示例 配置文件路径：/etc/shadowsocks.json 123456789101112131415&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;8989&quot;:&quot;password0&quot;, &quot;9001&quot;:&quot;password1&quot;, &quot;9002&quot;:&quot;password2&quot;, &quot;9003&quot;:&quot;password3&quot;, &quot;9004&quot;:&quot;password4&quot; &#125;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;your_encryption_method&quot;, &quot;fast_open&quot;: false&#125; 安装脚本 python 如果有安装其他版本记得改下 python3 setup.py install –record /usr/local/shadowsocks_install.log ln -s /usr/local/python3/bin/ssserver /usr/bin/ssserver 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426#!/usr/bin/env bashPATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATH#=================================================================## System Required: CentOS 6+, Debian 7+, Ubuntu 12+ ## Description: One click Install Shadowsocks-Python server ## Author: Teddysun &lt;i@teddysun.com&gt; ## Thanks: @clowwindy &lt;https://twitter.com/clowwindy&gt; ## Intro: https://teddysun.com/342.html ##=================================================================#clearechoecho &quot;#############################################################&quot;echo &quot;# One click Install Shadowsocks-Python server #&quot;echo &quot;# Intro: https://teddysun.com/342.html #&quot;echo &quot;# Author: Teddysun &lt;i@teddysun.com&gt; #&quot;echo &quot;# Github: https://github.com/shadowsocks/shadowsocks #&quot;echo &quot;#############################################################&quot;echolibsodium_file=&quot;libsodium-1.0.15&quot;libsodium_url=&quot;https://github.com/jedisct1/libsodium/releases/download/1.0.15/libsodium-1.0.15.tar.gz&quot;# Current foldercur_dir=`pwd`# Stream Ciphersciphers=(aes-256-gcmaes-192-gcmaes-128-gcmaes-256-ctraes-192-ctraes-128-ctraes-256-cfbaes-192-cfbaes-128-cfbcamellia-128-cfbcamellia-192-cfbcamellia-256-cfbchacha20-ietf-poly1305chacha20-ietfchacha20rc4-md5)# Colorred=&apos;\033[0;31m&apos;green=&apos;\033[0;32m&apos;yellow=&apos;\033[0;33m&apos;plain=&apos;\033[0m&apos;# Make sure only root can run our script[[ $EUID -ne 0 ]] &amp;&amp; echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] This script must be run as root!&quot; &amp;&amp; exit 1# Disable selinuxdisable_selinux()&#123; if [ -s /etc/selinux/config ] &amp;&amp; grep &apos;SELINUX=enforcing&apos; /etc/selinux/config; then sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/config setenforce 0 fi&#125;#Check systemcheck_sys()&#123; local checkType=$1 local value=$2 local release=&apos;&apos; local systemPackage=&apos;&apos; if [[ -f /etc/redhat-release ]]; then release=&quot;centos&quot; systemPackage=&quot;yum&quot; elif cat /etc/issue | grep -Eqi &quot;debian&quot;; then release=&quot;debian&quot; systemPackage=&quot;apt&quot; elif cat /etc/issue | grep -Eqi &quot;ubuntu&quot;; then release=&quot;ubuntu&quot; systemPackage=&quot;apt&quot; elif cat /etc/issue | grep -Eqi &quot;centos|red hat|redhat&quot;; then release=&quot;centos&quot; systemPackage=&quot;yum&quot; elif cat /proc/version | grep -Eqi &quot;debian&quot;; then release=&quot;debian&quot; systemPackage=&quot;apt&quot; elif cat /proc/version | grep -Eqi &quot;ubuntu&quot;; then release=&quot;ubuntu&quot; systemPackage=&quot;apt&quot; elif cat /proc/version | grep -Eqi &quot;centos|red hat|redhat&quot;; then release=&quot;centos&quot; systemPackage=&quot;yum&quot; fi if [[ $&#123;checkType&#125; == &quot;sysRelease&quot; ]]; then if [ &quot;$value&quot; == &quot;$release&quot; ]; then return 0 else return 1 fi elif [[ $&#123;checkType&#125; == &quot;packageManager&quot; ]]; then if [ &quot;$value&quot; == &quot;$systemPackage&quot; ]; then return 0 else return 1 fi fi&#125;# Get versiongetversion()&#123; if [[ -s /etc/redhat-release ]]; then grep -oE &quot;[0-9.]+&quot; /etc/redhat-release else grep -oE &quot;[0-9.]+&quot; /etc/issue fi&#125;# CentOS versioncentosversion()&#123; if check_sys sysRelease centos; then local code=$1 local version=&quot;$(getversion)&quot; local main_ver=$&#123;version%%.*&#125; if [ &quot;$main_ver&quot; == &quot;$code&quot; ]; then return 0 else return 1 fi else return 1 fi&#125;# Get public IP addressget_ip()&#123; local IP=$( ip addr | egrep -o &apos;[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;&apos; | egrep -v &quot;^192\.168|^172\.1[6-9]\.|^172\.2[0-9]\.|^172\.3[0-2]\.|^10\.|^127\.|^255\.|^0\.&quot; | head -n 1 ) [ -z $&#123;IP&#125; ] &amp;&amp; IP=$( wget -qO- -t1 -T2 ipv4.icanhazip.com ) [ -z $&#123;IP&#125; ] &amp;&amp; IP=$( wget -qO- -t1 -T2 ipinfo.io/ip ) [ ! -z $&#123;IP&#125; ] &amp;&amp; echo $&#123;IP&#125; || echo&#125;get_char()&#123; SAVEDSTTY=`stty -g` stty -echo stty cbreak dd if=/dev/tty bs=1 count=1 2&gt; /dev/null stty -raw stty echo stty $SAVEDSTTY&#125;# Pre-installation settingspre_install()&#123; if check_sys packageManager yum || check_sys packageManager apt; then # Not support CentOS 5 if centosversion 5; then echo -e &quot;$[&#123;red&#125;Error$&#123;plain&#125;] Not supported CentOS 5, please change to CentOS 6+/Debian 7+/Ubuntu 12+ and try again.&quot; exit 1 fi else echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Your OS is not supported. please change OS to CentOS/Debian/Ubuntu and try again.&quot; exit 1 fi # Set shadowsocks config password echo &quot;Please enter password for shadowsocks-python&quot; read -p &quot;(Default password: teddysun.com):&quot; shadowsockspwd [ -z &quot;$&#123;shadowsockspwd&#125;&quot; ] &amp;&amp; shadowsockspwd=&quot;teddysun.com&quot; echo echo &quot;---------------------------&quot; echo &quot;password = $&#123;shadowsockspwd&#125;&quot; echo &quot;---------------------------&quot; echo # Set shadowsocks config port while true do echo &quot;Please enter a port for shadowsocks-python [1-65535]&quot; read -p &quot;(Default port: 8989):&quot; shadowsocksport [ -z &quot;$shadowsocksport&quot; ] &amp;&amp; shadowsocksport=&quot;8989&quot; expr $&#123;shadowsocksport&#125; + 1 &amp;&gt;/dev/null if [ $? -eq 0 ]; then if [ $&#123;shadowsocksport&#125; -ge 1 ] &amp;&amp; [ $&#123;shadowsocksport&#125; -le 65535 ] &amp;&amp; [ $&#123;shadowsocksport:0:1&#125; != 0 ]; then echo echo &quot;---------------------------&quot; echo &quot;port = $&#123;shadowsocksport&#125;&quot; echo &quot;---------------------------&quot; echo break fi fi echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Please enter a correct number [1-65535]&quot; done # Set shadowsocks config stream ciphers while true do echo -e &quot;Please select stream cipher for shadowsocks-python:&quot; for ((i=1;i&lt;=$&#123;#ciphers[@]&#125;;i++ )); do hint=&quot;$&#123;ciphers[$i-1]&#125;&quot; echo -e &quot;$&#123;green&#125;$&#123;i&#125;$&#123;plain&#125;) $&#123;hint&#125;&quot; done read -p &quot;Which cipher you&apos;d select(Default: $&#123;ciphers[0]&#125;):&quot; pick [ -z &quot;$pick&quot; ] &amp;&amp; pick=1 expr $&#123;pick&#125; + 1 &amp;&gt;/dev/null if [ $? -ne 0 ]; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Please enter a number&quot; continue fi if [[ &quot;$pick&quot; -lt 1 || &quot;$pick&quot; -gt $&#123;#ciphers[@]&#125; ]]; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Please enter a number between 1 and $&#123;#ciphers[@]&#125;&quot; continue fi shadowsockscipher=$&#123;ciphers[$pick-1]&#125; echo echo &quot;---------------------------&quot; echo &quot;cipher = $&#123;shadowsockscipher&#125;&quot; echo &quot;---------------------------&quot; echo break done echo echo &quot;Press any key to start...or Press Ctrl+C to cancel&quot; char=`get_char` # Install necessary dependencies if check_sys packageManager yum; then yum install -y python python-devel python-setuptools openssl openssl-devel curl wget unzip gcc automake autoconf make libtool elif check_sys packageManager apt; then apt-get -y update apt-get -y install python python-dev python-setuptools openssl libssl-dev curl wget unzip gcc automake autoconf make libtool fi cd $&#123;cur_dir&#125;&#125;# Download filesdownload_files()&#123; # Download libsodium file if ! wget --no-check-certificate -O $&#123;libsodium_file&#125;.tar.gz $&#123;libsodium_url&#125;; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Failed to download $&#123;libsodium_file&#125;.tar.gz!&quot; exit 1 fi # Download Shadowsocks file if ! wget --no-check-certificate -O shadowsocks-master.zip https://github.com/shadowsocks/shadowsocks/archive/master.zip; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Failed to download shadowsocks python file!&quot; exit 1 fi # Download Shadowsocks init script if check_sys packageManager yum; then if ! wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks -O /etc/init.d/shadowsocks; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Failed to download shadowsocks chkconfig file!&quot; exit 1 fi elif check_sys packageManager apt; then if ! wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-debian -O /etc/init.d/shadowsocks; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Failed to download shadowsocks chkconfig file!&quot; exit 1 fi fi&#125;# Config shadowsocksconfig_shadowsocks()&#123; cat &gt; /etc/shadowsocks.json&lt;&lt;-EOF&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:$&#123;shadowsocksport&#125;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;$&#123;shadowsockspwd&#125;&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;$&#123;shadowsockscipher&#125;&quot;, &quot;fast_open&quot;:false&#125;EOF&#125;# Firewall setfirewall_set()&#123; echo -e &quot;[$&#123;green&#125;Info$&#123;plain&#125;] firewall set start...&quot; if centosversion 6; then /etc/init.d/iptables status &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then iptables -L -n | grep -i $&#123;shadowsocksport&#125; &gt; /dev/null 2&gt;&amp;1 if [ $? -ne 0 ]; then iptables -I INPUT -m state --state NEW -m tcp -p tcp --dport $&#123;shadowsocksport&#125; -j ACCEPT iptables -I INPUT -m state --state NEW -m udp -p udp --dport $&#123;shadowsocksport&#125; -j ACCEPT /etc/init.d/iptables save /etc/init.d/iptables restart else echo -e &quot;[$&#123;green&#125;Info$&#123;plain&#125;] port $&#123;shadowsocksport&#125; has already been set up.&quot; fi else echo -e &quot;[$&#123;yellow&#125;Warning$&#123;plain&#125;] iptables looks like shutdown or not installed, please manually set it if necessary.&quot; fi elif centosversion 7; then systemctl status firewalld &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then firewall-cmd --permanent --zone=public --add-port=$&#123;shadowsocksport&#125;/tcp firewall-cmd --permanent --zone=public --add-port=$&#123;shadowsocksport&#125;/udp firewall-cmd --reload else echo -e &quot;[$&#123;yellow&#125;Warning$&#123;plain&#125;] firewalld looks like not running or not installed, please enable port $&#123;shadowsocksport&#125; manually if necessary.&quot; fi fi echo -e &quot;[$&#123;green&#125;Info$&#123;plain&#125;] firewall set completed...&quot;&#125;# Install Shadowsocksinstall()&#123; # Install libsodium if [ ! -f /usr/lib/libsodium.a ]; then cd $&#123;cur_dir&#125; tar zxf $&#123;libsodium_file&#125;.tar.gz cd $&#123;libsodium_file&#125; ./configure --prefix=/usr &amp;&amp; make &amp;&amp; make install if [ $? -ne 0 ]; then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] libsodium install failed!&quot; install_cleanup exit 1 fi fi ldconfig # Install Shadowsocks cd $&#123;cur_dir&#125; unzip -q shadowsocks-master.zip if [ $? -ne 0 ];then echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] unzip shadowsocks-master.zip failed! please check unzip command.&quot; install_cleanup exit 1 fi cd $&#123;cur_dir&#125;/shadowsocks-master python setup.py install --record /usr/local/shadowsocks_install.log if [ -f /usr/bin/ssserver ] || [ -f /usr/local/bin/ssserver ]; then chmod +x /etc/init.d/shadowsocks if check_sys packageManager yum; then chkconfig --add shadowsocks chkconfig shadowsocks on elif check_sys packageManager apt; then update-rc.d -f shadowsocks defaults fi /etc/init.d/shadowsocks start else echo echo -e &quot;[$&#123;red&#125;Error$&#123;plain&#125;] Shadowsocks install failed! please visit https://teddysun.com/342.html and contact.&quot; install_cleanup exit 1 fi clear echo echo -e &quot;Congratulations, Shadowsocks-python server install completed!&quot; echo -e &quot;Your Server IP : \033[41;37m $(get_ip) \033[0m&quot; echo -e &quot;Your Server Port : \033[41;37m $&#123;shadowsocksport&#125; \033[0m&quot; echo -e &quot;Your Password : \033[41;37m $&#123;shadowsockspwd&#125; \033[0m&quot; echo -e &quot;Your Encryption Method: \033[41;37m $&#123;shadowsockscipher&#125; \033[0m&quot; echo echo &quot;Welcome to visit:https://teddysun.com/342.html&quot; echo &quot;Enjoy it!&quot; echo&#125;# Install cleanupinstall_cleanup()&#123; cd $&#123;cur_dir&#125; rm -rf shadowsocks-master.zip shadowsocks-master $&#123;libsodium_file&#125;.tar.gz $&#123;libsodium_file&#125;&#125;# Uninstall Shadowsocksuninstall_shadowsocks()&#123; printf &quot;Are you sure uninstall Shadowsocks? (y/n) &quot; printf &quot;\n&quot; read -p &quot;(Default: n):&quot; answer [ -z $&#123;answer&#125; ] &amp;&amp; answer=&quot;n&quot; if [ &quot;$&#123;answer&#125;&quot; == &quot;y&quot; ] || [ &quot;$&#123;answer&#125;&quot; == &quot;Y&quot; ]; then ps -ef | grep -v grep | grep -i &quot;ssserver&quot; &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then /etc/init.d/shadowsocks stop fi if check_sys packageManager yum; then chkconfig --del shadowsocks elif check_sys packageManager apt; then update-rc.d -f shadowsocks remove fi # delete config file rm -f /etc/shadowsocks.json rm -f /var/run/shadowsocks.pid rm -f /etc/init.d/shadowsocks rm -f /var/log/shadowsocks.log if [ -f /usr/local/shadowsocks_install.log ]; then cat /usr/local/shadowsocks_install.log | xargs rm -rf fi echo &quot;Shadowsocks uninstall success!&quot; else echo echo &quot;uninstall cancelled, nothing to do...&quot; echo fi&#125;# Install Shadowsocks-pythoninstall_shadowsocks()&#123; disable_selinux pre_install download_files config_shadowsocks if check_sys packageManager yum; then firewall_set fi install install_cleanup&#125;# Initialization stepaction=$1[ -z $1 ] &amp;&amp; action=installcase &quot;$action&quot; in install|uninstall) $&#123;action&#125;_shadowsocks ;; *) echo &quot;Arguments error! [$&#123;action&#125;]&quot; echo &quot;Usage: `basename $0` [install|uninstall]&quot; ;;esac 启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#!/bin/sh# chkconfig: 2345 90 10# description: Start or stop the Shadowsocks server#### BEGIN INIT INFO# Provides: Shadowsocks# Required-Start: $network $syslog# Required-Stop: $network# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Description: Start or stop the Shadowsocks server### END INIT INFO# Author: Teddysun &lt;i@teddysun.com&gt;name=shadowsocksBIN=/usr/bin/ssserverconf=/etc/shadowsocks.jsonstart()&#123; $BIN -c $conf -d start RETVAL=$? if [ &quot;$RETVAL&quot; = &quot;0&quot; ]; then echo &quot;$name start success&quot; else echo &quot;$name start failed&quot; fi&#125;stop()&#123; pid=`ps -ef | grep -v grep | grep -v ps | grep -i &quot;$&#123;BIN&#125;&quot; | awk &apos;&#123;print $2&#125;&apos;` if [ ! -z $pid ]; then $BIN -c $conf -d stop RETVAL=$? if [ &quot;$RETVAL&quot; = &quot;0&quot; ]; then echo &quot;$name stop success&quot; else echo &quot;$name stop failed&quot; fi else echo &quot;$name is not running&quot; RETVAL=1 fi&#125;status()&#123; pid=`ps -ef | grep -v grep | grep -v ps | grep -i &quot;$&#123;BIN&#125;&quot; | awk &apos;&#123;print $2&#125;&apos;` if [ -z $pid ]; then echo &quot;$name is not running&quot; RETVAL=1 else echo &quot;$name is running with PID $pid&quot; RETVAL=0 fi&#125;case &quot;$1&quot; in&apos;start&apos;) start ;;&apos;stop&apos;) stop ;;&apos;status&apos;) status ;;&apos;restart&apos;) stop start RETVAL=$? ;;*) echo &quot;Usage: $0 &#123; start | stop | restart | status &#125;&quot; RETVAL=1 ;;esacexit $RETVALvim /usr/bin/ssserver#!/usr/bin/python# EASY-INSTALL-ENTRY-SCRIPT: &apos;shadowsocks==2.8.2&apos;,&apos;console_scripts&apos;,&apos;ssserver&apos;__requires__ = &apos;shadowsocks==2.8.2&apos;import sysfrom pkg_resources import load_entry_pointif __name__ == &apos;__main__&apos;: sys.exit( load_entry_point(&apos;shadowsocks==2.8.2&apos;, &apos;console_scripts&apos;, &apos;ssserver&apos;)() )]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-ocsp]]></title>
    <url>%2Fnginx-ocsp.html</url>
    <content type="text"><![CDATA[OCSP是更轻量级的，因为它一次只获取一条记录。但是副作用是，当连接到服务器的时候，OCSP请求必须发送到第三方响应者，这增加了延迟，以及失败的可能。实际上，OCSP响应者由CA操控，由于它常常不可靠，导致浏览器由于收不到适时的响应而失败。这减少了安全性，因为它允许攻击者对OCSP响应者进行DoS攻击来取消验证。 nginx 配置文件123456789101112ssl_dhparam /usr/local/nginx/ssl-key/dh_ssl/nginx.pem;ssl_certificate /usr/local/nginx/ssl-key/_.yd.cc/STAR.yd.cc.crt;ssl_certificate_key /usr/local/nginx/ssl-key/_.yd.cc/STAR.yd.cc.key;ssl_trusted_certificate # ocspssl_stapling on;ssl_stapling_verify on;ssl_trusted_certificate /usr/local/nginx/ssl-key/GlobalSign/chain.pem;# 国内国外 dns 不一样resolver 8.8.8.8 8.8.4.4 223.5.5.5 valid=300s;resolver_timeout 5s; 配置项 说明 ssl_dhparam123所有的nginx版本在往Diffiel-Hellman输入参数时依赖OpenSSL。不幸的时，这就意味着Ephemeral Diffiel-Hellman（DHE）会使用OpenSSL的这一缺陷，包括一个1024位的交换密钥。由于我们正在使用一个2048位的证书，DHE客户端比非ephemeral客户端将使用一个更弱的密钥交换。我们需要产生一个更强的DHE参数： 123cd /etc/ssl/certsopenssl dhparam -out dhparam.pem 4096 ssl_certificate 1网站证书 ssl_certificate_key 1证书私钥 ssl_trusted_certificate 123OCSP是更轻量级的，因为它一次只获取一条记录。但是副作用是，当连接到服务器的时候，OCSP请求必须发送到第三方响应者，这增加了延迟，以及失败的可能。实际上，OCSP响应者由CA操控，由于它常常不可靠，导致浏览器由于收不到适时的响应而失败。这减少了安全性，因为它允许攻击者对OCSP响应者进行DoS攻击来取消验证。解决方案是在TLS握手期间，允许服务器发送缓存的OCSP记录，这样来绕过OCSP响应者。这个技术节省了在客户端和OCSP响应者之间的一个来回，称为OCSP闭合（OCSP Stapling）。 检查ocsp 是否开启服务端启用 OCSP Stapling 之后，客户端还需要在建立 TLS 时，在 Client Hello 中启用 status_request 这个 TLS 扩展，告诉服务端自己希望得到 OCSP Response。目前主流浏览器都会带上 status_request，而在 openssl 中需要指定 -status 参数。完整命令如下：1$ openssl s_client -connect imququ.com:443 -status -tlsextdebug &lt; /dev/null 2&gt;&amp;1 | grep -i &quot;OCSP response&quot; 如果你的服务器上部署了多个 HTTPS 站点，可能还需要加上 -servername 参数启用 SNI：1$ openssl s_client -connect imququ.com:443 -servername imququ.com -status -tlsextdebug &lt; /dev/null 2&gt;&amp;1 | grep -i &quot;OCSP response&quot; 如果结果是下面这样，说明 OCSP Stapling 已开启：1234OCSP response:OCSP Response Data: OCSP Response Status: successful (0x0) Response Type: Basic OCSP Response 而这样显然是未开启：1OCSP response: no response sent 获取证书 OCSP Response了解如何通过 openssl 验证 OCSP Stapling 状态后，我们再来看看 OCSP Response 的完整内容，去掉前面命令中的 grep 就可以看到。例如这是本站的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ openssl s_client -connect imququ.com:443 -status -tlsextdebug &lt; /dev/null 2&gt;&amp;1OCSP response:======================================OCSP Response Data: OCSP Response Status: successful (0x0) Response Type: Basic OCSP Response Version: 1 (0x0) Responder Id: 87BAEBE8F7B12700EC9CD1A04EE0E123E57D809E Produced At: Mar 11 07:56:56 2016 GMT Responses: Certificate ID: Hash Algorithm: sha1 Issuer Name Hash: 7C8E4E54532DB74C235073AAF1CDCF2C2423F86B Issuer Key Hash: F3B5560CC409B0B4CF1FAAF9DD2356F077E8A1F9 Serial Number: 5A26 Cert Status: good This Update: Mar 11 07:56:56 2016 GMT Next Update: Mar 18 07:56:56 2016 GMT Signature Algorithm: sha1WithRSAEncryption 8a:81:d6:a5:aa:8a:92:05:6f:39:97:f5:da:d0:bc:06:86:f2: ... ...Certificate: Data: Version: 3 (0x2) Serial Number: 8 (0x8) Signature Algorithm: sha256WithRSAEncryption Issuer: C=US, O=GeoTrust Inc., CN=RapidSSL SHA256 CA - G4 Validity Not Before: Jul 10 18:18:29 2015 GMT Not After : May 22 18:18:29 2016 GMT Subject: CN=RapidSSL SHA256 CA - G4 OCSP Responder Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:9d:e9:7b:75:81:1e:00:ab:b3:b4:cc:3f:a3:2d: ... ... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Authority Key Identifier: keyid:F3:B5:56:0C:C4:09:B0:B4:CF:1F:AA:F9:DD:23:56:F0:77:E8:A1:F9 OCSP No Check: X509v3 Subject Key Identifier: 87:BA:EB:E8:F7:B1:27:00:EC:9C:D1:A0:4E:E0:E1:23:E5:7D:80:9E X509v3 Extended Key Usage: OCSP Signing X509v3 Basic Constraints: critical CA:FALSE X509v3 Key Usage: critical Digital Signature X509v3 Subject Alternative Name: DirName:/CN=TGV-C-26 Signature Algorithm: sha256WithRSAEncryption bb:ac:c3:3e:8b:20:be:a0:a7:4d:bb:e1:d1:c3:98:17:8e:58: ... ...-----BEGIN CERTIFICATE-----MIIDnTCCAoWgAwIBAgIBCDANBgkqhkiG9w0BAQsFADBHMQswCQYDVQQGEwJVUzEW... ...bmgyvaosG4GykSUnasMqfbA=-----END CERTIFICATE-----====================================== 可以看到 OCSP Response 由两部分组成：OCSP Response Data 和 Certificate。OCSP Response Data 是本站证书的验证信息；而 Certificate 则是用来验证 OCSP Response Data。本例中的 Certificate 的 Common Name 是 RapidSSL SHA256 CA - G4 OCSP Responder，可以看出它专属于 RapidSSL 的 OCSP 服务。后面我们会发现，并不是每一家 CA 的 OCSP Response 都会提供 Certificate 信息。上面这段 OCSP Response 信息是通过服务端 OCSP Stapling 获取的。下面介绍如何通过 openssl 在本地获取证书 OCSP Response。 首先需要准备好待验证网站证书链上的所有证书。证书链一般由根证书、一个或多个中间证书、站点证书组成。根证书内置在操作系统或浏览器内（Firefox），可以直接导出，或者去各大 CA 官方下载；中间证书、站点证书在建立 TLS 连接时由服务端发送，可以这样获取：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263$ openssl s_client -connect imququ.com:443 -showcerts &lt; /dev/null 2&gt;&amp;1CONNECTED(00000003)depth=2 C = US, O = GeoTrust Inc., OU = (c) 2008 GeoTrust Inc. - For authorized use only, CN = GeoTrust Primary Certification Authority - G3verify return:1depth=1 C = US, O = GeoTrust Inc., CN = RapidSSL SHA256 CA - G4verify return:1depth=0 CN = www.imququ.comverify return:1---Certificate chain 0 s:/CN=www.imququ.com i:/C=US/O=GeoTrust Inc./CN=RapidSSL SHA256 CA - G4-----BEGIN CERTIFICATE-----MIIFMDCCBBigAwIBAgICWiYwDQYJKoZIhvcNAQELBQAwRzELMAkGA1UEBhMCVVMx... ...fBv5YysJ/pgFe75P9RVALMiPUPHvH2FGI47pxlvzs5+7Gt2p-----END CERTIFICATE----- 1 s:/C=US/O=GeoTrust Inc./CN=RapidSSL SHA256 CA - G4 i:/C=US/O=GeoTrust Inc./OU=(c) 2008 GeoTrust Inc. - For authorized use only/CN=GeoTrust Primary Certification Authority - G3-----BEGIN CERTIFICATE-----MIIEpjCCA46gAwIBAgIQKByJKWYUQ4BCY1U6MkCuszANBgkqhkiG9w0BAQsFADCB... ...nPvdJAq9WZFKQgM4EnEyiHagjny7Mu+IKhvUam9QuVJni6sw+h/94ySa-----END CERTIFICATE--------Server certificatesubject=/CN=www.imququ.comissuer=/C=US/O=GeoTrust Inc./CN=RapidSSL SHA256 CA - G4---No client certificate CA names sentPeer signing digest: SHA512Server Temp Key: ECDH, P-256, 256 bits---SSL handshake has read 3460 bytes and written 434 bytes---New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256Server public key is 4096 bitSecure Renegotiation IS supportedCompression: NONEExpansion: NONENo ALPN negotiatedSSL-Session: Protocol : TLSv1.2 Cipher : ECDHE-RSA-AES128-GCM-SHA256 Session-ID: B6A0F49F6DAD0BD8AFB63F87D134FFCBC2B1487CD81440C26D165B5738A5C3EC Session-ID-ctx: Master-Key: 72871B14BC37B08F51F818285264169C512B865D13839C9B824175115F008801781FBAC64D01FC76376BCAB85E6B8F84 Key-Arg : None PSK identity: None PSK identity hint: None SRP username: None TLS session ticket lifetime hint: 86400 (seconds) TLS session ticket: 0000 - 56 f8 0d dd 0e ea 7d 0b-09 70 0b dd 52 da b7 a8 V.....&#125;..p..R... ... ... ... ... 00a0 - c2 25 af a9 46 69 64 73-69 16 ea 64 94 c7 f4 a4 .%..Fidsi..d.... Start Time: 1457861201 Timeout : 300 (sec) Verify return code: 0 (ok)---DONE 以上内容中 Certificate Chain 这一节，编号为 0 的证书是站点证书；编号为 1 的证书是中间证书。我的证书链一共是三级，服务端只需要发送两个证书，对于四级证书链，服务端就需要发送三个证书了。总之，只有根证书无需发送。 将站点证书保存为 site.pem；中间证书保存为 intermediate.pem（如果有多个中间证书，按照子证书在上的顺序保存）；再从系统中导出对应的根证书存为 root.pem。这样，证书链上的所有证书都搞定了。为了确保无误，建议再验证一下每个证书的 Common Name： 12345678$ openssl x509 -in site.pem -noout -subjectsubject= /CN=www.imququ.com$ openssl x509 -in intermediate.pem -noout -subjectsubject= /C=US/O=GeoTrust Inc./CN=RapidSSL SHA256 CA - G4$ openssl x509 -in root.pem -noout -subjectsubject= /C=US/O=GeoTrust Inc./OU=(c) 2008 GeoTrust Inc. - For authorized use only/CN=GeoTrust Primary Certification Authority - G3 接着，获取站点证书的 OCSP 服务地址：12$ openssl x509 -in site.pem -noout -ocsp_urihttp://gz.symcd.com 错误12Error querying OCSP responsder140292167403336:error:27076072:OCSP routines:PARSE_HTTP_LINE1:server response error:ocsp_ht.c:250:Code=403,Reason=Forbidden 需要参数 -header “HOST” “ocsp.int-x3.letsencrypt.org” 验证方式123openssl ocsp -no_nonce -issuer intermediate.pem -cert ../_.yd.cc/STAR.yd.cc.crt -CAfile chain.pem -text -url http://ocsp2.globalsign.com/gsdomainvalg2 -header Host ocsp2.globalsign.comopenssl ocsp -no_nonce -issuer intermediate.pem -cert ../_.app-fame.com/_.app-fame.com.crt -CAfile chain.pem -text -url http://gn.symcd.com -header Host &quot;http://gn.symcd.com&quot; HA 证书HA 证书 = 证书.cer + 证书.key ginx开启ssl_dhparam参考文档： https://weakdh.org/sysadmin.html 一般地，Nginx 会使用来自 Openssl 默认的 DHE 参数 (Ephemeral Diffie-Hellman)，其加密性能弱。我们可以在终端命令生成一个新的来代替它。12shell&gt; mkdir /etc/letsencrypt/dh_ssl &amp;&amp; cd /etc/letsencrypt/dh_sslshell&gt; openssl dhparam -out xxx.com.pem 2048]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx ocsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nexus3-docker]]></title>
    <url>%2FNexus3-docker.html</url>
    <content type="text"><![CDATA[使用nexus3.x配置docker镜像仓库及仓库代理前言我们一直使用 docker registry 作为docker的镜像仓库，但docker registry只能作为私有仓库，当需要Docker Hub 或 Google Cloud Containers 上的镜像时，我们只能自己手动pull，重新打tag，再push到docker registry上。 当需要拉取多个镜像时，这样相当麻烦，尤其是我们使用Kubespray来部署Kubernetes集群，仅仅准备镜像就需要花费很多时间。 我们希望有一个Docker仓库，能同时托管私有镜像，还能代理访问公共的镜像仓库。 正好我们在使用Nexus作为Maven的仓库，同时nexus3提供了Docker, yum, apt, npm, ruby gems, pypi 等诸多类型的仓库功能。 经过技术调研，Nexus3完全可以达到我们的预期。 注意事项Nexus3 提供了的3种类型的Docker仓库，前两者都可以创建多个仓库，最后一个则可以将他们全部聚合到一个URL来访问。 docker (hosted): 自托管 docker (proxy): 代理 docker (group): 聚合 建议为你想要创建的每个新仓库创建一个新的blob store。这样，每个仓库的数据都将位于/nexus-data中的不同文件夹中（在Docker容器内） 需要注意的重要事项：Docker repo需要2个不同的端口。我们将使用5001端口从代理仓库获取镜像，5002端口用于拉动并推送到私人仓库。 创建docker仓库1. 为了仓库数据的独立性和安全性，我们可以给每一个repository创建一个独立的Blob块存储。 Name：填写一个易于辨认的名字 Path：会自动生成并补全。默认在Nexus安装目录下面的sonatype-work/nexus3/blobs/下，也可以修改到其它目录或磁盘，甚至可以是NFS或者cephfs的目录。 分别创建三个blobs: docker-hub-hosted, docker-hub-proxy, docker-hub-group 2. 创建一个hosted类型的docker仓库Hosted类型仓库用作我们的私有仓库 点击 Repository下面的 Repositories - Create repository - docker(hosted) : Name: 输入一个简洁直观的名字 Online: 勾选。这个开关可以设置这个Docker repo是在线还是离线。 Repository Connectors 下面包含HTTP和HTTPS两种类型的port。 有什么用呢？说明讲得很清楚： 连接器允许docker客户端直接连接到docker仓库，并实现一些请求操作，如docker pull, docker push, API查询等。 因此，这里我们勾选http并且填写端口 15002， Nexus就会启动一个监听到15002端口的连接器。 Force basic authentication 勾选。这样的话就不允许匿名访问了，执行docker pull或 docker push之前，都要先登录：docker login Docker Registry API Support Docker registry默认使用的是API v2, 但是为了兼容性，我们可以勾选启用API v1。 Storage Blob store，我们下拉选择前面创建好的专用blob：docker-hub-hosted Hosted 开发环境，我们运行重复发布，因此Delpoyment policy 我们选择Allow redeploy。 3. 创建一个proxy类型的docker仓库proxy类型仓库，可以帮助我们访问不能直接到达的网络，如另一个私有仓库，或者国外的公共仓库，如Google cloud registry。 对于代理Docker hub, 官方有简要的文档可以参考Proxy Repository for Docker 点击 Repository下面的 Repositories - Create repository - docker(proxy) : Name: 输入一个简洁直观的名字 Online: 勾选。这个开关可以设置这个Docker repo是在线还是离线。 Repository Connectors: 不设置。 Proxy Remote Storage: 当配置docker hub的proxy时，这里填写: https://registry-1.docker.io Docker Index: 当配置docker hub的Docker Index时，点选Use Docker Hub或者填写：https://index.docker.io/ Storage Blob store，我们下拉选择前面创建好的专用blob：docker-hub-proxy 4. 创建一个group类型的docker仓库group类型的docker仓库，是一个聚合类型的仓库。它可以将前面我们创建的3个仓库聚合成一个URL对外提供服务，可以屏蔽后端的差异性，实现类似透明代理的功能。 点击 Repository下面的 Repositories - Create repository - docker(group) : Name: 输入一个简洁直观的名字, Online: 勾选。这个开关可以设置这个Docker repo是在线还是离线。 Repository Connectors 这里我们勾选http并且填写端口 15001， Nexus就会启动一个监听到15001端口的连接器。 Storage：选择专用的blob存储docker-hub-hosted group : 将左边选择需要添加的仓库，添加到右边的members下； 设置SSL（可选）默认情况下，Docker客户端是使用HTTPS与repo通信，但是这不是必须的。 Nexus3上SSL有两种方式Nginx反向代理和JAVA Keytool。 JAVA Keytool 这个建议参考官网的文档: Configuring SSL Nginx反向代理 使用Nginx反向代理，需要配置前面定义好的 5001和5002。 参考配置如下: upstream register_5000 { server 127.0.0.1:5001; } server { listen 15001 ssl; server_name your-repo; ssl_certificate /usr/local/nginx/conf/ssl-key/STAR.your-repo.crt; ssl_certificate_key /usr/local/nginx/conf/ssl-key/STAR.your-repo.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; large_client_header_buffers 4 32k; client_max_body_size 1000m; client_body_buffer_size 512k; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 512k; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://register_5000; proxy_read_timeout 900s; } #error_page 500 502 503 504 /50x.html; access_log /data/httplogs/your-repo-access.log weblog; error_log /data/httplogs/your-repo-error.log; } 配置客户端和项目以使用Nexus存储库1. 配置/etc/docker/daemon.json，并重启docker。 http $ vim /etc/docker/daemon.json { &quot;insecure-registries&quot;: [ &quot;http://your-repo:5001&quot;, &quot;http://your-repo:5002&quot; ], &quot;disable-legacy-registry&quot;: true } https $ vim /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [ &quot;https://your-repo:15001&quot;, &quot;https://your-repo:15002&quot; ] } 2. 登陆docker。需要登陆两次 $ docker login -u docker-user -p XXXXX https://your-repo:15001 $ docker login -u docker-user -p XXXXX https://your-repo:15002 3. 使用docker。$ docker pull your-repo:15001/rabbitmq:3.7 $ docker tag abd3fc84b335 your-repo:15002/rabbitmq:3.7 $ docker push your-repo:15002/rabbitmq:3.7 参考链接https://segmentfault.com/a/1190000015629878 https://blog.sonatype.com/using-nexus-3-as-your-repository-part-3-docker-images https://help.sonatype.com/repomanager3/private-registry-for-docker/proxy-repository-for-docker https://blog.csdn.net/sinat_31908303/article/details/79799654]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nexus3 docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nexus3]]></title>
    <url>%2FNexus3.html</url>
    <content type="text"><![CDATA[Nexus3Nexus介绍Nexus是一个强大的仓库管理器，它极大地简化了本地内部仓库的维护和外部仓库的访问。 Nexus在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷,节省外网带宽和时间，Nexus私服就可以满足这样的需要。 Nexus是一套“开箱即用”的系统不需要数据库，它使用文件系统加Lucene来组织数据。 Nexus使用ExtJS来开发界面，利用Restlet来提供完整的REST APIs，通过m2eclipse与Eclipse集成使用。 Nexus支持WebDAV与LDAP安全身份认证。 Nexus还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。 为什么要构建Nexus私服？如果没有Nexus私服，我们所需的所有构件都需要通过maven的中央仓库和第三方的Maven仓库下载到本地，而一个团队中的所有人都重复的从maven仓库下载构件无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的进程。很多情况下项目的开发都是在内网进行的，连接不到maven仓库怎么办呢？开发的公共构件怎么让其它项目使用？这个时候我们不得不为自己的团队搭建属于自己的maven私服，这样既节省了网络带宽也会加速项目搭建的进程，当然前提条件就是你的私服中拥有项目所需的所有构件。 总之，在本地构建nexus私服的好处有： 1）加速构建； 2）节省带宽； 3）节省中央仓库的带宽； 4）稳定（应付一旦中央服务器出问题的情况）； 5）控制和审计； 6）能够部署第三方构件； 7）可以建立本地内部仓库； 8）可以建立公共仓库 这些优点使得Nexus日趋成为最流行的Maven仓库管理器。 下载地址win64: https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.17.0-01-win64.zip unix: https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.17.0-01-unix.tar.gz 需要先安装JDK。且最少为JDK1.8安装服务解压文件 $ tar xf nexus-3.17.0-01-unix.tar.gz 将解压出两个目录移动到相应位置 $ mv nexus-3.17.0-01 /usr/local/nexus-3.17.0-01 $ mv sonatype-work /data/sonatype-work $ ln -s /usr/local/nexus-3.17.0-01 /usr/local/nexus 修改权限 $ sudo useradd -s /sbin/nologin nexus $ chown -R nexus:nexus /data/sonatype-work $ chown -R nexus:nexus /usr/local/nexus-3.17.0-01 修改文件最大打开数(可选) $ vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 修改配置文件 $ vim /usr/local/nexus-3.17.0-01/bin/nexus.rc #run_as_user=&quot;&quot; run_as_user=&quot;nexus&quot; $ vim /usr/local/nexus-3.17.0-01/bin/nexus.vmoptions -Xms1200M -Xmx1200M -XX:MaxDirectMemorySize=2G -XX:+UnlockDiagnosticVMOptions -XX:+UnsyncloadClass -XX:+LogVMOutput -XX:LogFile=/data/sonatype-work/nexus3/log/jvm.log -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true -Dkaraf.home=. -Dkaraf.base=. -Dkaraf.etc=etc/karaf -Djava.util.logging.config.file=etc/karaf/java.util.logging.properties -Dkaraf.data=/data/sonatype-work/nexus3 -Djava.io.tmpdir=/data/sonatype-work/nexus3/tmp -Dkaraf.startLocalConsole=false 创建启动脚本 $ vim /usr/lib/systemd/system/nexus.service [Unit] Description=nexus service After=network.target [Service] Type=forking LimitNOFILE=65536 ExecStart=/usr/local/nexus/bin/nexus start ExecStop=/usr/local/nexus/bin/nexus stop User=nexus Restart=on-abort [Install] WantedBy=multi-user.target 启动命令 $ sudo systemctl daemon-reload $ sudo systemctl enable nexus.service $ sudo systemctl start nexus.service 访问默认启动，访问的端口为 8091。 admin的初始密码可以在 $datadir(数据目录，比如/data/sonatype-work/nexus3)中找到 admin.password 参考文档https://help.sonatype.com/repomanager3 https://help.sonatype.com/repomanager3/installation/run-as-a-service https://www.cnblogs.com/kevingrace/p/6201984.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nexus3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qiniu_bucket_domain]]></title>
    <url>%2Fqiniu-bucket-domain.html</url>
    <content type="text"><![CDATA[环境需求 cdn 在腾讯云 存储在七牛云 每次配置cdn,都需要找七牛云配置源站域名绑定到相应的存储上面。 但七牛云的控制台上并没有这个信息。 只能更具API 来获取 七牛API获取 Bucket 空间域名 代码 Python2.7123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#!/usr/bin/env python# -*- coding: utf-8 -*-from qiniu import Auth# import bucketimport platformimport requests# from requests.auth import AuthBasefrom qiniu.compat import is_py2, is_py3from qiniu import configimport qiniu.auth### 版本号可能会变,https://github.com/qiniu/python-sdk/blob/master/qiniu/__init__.py 这边去确认__version__ = &apos;7.2.6&apos;_sys_info = &apos;&#123;0&#125;; &#123;1&#125;&apos;.format(platform.system(), platform.machine())_python_ver = platform.python_version()USER_AGENT = &apos;QiniuPython/&#123;0&#125; (&#123;1&#125;; ) Python/&#123;2&#125;&apos;.format( __version__, _sys_info, _python_ver)_session = None_headers = &#123;&apos;User-Agent&apos;: USER_AGENT&#125;access_key = &apos;填入ak&apos;secret_key = &apos;填入sk&apos;bucket_name = &quot;存储空间名&quot;auth = Auth(access_key, secret_key)def _get(url, params, auth): try: r = requests.get( url, params=params, auth=qiniu.auth.RequestsAuth(auth) if auth is not None else None, timeout=config.get_default(&apos;connection_timeout&apos;), headers=_headers) except Exception as e: return None, ResponseInfo(None, e) return __return_wrapper(r)def __return_wrapper(resp): if resp.status_code != 200 or resp.headers.get(&apos;X-Reqid&apos;) is None: return None, ResponseInfo(resp) resp.encoding = &apos;utf-8&apos; ret = resp.json(encoding=&apos;utf-8&apos;) if resp.text != &apos;&apos; else &#123;&#125; if ret is None: # json null ret = &#123;&#125; return ret, ResponseInfo(resp)class ResponseInfo(object): &quot;&quot;&quot;七牛HTTP请求返回信息类 该类主要是用于获取和解析对七牛发起各种请求后的响应包的header和body。 Attributes: status_code: 整数变量，响应状态码 text_body: 字符串变量，响应的body req_id: 字符串变量，七牛HTTP扩展字段，参考 http://developer.qiniu.com/docs/v6/api/reference/extended-headers.html x_log: 字符串变量，七牛HTTP扩展字段，参考 http://developer.qiniu.com/docs/v6/api/reference/extended-headers.html error: 字符串变量，响应的错误内容 &quot;&quot;&quot; def __init__(self, response, exception=None): &quot;&quot;&quot;用响应包和异常信息初始化ResponseInfo类&quot;&quot;&quot; self.__response = response self.exception = exception if response is None: self.status_code = -1 self.text_body = None self.req_id = None self.x_log = None self.error = str(exception) else: self.status_code = response.status_code self.text_body = response.text self.req_id = response.headers.get(&apos;X-Reqid&apos;) self.x_log = response.headers.get(&apos;X-Log&apos;) if self.status_code &gt;= 400: ret = response.json() if response.text != &apos;&apos; else None if ret is None or ret[&apos;error&apos;] is None: self.error = &apos;unknown&apos; else: self.error = ret[&apos;error&apos;] if self.req_id is None and self.status_code == 200: self.error = &apos;server is not qiniu&apos; def ok(self): return self.status_code == 200 and self.req_id is not None def need_retry(self): if self.__response is None or self.req_id is None: return True code = self.status_code if (code // 100 == 5 and code != 579) or code == 996: return True return False def connect_failed(self): return self.__response is None or self.req_id is None def __str__(self): if is_py2: return &apos;, &apos;.join( [&apos;%s:%s&apos; % item for item in self.__dict__.items()]).encode(&apos;utf-8&apos;) elif is_py3: return &apos;, &apos;.join([&apos;%s:%s&apos; % item for item in self.__dict__.items()]) def __repr__(self): return self.__str__()if __name__ == &quot;__main__&quot;: options = &#123; &apos;tbl&apos;: bucket_name, &#125; url = &apos;http://api.qiniu.com/v6/domain/list&apos; print(bucket_name) ret, info = _get(url, options, auth) print(info)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>七牛云 Bucket 空间域名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-disk]]></title>
    <url>%2Fwindow-disk.html</url>
    <content type="text"><![CDATA[如何在Windows Server上启用磁盘清理工具默认情况下，Windows Server2008/2008R2/2012/2012R2 中不存在磁盘清理可执行文件cleanmgr.exe和关联的磁盘清理按钮。（Win2016默认是安装了磁盘清理cleanmgr服务） 那么如何启用磁盘清理工具： 转到“程序和功能”，然后在“功能”部分中，启用/安装 “桌面体验”。 这样做的缺点是，你需要在安装后重新启动服务器，并在服务器上安装其他不需要的组件。 [推荐] - 如果你的系统不是Windows Server 2012 R2 ，那么你真正需要做的就是将服务器上已有的一些文件复制到特定的系统文件夹中(找不到可以默认全局搜一下cleanmgr) 为了使用cleanmgr.exe，你需要复制服务器上已存在的两个文件，cleanmgr.exe和cleanmgr.exe.mui。参考下表查找操作系统的文件。 Operating System Architecture File Location Windows Server 2008 R2 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.1.7600.16385_none_c9392808773cd7da\cleanmgr.exe Windows Server 2008 R2 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.1.7600.16385_en-us_b9cb6194b257cc63\cleanmgr.exe.mui Windows Server 2008 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.0.6001.18000_en-us_b9f50b71510436f2\cleanmgr.exe.mui Windows Server 2008 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.0.6001.18000_none_c962d1e515e94269\cleanmgr.exe Windows Server 2008 32-bit C:\Windows\winsxs\x86_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.0.6001.18000_en-us_5dd66fed98a6c5bc\cleanmgr.exe.mui Windows Server 2008 32-bit C:\Windows\winsxs\x86_microsoft-windows-cleanmgr_31bf3856ad364e35_6.0.6001.18000_none_6d4436615d8bd133\cleanmgr.exe Windows Server 2012 64-bit C:\Windows\WinSxS\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.2.9200.16384_none_c60dddc5e750072a\cleanmgr.exe Windows Server 2012 64-bit C:\Windows\WinSxS\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.2.9200.16384_en-us_b6a01752226afbb3\cleanmgr.exe.mui 找到文件后，将它们移动到以下位置（Server 2012非R2及更早版本）： 将Cleanmgr.exe复制 到 %systemroot%\System32. 将Cleanmgr.exe.mui复制 到 %systemroot%\System32\zh-CN. 现在可以通过 从命令提示符运行Cleanmgr.exe来启动磁盘清理工具。 注意：Windows Server 2012 R2 必须安装桌面体验。使用Powershell命令 PS&gt; Install-WindowsFeature Desktop-Experience 参考链接Disk Cleanup on Windows Server 2008 Without Installing Desktop Experience How to enable the Disk Cleanup tool on Windows Server 2008 R2 Disk Cleanup option on drive’s general properties and cleanmgr.exe is not present in Windows Server 2008 or Windows Server 2008 R2 by default)]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>磁盘清理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-base]]></title>
    <url>%2Flinux-base.html</url>
    <content type="text"><![CDATA[!参考由于之前的线上的版本是CentOS6，鉴于该系统实在老旧目前正慢慢的往CentOS7和Ubuntu16上升级。 一般如果使用云服务器，厂商都会对镜像做一些优化，不太需要我们怎么操心。 新版的系统CentOS7和Ubuntu16对比CentOS6进步不是一点点，至少烦人的Python2和Gcc版本过低问题，在这里是完全没有了。 一、SSHD调整1.1、配置文件 备份配置文件 1$ cp -pv /etc/ssh/sshd_config&#123;,.old&#125; 修改端口 12$ sed -i &quot;s/#Port 22$/Port 5831/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/Port 22$/Port 5831/g&quot; /etc/ssh/sshd_config 禁用 DNS查询 123$ -i &quot;s/#UseDNS yes/UseDNS no/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/#PubkeyAuthentication yes/PubkeyAuthentication yes/g&quot; /etc/ssh/sshd_config 密钥登陆 12345$ sed -i &quot;s/#AuthorizedKeysFile/AuthorizedKeysFile/g&quot; /etc/ssh/sshd_config# 设置ssh在接收登录请求之前是否检查用户家目录和rhosts文件的权限和所有权。这通常是必要的，因为新手经常会把自己的目录和文件设成任何人都有写权限。$ sed -i &quot;s/#StrictModes yes/StrictModes yes/g&quot; /etc/ssh/sshd_config 开启或者禁止密码登陆 1234# 建议是能用密钥，就不需要在用密码了。如果是个人用户，保存好密钥，修改好端口那么服务器正常 就不会被人从SSHD这边攻破；# 如果是独立IP的企业用户或者有堡垒机，那么在开启密码登陆的时候 应该要做好IP/权限限制$ sed -i &quot;s/#PasswordAuthentication yes/PasswordAuthentication yes/g&quot; /etc/ssh/sshd_config$$ sed -i &quot;s/PasswordAuthentication no/PasswordAuthentication yes/g&quot; /etc/ssh/sshd_config 禁止空密码 12$ sed -i &quot;s/PermitEmptyPasswords yes/PermitEmptyPasswords no/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/#PermitEmptyPasswords no/PermitEmptyPasswords no/g&quot; /etc/ssh/sshd_config 开启或者禁止root登陆 1234# 现有的Redhat系的Linux都是默认允许root登陆的;# Ubuntu的Linux默认都是禁止root登陆(但是大部分的云服务器商，在初始化的时候都会默认开)。$ sed -i &quot;s/#PermitRootLogin yes/PermitRootLogin yes/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/PermitRootLogin no/PermitRootLogin yes/g&quot; /etc/ssh/sshd_config 最新版本的Redhat/CentOS 7.4已经弃用RSAAuthentication，这里就提一下。 1$ sed -i &quot;s/#RSAAuthentication yes/RSAAuthentication yes/g&quot; /etc/ssh/sshd_config 二、SSHD密钥生成 直接使用ssh-keygen生成密钥 123$ ssh-keygen -b 4096or$ ssh-keygen -t rsa -b 4096 将生成好的私钥自己保存好，公钥复制到机器上去，比如： 12345$ ssh_rsa=&quot;ssh-dss AAAAB3NzaC1k ... Zk=&quot;$ mkdir /root/.ssh$ chmod 700 /root/.ssh$ echo $&#123;ssh_rsa&#125; &gt;&gt; /root/.ssh/authorized_keys$ chmod 600 /root/.ssh/authorized_keys 三、常用的软件现在的云厂商在他们默认的镜像里面已经安装好大部分的软件包。 Redhat/CentOS Redhat默认没有的依赖包还是很多的。12345678910111213141516171819202122#常用的epel源一般是要安装上去，如果你不放心这种非官方维护的源，那么就不要安装了。$ yum -y install epel-release# 生成缓存$ yum makecache#常用的工具包$ yum -y install wget bash-completion zsh git mlocate man unzip procps-ng\ net-tools bind-utils tcpdump nmap mtr psmisc tree screen dmidecode\ at openssl openssl-devel readline-devel telnet ntpdate coreutils\ deltarpm nss#接下是开发工具全家桶，基本上这些安装完，后面编译什么东西都很顺利了。。。$ yum -y install vim gcc gcc-c++ make cmake autoconf automake \ texinfo pcre pcre-devel zlib-devel zlib ncurses ncurses-devel\ bison bison-devel curl curl-devel glibc glibc-devel glib2 glib2-devel\ bzip2 bzip2-devel libxslt libxslt-devel libxml2 libxml2-devel \ libxml2-static gd gd-devel freetype freetype-devel libjpeg libjpeg-devel\ libpng libpng-devel openldap openldap-devel openssl openssl-devel \ readline-devel expat-devel gettext-devel libicu-devel perl-Digest-SHA \ deltarpm perl-devel nss Ubuntu Ubuntu/Debian默认安装的依赖包基本是完全满足我们正常的需求了。1234567891011121314151617181920212223$ sudo apt-get update#development tools$ apt-get -y install build-essential git autoconf automake cmake pkg-config \ libperl-dev python-dev python3-dev python-pip python3-pip libssl-dev \ libpcre3-dev libpcrecpp0 libxslt1-dev libcurl4-openssl-dev libxml2 \ libxml2-dev libreadline-dev libreadline6-dev libtinfo-dev#Security tools$ apt-get -y install nmap libpam-pwquality#network tools$ apt-get -y install traceroute tcpdump nload#imgs &amp; font$ apt-get -y install imagemagick libjpeg-dev libjpeg8-dev libpng12-dev libgd2-dev \ libfreetype6 libfreetype6-dev#常用的工具$ apt-get -y install unzip lrzsz screen tree sysv-rc-conf unattended-upgrades$ apt-get -y autoremove$ update-grub 更新CA证书 1$ update-ca-certificates --fresh 设置自动更新安全补丁(可选) 12345$ vim /etc/apt/apt.conf.d/10periodic APT::Periodic::Update-Package-Lists &quot;1&quot;; APT::Periodic::Download-Upgradeable-Packages &quot;1&quot;; APT::Periodic::AutocleanInterval &quot;7&quot;; APT::Periodic::Unattended-Upgrade &quot;1&quot;; 四、修改sudo, 支持sudo无密码(可选)主要是针对Ubuntu的用户，大部分的Redhat/CentOS用户都喜欢root。1234$ sudo cp -pv /etc/sudoers /etc/sudoers.old# 建议是用visudo来修改/etc/sudoers。$ sudo vim /etc/sudoers xiaoqiang ALL=(ALL) NOPASSWD: ALL 五、网络 时间同步 时间同步的话，建议如果对时间敏感的业务要做一个计划任务1$ /usr/sbin/ntpdate -u pool.ntp.org &gt;/dev/null 2&gt;&amp;1;/sbin/hwclock --systohc &gt;/dev/null 2&gt;&amp;1 修改DNS 如果使用云服务器，正常是不建议直接修改他们已经配置好的DNS。 我们可以在原先的基础上加上几条用来备份。 Redhat/CentOS 12$ vim /etc/resolv.conf dns-nameservers 1.1.1.1 Ubuntu 不能直接修改/etc/resolv.conf(你下一次重启或者重启网络服务之后，就会失效，如果你需要一个临时的连接一个dns的话，那么这是一个好的选择) 方法112$ sudo vim /etc/network/interfaces dns-nameservers 1.1.1.1 方法212$ sudo vim /etc/resolvconf/resolv.conf.d/base nameserver 1.1.1.1 修改完之后保存，然后执行1$ sudo resolvconf -u 然后，你会发现/etc/resolv.conf文件中多了几行，这几行是resolve程序自动写入的：123# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTENnameserver 1.1.1.1 六、系统优化 limits.conf 修改open files , 默认为102412345678先使用`ulimit -n`查看当前的open files，如果是默认的值,则修改$ sudo ulimit -n$ sudo ulimit -n 65535$ sudo vim /etc/security/limits.conf * soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 swapfile分区 小内存的机器，难免会用到swap，这里先看看怎么创建swap分区1234$ sudo dd if=/dev/zero of=/tmp/swapfile06 bs=1M count=4000$ sudo chmod 600 /tmp/swapfile06$ sudo mkswap /tmp/swapfile06$ sudo swapon /tmp/swapfile06 然后我们应该让系统优先使用内存，这样可以有效的避免OOM。 修改vm.swappiness，这个系统默认值为30。1234$ sysctl -a | grep vm.swappines$ sysctl -w vm.swappiness = 1$ vim /etc/sysctl.conf vm.swappiness = 1 sysctl.conf(可选) sysctl.conf的调优就复杂了。网络上有很多关于sysctl.conf的调优教程。 个人认为那些教程有点误人子弟的味道，因为sysctl.conf涉及到内存，网络带宽，TCP/IP堆栈和虚拟内存系统等高级选项，用sysctl可以读取设置超过五百个系统变量。而且不同德内核版本sysctl.conf里面的参数也不一定相同。 在这种情况下其实是很难有一个通用的sysctl.conf来应对全部的业务场景。 下面是金山云Ubuntun16系统的sysctl.conf，经供参考。12345678910111213141516171819202122232425$ cat sysctl.confnet.ipv4.ip_forward = 1net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1net.bridge.bridge-nf-call-ip6tables = 0net.bridge.bridge-nf-call-iptables = 0net.bridge.bridge-nf-call-arptables = 0kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 1024 65535net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.eth0.rp_filter = 0net.ipv4.conf.eth1.rp_filter = 0net.ipv4.conf.all.arp_announce = 2net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.eth0.arp_announce = 2net.ipv4.conf.eth1.arp_announce = 2 IP欺骗防护1234$ /etc/host.conforder hosts,bindmulti onnospoof on 七、密码复杂度 CentOS/Redhat的密码复杂度 12345678是通过配置/etc/pam.d/system-auth-ac或者/etc/pam.d/system-auth来实现的,下面是一个例子设置密码复杂度：密码至少14位;与前一次密码至少有三个位不同;大、小写字母，字数都至少2个。$ cp -rvp /etc/pam.d/system-auth&#123;,.old&#125;$ sed -i &apos;s/password requisite/#password requisite/&apos; /etc/pam.d/system-auth$ sed -i &apos;/pam_cracklib.so/a \password requisite pam_cracklib.so try_first_pass retry=6 type= minlen=14 difok=3 ucredit=2 lcredit=2 dcredit=2&apos; /etc/pam.d/system-auth Ubuntu使用crablib实现系统密码复杂度管理 1234567891011121314151617181920安装软件包：$ apt-get install libpam-cracklib修改PAM配置文件：$ vim /etc/pam.d/common-password在 &quot;password requisite pam_cracklib.so&quot;后加上参数retry=N：用户最多可以几次输入密码后报错。默认是1次。difok=N：新密码有几个字符不能和旧密码相同，默认是5个。另外如果新密码有1/2的字符于旧不同，也会被接受。diginore=N：默认当新密码有23个字符时，difok选项会被忽略。minlen=N：最小密码长度。dcredit=N：阿拉伯数字个数。N&gt;=0，代表新密码最多可以有多少个阿拉伯数字；N&lt;0，最少要有多少个数字。ucredit=N：大写字母个数。N&gt;=0，代表新密码最多可以有多少大写字母；N&lt;0，最少要有多少个大写字母。lcredit=N：小写字母个数。N&gt;=0，代表新密码最多可以有多少小写字母；N&lt;0，最少要有多少个小写字母。ocredit=N：特殊字符个数。N&gt;=0，代表新密码最多可以有多少特殊字符；N&lt;0，最少要有多少个特殊字符。例如： 密码最多尝试3次，新密码最短8个字符，要有3个字符不能与旧密码相同，最少要有1个数字、1个大写字母、1个小写字母、1个特殊字符。password requisite pam_cracklib.so retry=3 minlen=8 difok=3 dcredit=-1 lcredit=-1 ocredit=-1 ucredit=-1 八、防火墙/selinux防火墙学问就很深，改天写点教程吧，这里写不完的。。。 说说怎么临时和永久关闭Selinux(Selinux目前是redhat系的Linux预装的安全软件，功能十分强大，但是对新手还是要有一段时间的学习期) 临时关闭 123456$ getenforce Enforcing$ setenforce 0$ getenforce Permissive 永久关闭： 12345$ vim /etc/sysconfig/selinuxSELINUX=enforcing 改为 SELINUX=disabled重启系统reboot]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux主机初始化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPSec VPN]]></title>
    <url>%2FIPSec-VPN.html</url>
    <content type="text"><![CDATA[安装 openswan 及其环境一、 openswan 介绍OpenSWan是linux选Ipsec及I2tp协议的一个不错的实现方案。他支持和ipsec相关的大多数的扩展（RFC+IETF drafts）。Openswan项目起源于FreeS/WAN 2.04项目，该项目的功能很强大，可以很大程度上保证数据在跨网传输中的安全性、完整性，特别是通过它，可以很好地实现跨机房或异地办公场所实现局域网互联解决方案，如果和openvpn工具配合，可以实现将注入门户网站的多机房互访及vpn的各种强大解决方案. 能实现 IPsec 的目前总体上有 openswan，libreswan，strongswan 这3种。 libreswan 是基于 openswan 的 fork，所以现在各个发行版基本已经看不到 openswan 的身影了。 当然也有使用 strongswan 的。 二、环境实现目标：外网服务器和公司网络打通,实现内网互通： 环境: 外部服务器: （外网）106.75.20.16 (内) 10.10.68.61 （VPN） 测试 10.10.68.62 公司: (外网) 58.22.123.82（内）192.168.99.168 （VPN） 测试 192.168.99.169 架构图 三、安装 openswan 及其环境(两台都要装)3.1 软件安装centos7:123yum -y install ppp libreswan xl2tpd firewalld lsofyum install -y openswan centos6:12345678yum -y remove libevent-develyum -y install libevent2-develyum -y install nss-devel nspr-devel pkgconfig pam-devel \ libcap-ng-devel libselinux-devel lsof \ curl-devel flex bison gcc ppp make iptables gmp-devel \ fipscheck-devel unbound-devel xmlto libpcap-devel xl2tpdyum install -y openswan Ubuntu:12apt-get updateapt-get install -y openswan lsof (ubuntu 会交互安装，第一个询问启用 X.509 证书的时候选择 no，第二个只要点 ok 就可以。) 3.2、开启 linux 主机的路由功能（所有为ipsec vpn server 的主机都要开启）12345678910# vim /etc/sysctl.conf## 开启主机路由转发net.ipv4.ip_forward = 1## 关闭源路由验证net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.eth0.rp_filter = 0net.ipv4.conf.eth1.rp_filter = 0## 关闭icmp重定向# sysctl -a | egrep &quot;ipv4.*(accept|send)_redirects&quot; | awk -F &quot;=&quot; &apos;&#123;print$1&quot;= 0&quot;&#125;&apos; &gt;&gt; /etc/sysctl.conf 修改完成后执行 sysctl -p 加载配置。 3.3 检测服务正常（所有为 ipsec vpn server 的主机）12345# service ipsec startStarting pluto IKE daemon for IPsec: . [ OK ]# service ipsec statuspluto (pid 23914) is running...IPsec connections: loaded 3, active 1 3.4、在控制台上的防火墙添加 ipsec vpn 所用的端口两边开启UDP 端口500，4500 3.4 测试udp端口1234nc -vuz 58.22.123.82 500Connection to 58.22.123.82 500 port [udp/isakmp] succeeded! nc -vuz 58.22.123.82 4500Connection to 58.22.123.82 4500 port [udp/isakmp] succeeded! 3.5 VPN自动启动1chkconfig ipsec on 将/etc/ipsec.conf 文件中的 auto=add 改为 auto=start 四、验证环境ipsec verify （一个 N/A 和一个 DISABLED 不影响 ipsec vpn 的建立，Ubuntu 主机可能在checking /bin/sh 会多一个 warning，也不影响。）12345678910111213141516171819202122# ipsec verifyVerifying installed system and configuration filesVersion check and ipsec on-path [OK]Libreswan 3.15 (netkey) on 2.6.32-431.1.2.0.1.el6.x86_64Checking for IPsec support in kernel [OK] NETKEY: Testing XFRM related proc values ICMP default/send_redirects [OK] ICMP default/accept_redirects [OK] XFRM larval drop [OK]Pluto ipsec.conf syntax [OK]Hardware random device [N/A]Two or more interfaces found, checking IP forwarding [OK]Checking rp_filter [OK]Checking that pluto is running [OK] Pluto listening for IKE on udp 500 [OK] Pluto listening for IKE/NAT-T on udp 4500 [OK] Pluto ipsec.secret syntax [OK]Checking &apos;ip&apos; command [OK]Checking &apos;iptables&apos; command [OK]Checking &apos;prelink&apos; command does not interfere with FIPSChecking for obsolete ipsec.conf options [OK]Opportunistic Encryption [DISABLED] 五、配置服务5.1 配置认证 key（所有为 ipsec vpn server 的主机）123456# vim /etc/ipsec.secrets##include /etc/ipsec.d/*.secrets##源IP 目标IP: PSK &quot;(key)&quot; （0.0.0.0 即为所有 vpn 都使用这个 key）0.0.0.0 0.0.0.0 : PSK &quot;www.172173.com&quot; （注意空格格式不能错） 5.3 配置ipsec.conf12345678910111213# cat /etc/ipsec.confversion 2# basic configurationconfig setup # which IPsec stack to use, &quot;netkey&quot; (the default), &quot;klips&quot; or &quot;mast&quot;. # For MacOSX use &quot;bsd&quot; protostack=netkey //使用2.6内核内建模块netkey，2.6以下是KLIPS模块 nat_traversal=yes //nat穿透 virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v4:25.0.0.0/8,%v4:100.64.0.0/10,%v6:fd00::/8,%v6:fe80::/10 dumpdir=/var/run/pluto/ logfile=/var/log/pluto.log //log locationinclude /etc/ipsec.d/*.conf 5.2 配置VPN主体公司服务器：192.168.99.168 12345678910111213141516171819202122# cat /etc/ipsec.d/campany.conf conn BY-to-UC # 第一阶段（两端要保持一致） ike=3des-sha1 authby=secret //使用预共享密钥方式进行认证 # 第二阶段（两端要保持一致 phase2=esp //用于连接的ESP加密/认证算法。 phase2alg=3des-sha1 compress=no //所有计划的IPsec sa都要包含IPCOMP(压缩)。如果KLIPS没有配置IPCOMP支持，会忽略该选项。 type=tunnel //使用tunnel隧道模式 pfs=yes //完全加密 leftid=106.75.20.16 left=106.75.20.16 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.123.82 right=192.168.99.168 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start //add代表只是添加，但并不会连接，如果为start则代表着启动自动连接 外部服务器：106.75.20.16 12345678910111213141516171819202122# cat /etc/ipsec.d/outside.conf conn UC-to-BY # 第一阶段（两端要保持一致） ike=3des-sha1 authby=secret //使用预共享密钥方式进行认证 # 第二阶段（两端要保持一致 phase2=esp //用于连接的ESP加密/认证算法。 phase2alg=3des-sha1 compress=no //所有计划的IPsec sa都要包含IPCOMP(压缩)。如果KLIPS没有配置IPCOMP支持，会忽略该选项。 type=tunnel //使用tunnel隧道模式 pfs=yes //完全加密 leftid=106.75.20.16 left=10.10.68.61 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.123.82 right=58.22.123.82 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start //add代表只是添加，但并不会连接，如果为start则代表着启动自动连接 第一阶段选择 ikev1 主模式（main mode），参数为 3des、sha、group2。 第二阶段选择模式为 tunnel，参数为 esp、3des、sha。 启用 pfs 和 nat-t（nat 穿越）。 六、测试完成与错误定位6.1 测试12345ipsec auto --up BY-to-UC002 &quot;BY-to-UC&quot; #371: initiating Quick Mode PSK+ENCRYPT+TUNNEL+PFS+UP+IKEV1_ALLOW+IKEV2_ALLOW+SAREF_TRACK+IKE_FRAG_ALLOW &#123;using isakmp#370 msgid:76bf0615 proposal=3DES(3)_000-SHA1(2)_000 pfsgroup=OAKLEY_GROUP_MODP1536&#125;117 &quot;BY-to-UC&quot; #371: STATE_QUICK_I1: initiate002 &quot;BY-to-UC&quot; #371: transition from state STATE_QUICK_I1 to state STATE_QUICK_I2004 &quot;BY-to-UC&quot; #371: STATE_QUICK_I2: sent QI2, IPsec SA established tunnel mode &#123;ESP/NAT=&gt;0x26978c24 &lt;0xdf95b93d xfrm=3DES_0-HMAC_SHA1 NATOA=none NATD=106.75.20.16:4500 DPD=passive&#125; 这个状态即为启动成功，两端可互相 ping 通。1IPsec SA established tunnel mode 排查错误常用命令1234ipsec auto --status //状态tail -f /var/log/ipsec.log //ipsec日志tail -f /var/log/secure //安全日志tail -f /var/log/messages //系统日志 6.2 其他主机路由 其他云主机如果要通过 ipsec 访问对端要增加相应的路由，或者网关指向本地的 ipsec服务器。12345678910111213141516在10.10.68.62 （外部测试）上，执行：# route add -net 192.168.0.0/24 gw 10.10.68.61 dev eth0在10.10.68.61 （外部VPN）上，执行：# route add -net 192.168.0.0/24 gw 10.10.68.61 dev eth0在192.168.99.168 (公司VPN)上执行 ：# route add -net 10.10.0.0/16 gw 192.168.99.168 dev eth0 在192.168.99.169（公司测试）上执行：或者 公司可以在三层交换机上添加以下路由，就所有的公司内网服务器都可以到外网服务器内网，不需要每台都加 # route add -net 10.10.0.0/16 gw 192.168.99.168 dev eth0 6.3 故障排查 1)、发生no connection named “xxxxx”的报错时基本为配置文件错误或者conn名字错误，检查conn名称、配置文件格式，并查看/var/log/messages中具体错误参数/格式提示。 12initiating all conns with alias=&quot;net-to-net&quot;no connection named &quot;net-to-net&quot; 2）、发生第一阶段（STATEMAINI1）或者第二阶段（STATEQUICKI1）初始化超时报错的时候，多为两端参数配置错误导致的协商失败，需要查看/var/log/secure以及对端的日志确定具体哪个参数协商错误。 12010 &quot;sample&quot; #2: STATE_QUICK_I1: retransmission; will wait 20s for response010 &quot;sample&quot; #2: STATE_QUICK_I1: retransmission; will wait 40s for response 6.4 测试相互ping]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>openswan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-2016-mstsc]]></title>
    <url>%2Fwindow-2016-mstsc.html</url>
    <content type="text"><![CDATA[错误连接无法继续，因为未启用身份验证，并且远程计算机需要启用身份验证进行连接。 场景自带远程工具mstsc连接成功，用第三方远程工具提示如下图 目标服务器 Windows Server 2016 解决1、先用自带远程工具 mstsc 连接到Windows Server 2016 2、开始-运行-gpedit.msc，进入组策略编辑器 3、找到左侧边栏计算机配置-管理模板-Windows组件-远程桌面服务-远程桌面会话主机-安全项 4、修改&quot;远程（RDP）连接要求使用指定的安全层&quot;，改为启用，安全层选择RDP]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>连接无法继续，因为未启用身份验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-form]]></title>
    <url>%2Fdjango-form.html</url>
    <content type="text"><![CDATA[什么时form组件呢？ 其实就是一个form类，可以检测前端传来的数据，是否合法。 就好邮件格式对不对，用户名中不能以什么开头，等等之类。 Django基础之form表单的所有内置字段。Field required=True, 是否允许为空 widget=None, HTML插件 label=None, 用于生成Label标签或显示内容 initial=None, 初始值 help_text=&apos;&apos;, 帮助信息(在标签旁边显示) error_messages=None, 错误信息 {&apos;required&apos;: &apos;不能为空&apos;, &apos;invalid&apos;: &apos;格式错误&apos;} validators=[], 自定义验证规则 localize=False, 是否支持本地化 disabled=False, 是否可以编辑 label_suffix=None Label内容后缀 CharField(Field) max_length=None, 最大长度 min_length=None, 最小长度 strip=True 是否移除用户输入空白 IntegerField(Field) max_value=None, 最大值 min_value=None, 最小值 FloatField(IntegerField) ... DecimalField(IntegerField) max_value=None, 最大值 min_value=None, 最小值 max_digits=None, 总长度 decimal_places=None, 小数位长度 BaseTemporalField(Field) input_formats=None 时间格式化 DateField(BaseTemporalField) 格式：2015-09-01 TimeField(BaseTemporalField) 格式：11:12 DateTimeField(BaseTemporalField)格式：2015-09-01 11:12 DurationField(Field) 时间间隔：%d %H:%M:%S.%f ... RegexField(CharField) regex, 自定制正则表达式 max_length=None, 最大长度 min_length=None, 最小长度 error_message=None, 忽略，错误信息使用 error_messages={&apos;invalid&apos;: &apos;...&apos;} EmailField(CharField) ... FileField(Field) allow_empty_file=False 是否允许空文件 ImageField(FileField) ... 注：需要PIL模块，pip3 install Pillow 以上两个字典使用时，需要注意两点： - form表单中 enctype=&quot;multipart/form-data&quot; - view函数中 obj = MyForm(request.POST, request.FILES) URLField(Field) ... BooleanField(Field) ... NullBooleanField(BooleanField) ... ChoiceField(Field) ... choices=(), 选项，如：choices = ((0,&apos;上海&apos;),(1,&apos;北京&apos;),) required=True, 是否必填 widget=None, 插件，默认select插件 label=None, Label内容 initial=None, 初始值 help_text=&apos;&apos;, 帮助提示 ModelChoiceField(ChoiceField) ... django.forms.models.ModelChoiceField queryset, # 查询数据库中的数据 empty_label=&quot;---------&quot;, # 默认空显示内容 to_field_name=None, # HTML中value的值对应的字段 limit_choices_to=None # ModelForm中对queryset二次筛选 ModelMultipleChoiceField(ModelChoiceField) ... django.forms.models.ModelMultipleChoiceField TypedChoiceField(ChoiceField) coerce = lambda val: val 对选中的值进行一次转换 empty_value= &apos;&apos; 空值的默认值 MultipleChoiceField(ChoiceField) ... TypedMultipleChoiceField(MultipleChoiceField) coerce = lambda val: val 对选中的每一个值进行一次转换 empty_value= &apos;&apos; 空值的默认值 ComboField(Field) fields=() 使用多个验证，如下：即验证最大长度20，又验证邮箱格式 fields.ComboField(fields=[fields.CharField(max_length=20), fields.EmailField(),]) MultiValueField(Field) PS: 抽象类，子类中可以实现聚合多个字典去匹配一个值，要配合MultiWidget使用 SplitDateTimeField(MultiValueField) input_date_formats=None, 格式列表：[&apos;%Y--%m--%d&apos;, &apos;%m%d/%Y&apos;, &apos;%m/%d/%y&apos;] input_time_formats=None 格式列表：[&apos;%H:%M:%S&apos;, &apos;%H:%M:%S.%f&apos;, &apos;%H:%M&apos;] FilePathField(ChoiceField) 文件选项，目录下文件显示在页面中 path, 文件夹路径 match=None, 正则匹配 recursive=False, 递归下面的文件夹 allow_files=True, 允许文件 allow_folders=False, 允许文件夹 required=True, widget=None, label=None, initial=None, help_text=&apos;&apos; GenericIPAddressField protocol=&apos;both&apos;, both,ipv4,ipv6支持的IP格式 unpack_ipv4=False 解析ipv4地址，如果是::ffff:192.0.2.1时候，可解析为192.0.2.1， PS：protocol必须为both才能启用 SlugField(CharField) 数字，字母，下划线，减号（连字符） ... UUIDField(CharField) uuid类型 Django Form内置字段 参考]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Django基础之form表单的所有内置字段</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog log forwarding]]></title>
    <url>%2FRsyslog-log-forwarding.html</url>
    <content type="text"><![CDATA[rsyslog 日志转发前言使用rsyslog日志收集是尽量保证日志的原始性不去做任何处理 ，直接收集入到队列，如kafka、redis，这样做的的好处时，减少日志客户端rsyslog的性能压力，从而不影响所在服务器上正常业务，并且保持原始日志也便于各自业务方处理，自己写的日志自己最熟悉。 日志收集客户端rsyslog 可以使用守护进程的工具做守护,如supervisor、monit等 rsyslog提供三个远程日志传输方式： UDP: 数据包传输可信度不高 TCP: 数据包传输可信度比较高 RELP: 数据包传输可信度最高，避免数据丢失，比较新的协议，目前应用较少 下面介绍的RELP方式 rsyslog client:查看rsyslog版本$ sudo rsyslogd -v rsyslogd 7.4.4, compiled with: FEATURE_REGEXP: Yes FEATURE_LARGEFILE: No GSSAPI Kerberos 5 support: Yes FEATURE_DEBUG (debug build, slow code): No 32bit Atomic operations supported: Yes 64bit Atomic operations supported: Yes Runtime Instrumentation (slow code): No uuid support: Yes 备份原先的配置$ sudo cp -pv /etc/rsyslog.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/20-ufw.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/50-default.conf{,.old} 安装rsyslog-relp# CentOS # yum install rsyslog-relp # Ubuntu $ sudo apt-get install rsyslog-relp 修改rsyslog.confCentOS $ sudo vim /etc/rsyslog.conf $ModLoad omrelp $SystemLogRateLimitInterval 0 $SystemLogRateLimitBurst 0 $MaxMessageSize 16k # $MaxOpenFiles 5000 Ubuntu $ sudo vim /etc/rsyslog.conf $ModLoad omrelp $SystemLogRateLimitInterval 0 $SystemLogRateLimitBurst 0 $ActionQueueFileName locals # unique name prefix for spool files $ActionQueueMaxDiskSpace 15g # 15gb space limit (use as much as possible) $ActionQueueSaveOnShutdown on # save messages to disk on shutdown $ActionQueueType LinkedList # run asynchronously $ActionResumeRetryCount -1 # infinite retries if host is down $ActionQueueTimeoutEnqueue 0 # discard messages instead of throttling the log emitter when the queue has reached its limit $ActionQueueDequeueSlowdown 0 # no slowdown of the log emitter $ActionQueueDiscardSeverity 6 # discard info level messages when reaching discard mark $MaxMessageSize 16k # $MaxOpenFiles 5000 禁止日志写到/var/log/syslog，同时启用local3。 none表示什么都不记录ubuntu: $ sudo vim /etc/rsyslog.d/50-default.conf #*.*;auth,authpriv.none -/var/log/syslog *.*;auth,authpriv.none,local3.none -/var/log/syslog # local3.* @@192.168.99.200:514 local3.* :omrelp:192.168.99.200:20514 centos: *.info;mail.none;authpriv.none;cron.none,local3.none /var/log/messages # local3.* @@x.x.243.239:514 local3.* :omrelp:x.x.243.239:20514 验证rsyslog配置$ sudo rsyslogd -N 1 rsyslogd: version 7.4.4, config validation run (level 1), master config /etc/rsyslog.conf rsyslogd: End of config validation run. Bye 重启rsyslogd$ sudo service rsyslog restart rsyslog server:查看rsyslog版本$ sudo rsyslogd -v rsyslogd 7.4.4, compiled with: FEATURE_REGEXP: Yes FEATURE_LARGEFILE: No GSSAPI Kerberos 5 support: Yes FEATURE_DEBUG (debug build, slow code): No 32bit Atomic operations supported: Yes 64bit Atomic operations supported: Yes Runtime Instrumentation (slow code): No uuid support: Yes 备份原先的配置$ sudo cp -pv /etc/rsyslog.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/20-ufw.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/50-default.conf{,.old} 安装rsyslog-relp# CentOS # yum install rsyslog-relp # Ubuntu $ sudo apt-get install rsyslog-relp 修改rsyslog.conf$ sudo vim /etc/rsyslog.conf # provides UDP syslog reception # $ModLoad imudp # $UDPServerRun 514 $ModLoad imrelp $InputRELPServerRun 20514 # provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 $MaxMessageSize 16k # $MaxOpenFiles 5000 $InputTCPMaxSessions 1024 $EscapeControlCharactersOnReceive off 禁止日志写到/var/log/syslog，同时启用local3, none表示什么都不记录$ sudo vim /etc/rsyslog.d/50-default.conf #*.*;auth,authpriv.none -/var/log/syslog *.*;auth,authpriv.none,local3.none -/var/log/syslog 自定义配置文件$ sudo vim /etc/rsyslog.d/51-gamelog.conf $template cocsFormat, &quot;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg%\n&quot; $template COCS, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/cocs_%$year%%$month%%$day%.log $template BUGS, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/bug_%$year%%$month%%$day%.log $template UNKNOWN, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/unknown_%$year%%$month%%$day%.log&quot; # http://www.rsyslog.com/doc/master/configuration/properties.html if $programname startswith &apos;cocs&apos; then ?COCS;cocsFormat &amp; stop if $programname startswith &apos;bugs&apos; then ?BUGS &amp; stop if $syslogfacility-text == &apos;local3&apos; then ?UNKNOWN 验证rsyslog配置$ sudo rsyslogd -N 1 rsyslogd: version 7.4.4, config validation run (level 1), master config /etc/rsyslog.conf rsyslogd: End of config validation run. Bye 目录权限sudo chown -R syslog.syslog /data/rsyslog 重启rsyslogd$ sudo service rsyslog restart 测试logger命令可以使用系统自带的logger命令来测试 $ logger -it bugs -p local3.info &apos;{&quot;@timestamp&quot;:&quot;2017-2-22T15:40:53.820Z&quot;,&quot;beat&quot;:{&quot;hostname&quot;:&quot;12.10.x.x&quot;,&quot;name&quot;:&quot;x.x.231.98&quot;,&quot;version&quot;:&quot;5.0.2&quot;},&quot;category&quot;:&quot;game_user_rank_record&quot;,&quot;db_name&quot;:&quot;androidxxx&quot;,&quot;input_type&quot;:&quot;log&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;log&quot;:&quot;{\&quot;i_user_id\&quot;:1432320,\&quot;i_ser_id\&quot;:8012,\&quot;gamekey\&quot;:\&quot;210_16_3_33\&quot;,\&quot;account_id\&quot;:145439,\&quot;user_name\&quot;:\&quot;时间歌声\&quot;,\&quot;user_level\&quot;:1,\&quot;vip_level\&quot;:0,\&quot;user_power\&quot;:331792,\&quot;rank_type\&quot;:3,\&quot;rank\&quot;:140,\&quot;add_time\&quot;:1490716793,\&quot;parama\&quot;:\&quot;342\&quot;}&quot;,&quot;offset&quot;:75196044,&quot;source&quot;:&quot;/data/xxxx/logs/game_user_rank_record_2017-03-28.log&quot;,&quot;time&quot;:&quot;2017-03-28 23:59:53&quot;,&quot;type&quot;:&quot;22222&quot;}&apos; logger命令解释-i 在每行都记录进程ID -t bugs 每行记录都加上“bugs”这个标签,即syslogtag -p local3.notice 设置记录的设备和级别 调试模式$ sudo rsyslogd -nd 配置列子# $template cocsFormat, &quot;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg%\n&quot; # $template DEBUG, &quot;/data/rsyslog/%fromhost-ip%/DEBUG_%$year%%$month%%$day%.log&quot; $template USER_ONLINE_AMOUNT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_user_online_amount_%$year%%$month%%$day%.log&quot; $template ACTION_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_action_%$year%%$month%%$day%.log&quot; $template LOGIN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_login_%$year%%$month%%$day%.log&quot; $template PAYMENT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_payment_%$year%%$month%%$day%.log&quot; $template RESOURCE_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_resource_%$year%%$month%%$day%.log&quot; $template REGISTER_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_register_%$year%%$month%%$day%.log&quot; $template PETS_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_pets_edit_%$year%%$month%%$day%.log&quot; $template PROPS_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_props_edit_%$year%%$month%%$day%.log&quot; $template CURRENCY_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_currency_%$year%%$month%%$day%.log&quot; $template HERO_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_hero_edit_%$year%%$month%%$day%.log&quot; $template EQUIPMENT_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_equipment_edit_%$year%%$month%%$day%.log&quot; $template MSG_PROCESS_TIME_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_msg_process_time_%$year%%$month%%$day%.log&quot; $template GAMEKEY_STATIC_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_gamekey_static_%$year%%$month%%$day%.log&quot; $template SERVER_ID_STATIC_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_server_id_static_%$year%%$month%%$day%.log&quot; $template UNKNOWN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_unknown_%$year%%$month%%$day%.log&quot; $template BUGS_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_bugs_%$year%%$month%%$day%.log&quot; if $programname startswith &apos;xxx&apos; and $msg contains &apos;register_log&apos; then ?REGISTER_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;login_log&apos; then ?LOGIN_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;resource_log&apos; then ?RESOURCE_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;payment_log&apos; then ?PAYMENT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;action_log&apos; then ?ACTION_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;online_amount_log&apos; then ?USER_ONLINE_AMOUNT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;pets_edit_log&apos; then ?PETS_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;props_edit_log&apos; then ?PROPS_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;currency_log&apos; then ?CURRENCY_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;hero_edit_log&apos; then ?HERO_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;equipment_edit_log&apos; then ?EQUIPMENT_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;msg_process_time&apos; then ?MSG_PROCESS_TIME_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;gamekey_static_log&apos; then ?GAMEKEY_STATIC_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;server_id_static_log&apos; then ?SERVER_ID_STATIC_LOG &amp; stop if $syslogfacility-text == &apos;local3&apos; and $syslogseverity &lt;= &apos;5&apos; then ?BUGS_LOG &amp; stop if $syslogfacility-text == &apos;local3&apos; then ?UNKNOWN_LOG]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Rsyslog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows-multi-user]]></title>
    <url>%2Fwindows-multi-user.html</url>
    <content type="text"><![CDATA[经常使用远程桌面的朋友可能会注意到，Windows server 2008 R2中，远程桌面最多只允许两个人远程连接，第三个人就无法连接过去，但是生产环境中有一些服务器可能有许多人需要连接上去，而微软的设置确实让人比较无奈，所以呢，今天就简单介绍一下在Windows Server 2008 R2上如何实现多用户远程连接同一台服务器。 一、安装远程桌面服务；cmd 运行 1appwiz.cpl 添加功能 等待安装完成 二、在远程桌面会话主机配置中将”限制每个用户只能进行一个会话”的勾去掉。 三、确认自己的计算机开启了远程连接 四、限制连接数量cmd 运行 gpedit.msc， -- 本地计算机 策略 计算机配置\管理模板\Windows 组件\远程桌面服务\远程桌面会话主机\连接 限制连接数量中进行配置； 五、记得更新一下策略，使设置尽快生效。1gpupdte /force]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Win2008 R2实现多用户远程连接设置方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac-python-error-matplotlib]]></title>
    <url>%2Fmac-python-error-matplotlib.html</url>
    <content type="text"><![CDATA[环境123ProductName: Mac OS XProductVersion: 10.12.6Python 2.7.10 安装金山云cdn sdk 1234567891011121314151617sudo pip2.7 install ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) |################################| 696kB 343kB/s Requirement already satisfied: docutils&gt;=0.10 in /Library/Python/2.7/site-packages (from ksc-sdk-python) (0.14)Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /Library/Python/2.7/site-packages (from ksc-sdk-python) (0.9.4)Collecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) |################################| 235kB 345kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlERROR: matplotlib 1.3.1 requires nose, which is not installed.ERROR: matplotlib 1.3.1 requires tornado, which is not installed.Installing collected packages: six, python-dateutil, pyyaml, ksc-sdk-python Found existing installation: six 1.4.1ERROR: Cannot uninstall &apos;six&apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. 问题原因是Apple预安装的这个six库出于安全原因被设置为sudo也不可以执行操作，所以需要依赖于高版本的库就需要更新six，但是没有six的权限，所以就会报错。 --ignore-installed 其作用是忽略已安装的某些模块 解决方案一、跳过验证12345678910111213141516171819sudo pip2.7 install --ignore-installed ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) |################################| 696kB 268kB/s Collecting docutils&gt;=0.10 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/50/09/c53398e0005b11f7ffb27b7aa720c617aba53be4fb4f4f3f06b9b5c60f28/docutils-0.14-py2-none-any.whl (543kB) |################################| 552kB 332kB/s Collecting jmespath&lt;1.0.0,&gt;=0.7.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whlCollecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) |################################| 235kB 445kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlERROR: matplotlib 1.3.1 requires nose, which is not installed.ERROR: matplotlib 1.3.1 requires tornado, which is not installed.Installing collected packages: docutils, jmespath, six, python-dateutil, pyyaml, ksc-sdk-pythonSuccessfully installed docutils-0.14 jmespath-0.9.4 ksc-sdk-python-1.3.10 python-dateutil-2.8.0 pyyaml-3.13 six-1.12.0 安装成功了，但还是有报错 二、更新版本12345678910111213141516171819brew install python2sudo pip2.7 install ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) 100% |################################| 696kB 416kB/s Collecting jmespath&lt;1.0.0,&gt;=0.7.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whlCollecting docutils&gt;=0.10 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/50/09/c53398e0005b11f7ffb27b7aa720c617aba53be4fb4f4f3f06b9b5c60f28/docutils-0.14-py2-none-any.whl (543kB) 100% |################################| 552kB 157kB/s Collecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) 100% |################################| 235kB 97kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlInstalling collected packages: jmespath, docutils, six, python-dateutil, pyyaml, ksc-sdk-pythonSuccessfully installed docutils-0.14 jmespath-0.9.4 ksc-sdk-python-1.3.10 python-dateutil-2.8.0 pyyaml-3.13 six-1.12.0 更新Python 版本，后彻底解决。]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>ERROR: matplotlib 1.3.1 requires nose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pure-ftp-install]]></title>
    <url>%2FPure-ftp-install.html</url>
    <content type="text"><![CDATA[Install Pure-ftpFTP 簡介 FTP (File Transfer Protocol) 是在因特网上已行之多年的文件传输协议，透过这个通讯协议，可以将远程计算机的档案数据传送回本机端 (下载)，也可以把本机的档案数据传输至远程计算机 (上传) ﹔而所谓的 FTP Server，就是一部专门提供给客户端进行档案上传与下载服务的服务器。 我们都知道 Web Server 是用 http 来做数据传输的协议，其除了可让 Client 端浏览网页外，同时也提供档案上传与下载的服务，不过它比较适用于小档案的传输，而在对大文件传输时，所表现的稳定度及传输效率就不那么高了。所以想改善 http 传输档案上的缺失及效能，最好的方式就是架设一台 FTP Server 了。 用来架设 FTP Server 的软件有好几种，其中最老牌的算是 wu-ftpd，不过也由于其树大招风的关系，使得在安全性方面会有比较大的隐忧。不过还好后来又陆续发展出一些安全性较佳的服务器软件，比方像 proftpd、vsftpd 及 pure-ftpd 等，而本章将会针对 pure-ftpd 及 vsftpd 这两个服务器软件来做介绍。 FTP 的联机流程 在还没开始介绍流程之前，要先来了解一下两台计算机间 TCP 联机建立的过程： 当 Client 向 Server 提出主动联机请求时，会送出联机过程的第一个 TCP 封包给对方，而此时 TCP 封包中的 SYN (同步旗标) 位值设定为 1，代表的是一个联机的启动 ﹔接着 Server 端也必须启动自己的联机并做响应的确认，因此会向 Client 端送出联机过程的第二个封包，此时该封包的 SYN 及 ACK (回应确认旗标) 位值皆设定为 1 ﹔最后在 Client 端收到对方的封包后，必须做响应确认的动作，因此会送出联机过程的第三个封包给 Server，此时封包的 ACK 位值设定为 1。至此双方的联机才正式建立起来，这就是所谓的 TCP Three-Way Handshake ( TCP 三段式交握 )。 了解了 TCP 联机建立的观念后，底下就来说明 FTP 联机的过程。不过在此之前，要先了解的是，FTP Client 能采取的联机模式有两种，分别是主动模式 (Active mode) 及被动模式 (Passive mode)，所以接着会以这两种不同模式来叙述联机过程。 主动模式下的 FTP 联机 当 FTP Client 一开始要连上 FTP Server 时，会先随机产生一个大于 1024 的 port ( 假设 3000 port )，来主动对 FTP Server 的 21 port 做联机，等完成了 TCP 三段式交握后，联机才正式建立起来，而这个 3000 port 与 21 port 所建立的联机信道，就叫做命令信道 (command channel )。之所以会称其为命令通道，当然是只能执行一些基本指令而已啰。 现在若是 Client 端想要下载或上传数据时，还要另外建立起一条数据信道 (data channel ) 来作为数据传输使用。由于 Client 是采取主动模式 (可以想象 Client 要求 Server 做主动联机，也就是 Server 主动连 Client )，因此本身会再开启另一个大于 1024 的 port ( 假设 5000 port )，然后透过命令通道通知 Server 已准备好这个 data channel 的端口，接着 Server 就以 20 port 来主动与 Client 端的 5000 port 建立联机，就在完成了另一次的三段式交握后，此 data channel 便建立起来，至此 Client 方可开始做数据传输。 被动模式下的 FTP 联机 一开始 command channel 的建立，与上面所述相同，不再重复，这里只针对 data channel 的建立做说明。由于此时 Client 是希望采取被动模式 (可以想象 Client 要求 Server 做被动联机，也就是 Client 主动连 Server)，所以会先透过 command channel 来通知 Server 这个讯息，Sever 收到后就随机开启一个大于 1024 的 port (假设 8000 port)，并经由 command channel 知会 Client 已准备好 data channel 的端口，接着 Client 也随机开启一个大于 1024 的 port (假设 9000 port) 来主动与 Server 建立联机，而完成的三段式交握后，此 8000 port 与 9000 port 之间的 data channel 便建立起来了。 编译安装Pure-ftp$ cd /usr/local/src/ $ wget ftp://ftp.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.45.tar.gz $ tar xf pure-ftpd-1.0.45.tar.gz &amp;&amp; cd pure-ftpd-1.0.45 $ ./configure --prefix=/usr/local/pure-ftpd-1.0.45 \ --with-cookie --with-throttling \ --with-ratios --with-quotas --with-sysquotas \ --with-tls --with-welcomemsg \ --with-uploadscript --with-virtualhosts \ --with-virtualchroot --with-puredb \ --with-diraliases --with-peruserlimits \ --with-paranoidmsg --with-altlog --with-nonroot $ make &amp;&amp; make install $ ln -s /usr/local/pure-ftpd-1.0.45 /usr/local/pure-ftpd $ cp -pv /usr/local/pure-ftpd/etc/pure-ftpd.conf{,.default} $ vim /usr/local/pure-ftpd-1.0.45/etc/pure-ftpd.conf ChrootEveryone yes # 启用chroot BrokenClientsCompatibility no # 兼容不同客户端 MaxClientsNumber 100 # 客户端最大连接数 Daemonize yes # 后台运行 MaxClientsPerIP 16 # 每个ip最大连接数 VerboseLog no # 记录日志 DisplayDotFiles no # 显示隐藏文件 AnonymousOnly no # 只允许匿名用户访问 NoAnonymous yes # 不允许匿名用户连接 SyslogFacility none # 不将日志在syslog日志中显示 AltLog clf:/var/log/pureftpd.log # clf格式日志文件位置 DontResolve yes # 不进行客户端DNS解析 MaxIdleTime 5 # 最大空闲时间 #MySQLConfigFile /usr/local/pure-ftpd/etc/pureftpd-mysql.conf # 用户数据库文件 MySQL PureDB /usr/local/pure-ftpd/etc/pureftpd.pdb # 用户数据库文件 PIDFile /var/run/pure-ftpd.pid PAMAuthentication no # 取消使用PAM验证 UnixAuthentication yes # /etc/passwd 文件验证 #MinUID 500 # 验证登录用户的最小UID LimitRecursion 30000 8 # 浏览限制，文件30000，目录8层 AnonymousCanCreateDirs no # 不允许匿名用户创建目录 MaxLoad 10 # 超出负载后禁止下载 PassivePortRange 49000 50000 # 被动模式端口范围 AntiWarez yes # 禁止下载匿名用户上传但未经验证的文件 UserBandwidth 1024 # 所有用户最大带宽（KB） Umask 133:022 # 创建文件/目录默认掩码 AllowUserFXP yes # 仅运行用户进行FXP传输 AllowAnonymousFXP no # 不能删除/写入隐藏文件 ProhibitDotFilesWrite no # 不能删除/写入隐藏文件 ProhibitDotFilesRead no # 禁止读取隐藏文件 AutoRename no # 有同名文件时自动重新命名 AnonymousCantUpload yes # 不允许匿名用户上传文件 MaxDiskUsage 90 # 当磁盘使用量打到90%时禁止上传 CreateHomeDir yes # 如果虚拟用户的目录不存在则自动创建#需要ftp根目录权限为755 CustomerProof yes # 防止命令误操作 Bind 0.0.0.0,52759 # 绑定端口 yum 安装$ yum -y install pure-ftpd 设置系统用户$ useradd -s /sbin/nologin -u 600 -d ${ftpdir} -M vftp $ chown -R vftp.vftp ${ftpdir} $ # 或者 $ groupadd ftpgroup $ useradd -g ftpgroup -d /dev/null -s /sbin/nologin ftpuser $ mkdir /data/ftpdata $ chown ftpuser.ftpgroup /data/ftpdata 设置Pure-ftp虚拟用户$ /usr/local/pure-ftpd/bin/pure-pw useradd ftpuser -u 600 -g 600 -d ${ftpdir} -m $ 或者 $ sudo pure-pw mkdb $ ./pure-pw useradd 虚拟用户名 -u 系统用户 -g 系统组 -d 目录 -m $ # 当使用pure-pw 生成虚拟用户之后一定要使用pure-pw mkdb命令生成数据库文件， 否则pure-ftp启动之后也无法验证虚拟用户 $ /usr/local/pure-ftpd/bin/pure-pw mkdb /usr/local/pure-ftpd/etc/pureftpd.pdb -f /usr/local/pure-ftpd/etc/pureftpd.passwd 查看用户比如创建好的用户为someuser，则 $ pure-pw show someuser 修改用户密码$ sudo pure-pw passwd someuser 之后，通过更新来提交更改 $ sudo pure-pw 启动pure-ftpd/usr/local/pure-ftpd/sbin/pure-ftpd /usr/local/pure-ftpd/etc/pure-ftpd.conf or /etc/init.d/pure-ftpd start 重启/etc/init.d/pure-ftpd restart https://wiki.archlinux.org/index.php/Pure-FTPd]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Pure ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum-errno-256]]></title>
    <url>%2Fyum-errno-256.html</url>
    <content type="text"><![CDATA[Centos7.5 [yum update -y] 更新报错 yum update Errno 256 No more mirrors to try 环境 CentOS Linux release 7.5.1804 (Core) 现象12345678910111213141516171819202122232425262728293031[root@x.x.x.x ~]# yum update -y Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package polkit.x86_64 0:0.112-18.el7 will be updated---&gt; Package polkit.x86_64 0:0.112-18.el7_6.1 will be an update--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================== Package Arch Version Repository Size==============================================================================================================================================================================Updating: polkit x86_64 0.112-18.el7_6.1 updates 168 kTransaction Summary==============================================================================================================================================================================Upgrade 1 PackageTotal download size: 168 kDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.polkit-0.112-18.el7_6.1.x86_64 FAILED http://mirrors.ucloud.cn/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpm: [Errno -1] Package does not match intended download. Suggestion: run yum --enablerepo=updates clean metadataTrying other mirror.Error downloading packages: polkit-0.112-18.el7_6.1.x86_64: [Errno 256] No more mirrors to try. 解决方案1234wget http://mirror.centos.org/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpmsudo yum localinstall -y polkit-0.112-18.el7_6.1.x86_64.rpm# 或者sudo yum install http://mirror.centos.org/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpm -y 参考1https://qiita.com/HiroshiAkutsu/items/9fdc65ce6147793d0a01]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>yum update Errno 256</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-win32net]]></title>
    <url>%2Fpython-win32net.html</url>
    <content type="text"><![CDATA[python windows 用户管理 python win32net 模块,添加系统用户，以及赋权限。用于场景，VPN批量增加用户，共享增加用户，挺好用的。这边最需要注意的是赋权，是分两步走的。 第一步，创建用户1win32net.NetUserAdd(None, 1, udata) 第二部，加组1win32net.NetLocalGroupAddMembers(serverName, group_name, 3, [u]) 第三步，赋权1win32net.NetUserSetInfo(None, u_name, 4, user_info) 代码# -*- coding: utf-8 -*- window 用户管理 .. important:: 用salt 也可以用这个模块 依赖模块 :depends: - pythoncom - pywintypes - win32api - win32con - win32net - win32netcon - win32profile - win32security - win32ts - wmi .. note:: 目前只适用于本地用户帐户，而不是域帐户。 # Import Python libs from __future__ import absolute_import, unicode_literals, print_function import logging import time from datetime import datetime try: from shlex import quote as _cmd_quote # pylint: disable=E0611 except Exception: from pipes import quote as _cmd_quote # Import Salt libs import salt.utils.args import salt.utils.dateutils import salt.utils.platform from salt.ext import six from salt.ext.six import string_types from salt.exceptions import CommandExecutionError log = logging.getLogger(__name__) try: import pywintypes import wmi import pythoncom import win32api import win32con import win32net import win32netcon import win32profile import win32security import win32ts HAS_WIN32NET_MODS = True except ImportError: HAS_WIN32NET_MODS = False # Define the module&apos;s virtual name __virtualname__ = &apos;user&apos; def __virtual__(): &apos;&apos;&apos; 需要Windows和Windows模块 &apos;&apos;&apos; if not salt.utils.platform.is_windows(): return False, &apos;Module win_useradd: Windows Only&apos; if not HAS_WIN32NET_MODS: return False, &apos;Module win_useradd: Missing Win32 Modules&apos; return __virtualname__ def _to_unicode(instr): &apos;&apos;&apos; 用于转换为Unicode字符串的内部函数 The NetUser* series of API calls in this module requires input parameters to be Unicode Strings. This function ensures the parameter is a Unicode String. This only seems to be an issue in Python 2. All calls to this function should be gated behind a ``if six.PY2`` check. Args: instr (str): String to convert Returns: str: Unicode type string &apos;&apos;&apos; if instr is None or isinstance(instr, six.text_type): return instr else: return six.text_type(instr, &apos;utf-8&apos;) def add(name, password=None, fullname=None, description=None, groups=None, home=None, homedrive=None, profile=None, logonscript=None): &apos;&apos;&apos; 添加用户 参数: name (str): User name password (str, optional): User&apos;s password in plain text. fullname (str, optional): The user&apos;s full name. description (str, optional): A brief description of the user account. groups (str, optional): A list of groups to add the user to. (see chgroups) home (str, optional): The path to the user&apos;s home directory. homedrive (str, optional): The drive letter to assign to the home directory. Must be the Drive Letter followed by a colon. ie: U: profile (str, optional): An explicit path to a profile. Can be a UNC or a folder on the system. If left blank, windows uses it&apos;s default profile directory. logonscript (str, optional): Path to a login script to run when the user logs on. Returns: bool: True if successful. False is unsuccessful. CLI Example: .. code-block:: bash salt &apos;*&apos; user.add name password &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) password = _to_unicode(password) fullname = _to_unicode(fullname) description = _to_unicode(description) home = _to_unicode(home) homedrive = _to_unicode(homedrive) profile = _to_unicode(profile) logonscript = _to_unicode(logonscript) user_info = {} if name: user_info[&apos;name&apos;] = name else: return False user_info[&apos;password&apos;] = password user_info[&apos;priv&apos;] = win32netcon.USER_PRIV_USER user_info[&apos;home_dir&apos;] = home user_info[&apos;comment&apos;] = description user_info[&apos;flags&apos;] = win32netcon.UF_SCRIPT user_info[&apos;script_path&apos;] = logonscript try: win32net.NetUserAdd(None, 1, user_info) except win32net.error as exc: log.error(&apos;Failed to create user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False update(name=name, homedrive=homedrive, profile=profile, fullname=fullname) ret = chgroups(name, groups) if groups else True return ret def update(name, password=None, fullname=None, description=None, home=None, homedrive=None, logonscript=None, profile=None, expiration_date=None, expired=None, account_disabled=None, unlock_account=None, password_never_expires=None, disallow_change_password=None): # pylint: disable=anomalous-backslash-in-string &apos;&apos;&apos; 更新Windows用户的设置。name是唯一必需的参数。 只有在传递参数值时，才会更改设置。 .. versionadded:: 2015.8.0 Args: name (str): The user name to update. password (str, optional): New user password in plain text. fullname (str, optional): The user&apos;s full name. description (str, optional): A brief description of the user account. home (str, optional): The path to the user&apos;s home directory. homedrive (str, optional): The drive letter to assign to the home directory. Must be the Drive Letter followed by a colon. ie: U: logonscript (str, optional): The path to the logon script. profile (str, optional): The path to the user&apos;s profile directory. expiration_date (date, optional): The date and time when the account expires. Can be a valid date/time string. To set to never expire pass the string &apos;Never&apos;. expired (bool, optional): Pass `True` to expire the account. The user will be prompted to change their password at the next logon. Pass `False` to mark the account as &apos;not expired&apos;. You can&apos;t use this to negate the expiration if the expiration was caused by the account expiring. You&apos;ll have to change the `expiration_date` as well. account_disabled (bool, optional): True disables the account. False enables the account. unlock_account (bool, optional): True unlocks a locked user account. False is ignored. password_never_expires (bool, optional): True sets the password to never expire. False allows the password to expire. disallow_change_password (bool, optional): True blocks the user from changing the password. False allows the user to change the password. Returns: bool: True if successful. False is unsuccessful. CLI Example: .. code-block:: bash salt &apos;*&apos; user.update bob password=secret profile=C:\\Users\\Bob home=\\server\homeshare\bob homedrive=U: &apos;&apos;&apos; # pylint: enable=anomalous-backslash-in-string if six.PY2: name = _to_unicode(name) password = _to_unicode(password) fullname = _to_unicode(fullname) description = _to_unicode(description) home = _to_unicode(home) homedrive = _to_unicode(homedrive) logonscript = _to_unicode(logonscript) profile = _to_unicode(profile) # Make sure the user exists # Return an object containing current settings for the user try: user_info = win32net.NetUserGetInfo(None, name, 4) except win32net.error as exc: log.error(&apos;Failed to update user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # Check parameters to update # Update the user object with new settings if password: user_info[&apos;password&apos;] = password if home: user_info[&apos;home_dir&apos;] = home if homedrive: user_info[&apos;home_dir_drive&apos;] = homedrive if description: user_info[&apos;comment&apos;] = description if logonscript: user_info[&apos;script_path&apos;] = logonscript if fullname: user_info[&apos;full_name&apos;] = fullname if profile: user_info[&apos;profile&apos;] = profile if expiration_date: if expiration_date == &apos;Never&apos;: user_info[&apos;acct_expires&apos;] = win32netcon.TIMEQ_FOREVER else: try: dt_obj = salt.utils.dateutils.date_cast(expiration_date) except (ValueError, RuntimeError): return &apos;Invalid Date/Time Format: {0}&apos;.format(expiration_date) user_info[&apos;acct_expires&apos;] = time.mktime(dt_obj.timetuple()) if expired is not None: if expired: user_info[&apos;password_expired&apos;] = 1 else: user_info[&apos;password_expired&apos;] = 0 if account_disabled is not None: if account_disabled: user_info[&apos;flags&apos;] |= win32netcon.UF_ACCOUNTDISABLE else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_ACCOUNTDISABLE if unlock_account is not None: if unlock_account: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_LOCKOUT if password_never_expires is not None: if password_never_expires: user_info[&apos;flags&apos;] |= win32netcon.UF_DONT_EXPIRE_PASSWD else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_DONT_EXPIRE_PASSWD if disallow_change_password is not None: if disallow_change_password: user_info[&apos;flags&apos;] |= win32netcon.UF_PASSWD_CANT_CHANGE else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_PASSWD_CANT_CHANGE # Apply new settings try: win32net.NetUserSetInfo(None, name, 4, user_info) except win32net.error as exc: log.error(&apos;Failed to update user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False return True def delete(name, purge=False, force=False): &apos;&apos;&apos; 删除用户 Args: name (str): The name of the user to delete purge (bool, optional): Boolean value indicating that the user profile should also be removed when the user account is deleted. If set to True the profile will be removed. Default is False. force (bool, optional): Boolean value indicating that the user account should be deleted even if the user is logged in. True will log the user out and delete user. Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.delete name &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) # Check if the user exists try: user_info = win32net.NetUserGetInfo(None, name, 4) except win32net.error as exc: log.error(&apos;User not found: %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # Check if the user is logged in # Return a list of logged in users try: sess_list = win32ts.WTSEnumerateSessions() except win32ts.error as exc: log.error(&apos;No logged in users found&apos;) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) # Is the user one that is logged in logged_in = False session_id = None for sess in sess_list: if win32ts.WTSQuerySessionInformation(None, sess[&apos;SessionId&apos;], win32ts.WTSUserName) == name: session_id = sess[&apos;SessionId&apos;] logged_in = True # If logged in and set to force, log the user out and continue # If logged in and not set to force, return false if logged_in: if force: try: win32ts.WTSLogoffSession(win32ts.WTS_CURRENT_SERVER_HANDLE, session_id, True) except win32ts.error as exc: log.error(&apos;User not found: %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False else: log.error(&apos;User %s is currently logged in.&apos;, name) return False # Remove the User Profile directory if purge: try: sid = getUserSid(name) win32profile.DeleteProfile(sid) except pywintypes.error as exc: (number, context, message) = exc.args if number == 2: # Profile Folder Not Found pass else: log.error(&apos;Failed to remove profile for %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # And finally remove the user account try: win32net.NetUserDel(None, name) except win32net.error as exc: log.error(&apos;Failed to delete user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False return True def getUserSid(username): &apos;&apos;&apos; 获取 用户安全ID Args: username (str): The user name for which to look up the SID Returns: str: The user SID CLI Example: .. code-block:: bash salt &apos;*&apos; user.getUserSid jsnuffy &apos;&apos;&apos; if six.PY2: username = _to_unicode(username) domain = win32api.GetComputerName() if username.find(&apos;\\&apos;) != -1: domain = username.split(&apos;\\&apos;)[0] username = username.split(&apos;\\&apos;)[-1] domain = domain.upper() return win32security.ConvertSidToStringSid( win32security.LookupAccountName(None, domain + &apos;\\&apos; + username)[0]) def setpassword(name, password): &apos;&apos;&apos; 设置密码 Args: name (str): The user name for which to set the password password (str): The new password Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.setpassword jsnuffy sup3rs3cr3t &apos;&apos;&apos; return update(name=name, password=password) def addgroup(name, group): &apos;&apos;&apos; 添加用户到组 Args: name (str): The user name to add to the group group (str): The name of the group to which to add the user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.addgroup jsnuffy &apos;Power Users&apos; &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) group = _to_unicode(group) name = _cmd_quote(name) group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) user = info(name) if not user: return False if group in user[&apos;groups&apos;]: return True cmd = &apos;net localgroup &quot;{0}&quot; {1} /add&apos;.format(group, name) ret = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) return ret[&apos;retcode&apos;] == 0 def removegroup(name, group): &apos;&apos;&apos; 把用户从组中移除 Args: name (str): The user name to remove from the group group (str): The name of the group from which to remove the user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.removegroup jsnuffy &apos;Power Users&apos; &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) group = _to_unicode(group) name = _cmd_quote(name) group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) user = info(name) if not user: return False if group not in user[&apos;groups&apos;]: return True cmd = &apos;net localgroup &quot;{0}&quot; {1} /delete&apos;.format(group, name) ret = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) return ret[&apos;retcode&apos;] == 0 def chhome(name, home, **kwargs): &apos;&apos;&apos; 更改家目录 Args: name (str): The name of the user whose home directory you wish to change home (str): The new location of the home directory Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chhome foo \\\\fileserver\\home\\foo True &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) home = _to_unicode(home) kwargs = salt.utils.args.clean_kwargs(**kwargs) persist = kwargs.pop(&apos;persist&apos;, False) if kwargs: salt.utils.args.invalid_kwargs(kwargs) if persist: log.info(&apos;Ignoring unsupported \&apos;persist\&apos; argument to user.chhome&apos;) pre_info = info(name) if not pre_info: return False if home == pre_info[&apos;home&apos;]: return True if not update(name=name, home=home): return False post_info = info(name) if post_info[&apos;home&apos;] != pre_info[&apos;home&apos;]: return post_info[&apos;home&apos;] == home return False def chprofile(name, profile): &apos;&apos;&apos; 修改配置文件目录 Args: name (str): The name of the user whose profile you wish to change profile (str): The new location of the profile Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chprofile foo \\\\fileserver\\profiles\\foo &apos;&apos;&apos; return update(name=name, profile=profile) def chfullname(name, fullname): &apos;&apos;&apos; 修改全名 Args: name (str): The user name for which to change the full name fullname (str): The new value for the full name Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chfullname user &apos;First Last&apos; &apos;&apos;&apos; return update(name=name, fullname=fullname) def chgroups(name, groups, append=True): &apos;&apos;&apos; Change the groups this user belongs to, add append=False to make the user a member of only the specified groups Args: name (str): The user name for which to change groups groups (str, list): A single group or a list of groups to assign to the user. For multiple groups this can be a comma delimited string or a list. append (bool, optional): True adds the passed groups to the user&apos;s current groups. False sets the user&apos;s groups to the passed groups only. Default is True. Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chgroups jsnuffy Administrators,Users True &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) if isinstance(groups, string_types): groups = groups.split(&apos;,&apos;) groups = [x.strip(&apos; *&apos;) for x in groups] if six.PY2: groups = [_to_unicode(x) for x in groups] ugrps = set(list_groups(name)) if ugrps == set(groups): return True name = _cmd_quote(name) if not append: for group in ugrps: group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) if group not in groups: cmd = &apos;net localgroup &quot;{0}&quot; {1} /delete&apos;.format(group, name) __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) for group in groups: if group in ugrps: continue group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) cmd = &apos;net localgroup &quot;{0}&quot; {1} /add&apos;.format(group, name) out = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) if out[&apos;retcode&apos;] != 0: log.error(out[&apos;stdout&apos;]) return False agrps = set(list_groups(name)) return len(ugrps - agrps) == 0 def info(name): &apos;&apos;&apos; Return user information Args: name (str): Username for which to display information Returns: dict: A dictionary containing user information - fullname - username - SID - passwd (will always return None) - comment (same as description, left here for backwards compatibility) - description - active - logonscript - profile - home - homedrive - groups - password_changed - successful_logon_attempts - failed_logon_attempts - last_logon - account_disabled - account_locked - password_never_expires - disallow_change_password - gid CLI Example: .. code-block:: bash salt &apos;*&apos; user.info jsnuffy &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) ret = {} items = {} try: items = win32net.NetUserGetInfo(None, name, 4) except win32net.error: pass if items: groups = [] try: groups = win32net.NetUserGetLocalGroups(None, name) except win32net.error: pass ret[&apos;fullname&apos;] = items[&apos;full_name&apos;] ret[&apos;name&apos;] = items[&apos;name&apos;] ret[&apos;uid&apos;] = win32security.ConvertSidToStringSid(items[&apos;user_sid&apos;]) ret[&apos;passwd&apos;] = items[&apos;password&apos;] ret[&apos;comment&apos;] = items[&apos;comment&apos;] ret[&apos;description&apos;] = items[&apos;comment&apos;] ret[&apos;active&apos;] = (not bool(items[&apos;flags&apos;] &amp; win32netcon.UF_ACCOUNTDISABLE)) ret[&apos;logonscript&apos;] = items[&apos;script_path&apos;] ret[&apos;profile&apos;] = items[&apos;profile&apos;] ret[&apos;failed_logon_attempts&apos;] = items[&apos;bad_pw_count&apos;] ret[&apos;successful_logon_attempts&apos;] = items[&apos;num_logons&apos;] secs = time.mktime(datetime.now().timetuple()) - items[&apos;password_age&apos;] ret[&apos;password_changed&apos;] = datetime.fromtimestamp(secs). \ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) if items[&apos;last_logon&apos;] == 0: ret[&apos;last_logon&apos;] = &apos;Never&apos; else: ret[&apos;last_logon&apos;] = datetime.fromtimestamp(items[&apos;last_logon&apos;]).\ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) ret[&apos;expiration_date&apos;] = datetime.fromtimestamp(items[&apos;acct_expires&apos;]).\ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) ret[&apos;expired&apos;] = items[&apos;password_expired&apos;] == 1 if not ret[&apos;profile&apos;]: ret[&apos;profile&apos;] = _get_userprofile_from_registry(name, ret[&apos;uid&apos;]) ret[&apos;home&apos;] = items[&apos;home_dir&apos;] ret[&apos;homedrive&apos;] = items[&apos;home_dir_drive&apos;] if not ret[&apos;home&apos;]: ret[&apos;home&apos;] = ret[&apos;profile&apos;] ret[&apos;groups&apos;] = groups if items[&apos;flags&apos;] &amp; win32netcon.UF_DONT_EXPIRE_PASSWD == 0: ret[&apos;password_never_expires&apos;] = False else: ret[&apos;password_never_expires&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_ACCOUNTDISABLE == 0: ret[&apos;account_disabled&apos;] = False else: ret[&apos;account_disabled&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_LOCKOUT == 0: ret[&apos;account_locked&apos;] = False else: ret[&apos;account_locked&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_PASSWD_CANT_CHANGE == 0: ret[&apos;disallow_change_password&apos;] = False else: ret[&apos;disallow_change_password&apos;] = True ret[&apos;gid&apos;] = &apos;&apos; return ret else: return {} def _get_userprofile_from_registry(user, sid): &apos;&apos;&apos; In case net user doesn&apos;t return the userprofile we can get it from the registry Args: user (str): The user name, used in debug message sid (str): The sid to lookup in the registry Returns: str: Profile directory &apos;&apos;&apos; profile_dir = __salt__[&apos;reg.read_value&apos;]( &apos;HKEY_LOCAL_MACHINE&apos;, &apos;SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\{0}&apos;.format(sid), &apos;ProfileImagePath&apos; )[&apos;vdata&apos;] log.debug( &apos;user %s with sid=%s profile is located at &quot;%s&quot;&apos;, user, sid, profile_dir ) return profile_dir def list_groups(name): &apos;&apos;&apos; Return a list of groups the named user belongs to Args: name (str): The user name for which to list groups Returns: list: A list of groups to which the user belongs CLI Example: .. code-block:: bash salt &apos;*&apos; user.list_groups foo &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) ugrp = set() try: user = info(name)[&apos;groups&apos;] except KeyError: return False for group in user: ugrp.add(group.strip(&apos; *&apos;)) return sorted(list(ugrp)) def getent(refresh=False): &apos;&apos;&apos; Return the list of all info for all users Args: refresh (bool, optional): Refresh the cached user information. Useful when used from within a state function. Default is False. Returns: dict: A dictionary containing information about all users on the system CLI Example: .. code-block:: bash salt &apos;*&apos; user.getent &apos;&apos;&apos; if &apos;user.getent&apos; in __context__ and not refresh: return __context__[&apos;user.getent&apos;] ret = [] for user in __salt__[&apos;user.list_users&apos;](): stuff = {} user_info = __salt__[&apos;user.info&apos;](user) stuff[&apos;gid&apos;] = &apos;&apos; stuff[&apos;groups&apos;] = user_info[&apos;groups&apos;] stuff[&apos;home&apos;] = user_info[&apos;home&apos;] stuff[&apos;name&apos;] = user_info[&apos;name&apos;] stuff[&apos;passwd&apos;] = user_info[&apos;passwd&apos;] stuff[&apos;shell&apos;] = &apos;&apos; stuff[&apos;uid&apos;] = user_info[&apos;uid&apos;] ret.append(stuff) __context__[&apos;user.getent&apos;] = ret return ret def list_users(): &apos;&apos;&apos; Return a list of all users on Windows Returns: list: A list of all users on the system CLI Example: .. code-block:: bash salt &apos;*&apos; user.list_users &apos;&apos;&apos; res = 0 user_list = [] dowhile = True try: while res or dowhile: dowhile = False (users, _, res) = win32net.NetUserEnum( None, 0, win32netcon.FILTER_NORMAL_ACCOUNT, res, win32netcon.MAX_PREFERRED_LENGTH ) for user in users: user_list.append(user[&apos;name&apos;]) return user_list except win32net.error: pass def rename(name, new_name): &apos;&apos;&apos; Change the username for a named user Args: name (str): The user name to change new_name (str): The new name for the current user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.rename jsnuffy jshmoe &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) new_name = _to_unicode(new_name) # Load information for the current name current_info = info(name) if not current_info: raise CommandExecutionError(&apos;User \&apos;{0}\&apos; does not exist&apos;.format(name)) # Look for an existing user with the new name new_info = info(new_name) if new_info: raise CommandExecutionError( &apos;User \&apos;{0}\&apos; already exists&apos;.format(new_name) ) # Rename the user account # Connect to WMI pythoncom.CoInitialize() c = wmi.WMI(find_classes=0) # Get the user object try: user = c.Win32_UserAccount(Name=name)[0] except IndexError: raise CommandExecutionError(&apos;User \&apos;{0}\&apos; does not exist&apos;.format(name)) # Rename the user result = user.Rename(new_name)[0] # Check the result (0 means success) if not result == 0: # Define Error Dict error_dict = {0: &apos;Success&apos;, 1: &apos;Instance not found&apos;, 2: &apos;Instance required&apos;, 3: &apos;Invalid parameter&apos;, 4: &apos;User not found&apos;, 5: &apos;Domain not found&apos;, 6: &apos;Operation is allowed only on the primary domain controller of the domain&apos;, 7: &apos;Operation is not allowed on the last administrative account&apos;, 8: &apos;Operation is not allowed on specified special groups: user, admin, local, or guest&apos;, 9: &apos;Other API error&apos;, 10: &apos;Internal error&apos;} raise CommandExecutionError( &apos;There was an error renaming \&apos;{0}\&apos; to \&apos;{1}\&apos;. Error: {2}&apos; .format(name, new_name, error_dict[result]) ) return info(new_name).get(&apos;name&apos;) == new_name def current(sam=False): &apos;&apos;&apos; Get the username that salt-minion is running under. If salt-minion is running as a service it should return the Local System account. If salt is running from a command prompt it should return the username that started the command prompt. .. versionadded:: 2015.5.6 Args: sam (bool, optional): False returns just the username without any domain notation. True returns the domain with the username in the SAM format. Ie: ``domain\\username`` Returns: str: Returns username CLI Example: .. code-block:: bash salt &apos;*&apos; user.current &apos;&apos;&apos; try: if sam: user_name = win32api.GetUserNameEx(win32con.NameSamCompatible) else: user_name = win32api.GetUserName() except pywintypes.error as exc: log.error(&apos;Failed to get current user&apos;) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) raise CommandExecutionError(&apos;Failed to get current user&apos;, info=exc) if not user_name: raise CommandExecutionError(&apos;Failed to get current user&apos;) return user_name 参考资料]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python win32net Windows Users</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat]]></title>
    <url>%2Ffilebeat.html</url>
    <content type="text"><![CDATA[filebeatfilebeat 是基于原先 logstash-forwarder 的源码改造出来的。换句话说：filebeat 就是新版的 logstash-forwarder，也会是 Elastic Stack 在 shipper 端的第一选择。 安装部署 deb: 12curl -L -O https://download.elastic.co/beats/filebeat/filebeat_5.0.0_amd64.debsudo dpkg -i filebeat_5.0.0_amd64.deb rpm: 1234curl -L -O https://download.elastic.co/beats/filebeat/filebeat-5.0.0-x86_64.rpm包可以去官网从新下载过https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.2.2-x86_64.rpmsudo rpm -vi filebeat-5.0.0-x86_64.rpm mac: 12curl -L -O https://download.elastic.co/beats/filebeat/filebeat-5.0.0-darwin.tgztar xzvf filebeat-5.0.0-darwin.tgz win: 12345678910下载 https://download.elastic.co/beats/filebeat/filebeat-5.0.0-windows.zip解压到 C:\Program Files重命名 filebeat-5.0.0-windows 目录为 Filebeat右键点击 PowerSHell 图标，选择『以管理员身份运行』运行下列命令，将 Filebeat 安装成 windows 服务：PS &gt; cd &apos;C:\Program Files\Filebeat&apos;PS C:\Program Files\Filebeat&gt; .\install-service-filebeat.ps1注意可能需要额外授予执行权限。命令为：PowerShell.exe -ExecutionPolicy RemoteSigned -File .\install-service-filebeat.ps1. filebeat 配置所有的 beats 组件在 output 方面的配置都是一致的，之前章节已经介绍过。这里只介绍 filebeat 在 input 段的配置，如下：1234567891011121314151617181920212223242526272829303132filebeat: spool_size: 1024 # 最大可以攒够 1024 条数据一起发送出去 idle_timeout: &quot;5s&quot; # 否则每 5 秒钟也得发送一次 registry_file: &quot;.filebeat&quot; # 文件读取位置记录文件，会放在当前工作目录下。所以如果你换一个工作目录执行 filebeat 会导致重复传输！ config_dir: &quot;path/to/configs/contains/many/yaml&quot; # 如果配置过长，可以通过目录加载方式拆分配置 prospectors: # 有相同配置参数的可以归类为一个 prospector - fields: ownfield: &quot;mac&quot; # 类似 logstash 的 add_fields paths: - /var/log/system.log # 指明读取文件的位置 - /var/log/wifi.log include_lines: [&quot;^ERR&quot;, &quot;^WARN&quot;] # 只发送包含这些字样的日志 exclude_lines: [&quot;^OK&quot;] # 不发送包含这些字样的日志 - document_type: &quot;apache&quot; # 定义写入 ES 时的 _type 值 ignore_older: &quot;24h&quot; # 超过 24 小时没更新内容的文件不再监听。在 windows 上另外有一个配置叫 force_close_files，只要文件名一变化立刻关闭文件句柄，保证文件可以被删除，缺陷是可能会有日志还没读完 scan_frequency: &quot;10s&quot; # 每 10 秒钟扫描一次目录，更新通配符匹配上的文件列表 tail_files: false # 是否从文件末尾开始读取 harvester_buffer_size: 16384 # 实际读取文件时，每次读取 16384 字节 backoff: &quot;1s&quot; # 每 1 秒检测一次文件是否有新的一行内容需要读取 paths: - &quot;/var/log/apache/*&quot; # 可以使用通配符 exclude_files: [&quot;/var/log/apache/error.log&quot;] - input_type: &quot;stdin&quot; # 除了 &quot;log&quot;，还有 &quot;stdin&quot; multiline: # 多行合并 pattern: &apos;^[[:space:]]&apos; negate: false match: afteroutput: ... 我们已完成了配置，当 sudo service filebeat start 之后，你就可以在 kibana 上看到你的日志了。 字段Filebeat 发送的日志，会包含以下字段： beat.hostname beat 运行的主机名 beat.name shipper 配置段设置的 name，如果没设置，等于 beat.hostname @timestamp 读取到该行内容的时间 type 通过 document_type 设定的内容 input_type 来自 “log” 还是 “stdin” source 具体的文件名全路径 offset 该行日志的起始偏移量 message 日志内容 fields 添加的其他固定字段都存在这个对象里面]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>filebeat install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sersync]]></title>
    <url>%2Fsersync.html</url>
    <content type="text"><![CDATA[1.sersync介绍sersync的实时数据同步： sersync监控指定的目录，对监控路径下变化的文件进行实时同步到rsync的服务端。 整个过程相当于rsync+inotify，并且推送是通过rsync --delete的，所以使用的时候要谨慎。 2.下载安装 部署前需要在被同步端（rsync服务端）开启响应的ip allow权限，以及增加rsync demon模式的区块配置。一个区块配置对应一个sersync的进程。 1234cd /usr/local/srcwget -S http://nagios.bytech.boyihuyu.com/linux/tools/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gztar xvf sersync2.5.4_64bit_binary_stable_final.tar.gz -C /usr/local/ln -s /usr/local/sersync2.5.4 /usr/local/sersync 3.配置文件如果想要监控多个目录，拷贝多个配置文件对应起多个进程来实时监控。 12cd /usr/local/sersync/conf/cp confxml.xml yd_vhosts.xml 只需要配置配置文件yd_vhosts.xml下的&lt;sersync&gt;区块 12345678910111213141516171819202122&lt;sersync&gt; &lt;localpath watch=&quot;/usr/local/nginx/conf/vhosts/&quot;&gt; &lt;remote ip=&quot;x.x.x.x&quot; name=&quot;yd_web_nginx_config&quot;/&gt; # rsync服务端ip，区块名 &lt;!--&lt;remote ip=&quot;192.168.8.39&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;!--&lt;remote ip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params=&quot;-artuz&quot;/&gt; &lt;auth start=&quot;false&quot; users=&quot;root&quot; passwordfile=&quot;/etc/rsync.pas&quot;/&gt; # 如果需要密码，改成true，对应密码文件600 &lt;userDefinedPort start=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt; &lt;timeout start=&quot;true&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt; # 超时时间，可开可不开。 &lt;ssh start=&quot;false&quot;/&gt; &lt;/rsync&gt; # 错误日志路径 &lt;failLog path=&quot;/usr/local/sersync/log/yd_vhosts_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--default every 60mins execute once--&gt; &lt;crontab start=&quot;false&quot; schedule=&quot;600&quot;&gt;&lt;!--600mins--&gt; &lt;crontabfilter start=&quot;false&quot;&gt; &lt;exclude expression=&quot;*.php&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;info/*&quot;&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start=&quot;false&quot; name=&quot;command&quot;/&gt;&lt;/sersync&gt; 4.启动12345/usr/local/sersync/bin/sersync2 -r -d -o /usr/local/sersync/conf/yd_vhosts.xml# -r 第一次启动进行一次推送# -d 守护进程# -o 指定配置文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>sersync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsyncd]]></title>
    <url>%2Flsyncd.html</url>
    <content type="text"><![CDATA[官网文档：https://axkibe.github.io/lsyncd/ 一、lsyncd 介绍 Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。 二、lsyncd安装ubuntu安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过(安装的版本是2.1.5) 1apt-get install lsyncd Redhat可以手动去下载lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖 1yum install lua lua-devel -y 也可以通过在线安装，需要epel-release扩展包： 12rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install lsyncd -y 编译安装github上下载lsyncd-master.zip 的2.2.2版本使用的是 cmake 编译工具，无法./configure： 1234uzip lsyncd-master.zipcd lsyncd-mastercmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncdmake &amp;&amp; make install 三、lsyncd配置配置文件1234567891011121314151617181920212223shell &gt; cat lsyncd.conf.luasettings &#123; logfile = &quot;/data/logs/lsyncd/lsyncd.log&quot;, statusFile = &quot;/data/logs/lsyncd/lsyncd.status&quot;, inotifyMode = &quot;CloseWrite or Modify&quot;, maxProcesses = 8, -- nodaemon =true, &#125;sync &#123; default.rsync, source = &quot;/data/rsyslog&quot;, target = &quot;x.x.x.x::bgo_log_server&quot;, -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, delay = 30, init = false, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, append = true &#125; &#125; 配置文件说明 settings里面是全局设置，–开头表示注释，下面是几个常用选项说明： logfile 定义日志文件 stausFile 定义状态文件 nodaemon=true 表示不启用守护模式，默认 statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒 inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程 maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到 sync里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。 一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式： default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程； default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份； default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证 source 同步的源目录，使用绝对路径。 target 定义目的地址.对应不同的模式有几种写法： /tmp/dest ：本地目录同步，可用于direct和rsync模式 ip:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd –delete –include-from=- –exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步 ip::module ：同步到远程服务器目录，用于rsync模式 init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件） excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = “/etc/lsyncd.exclude”，如果是简单的排除，可以使用exclude = LIST。这里的排除规则写法与原生rsync有点不同，更为简单： 监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo 如果规则以斜线/开头，则从头开始要匹配全部 如果规则以/结尾，则要匹配监控路径的末尾 ?匹配任何字符，但不包括/ *匹配0或多个字符，但不包括/ **匹配0或多个字符，可以是/ delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。 创建配置文件1CONFIG=/etc/lsyncd/lsyncd.conf.lua 四、启动123/usr/local/lsyncd/bin/lsyncd -pidfile /var/run/lsyncd.pid /etc/lsyncd/lsyncd.conf.lua# 或者/etc/init.d/lsyncd start 五、遇到问题IO过大 运用场景 日志实时写，做到实时同步 每次同步，多会重新同步一次文件，造成io过高 解决方案 升级lsyncd 到2.x 版本 2.x版本才支持rsync append (追加同步减少io) 123456789101112131415/etc/init.d/lsyncd stopgit clone https://github.com/axkibe/lsyncd.gitapt-get remove lsyncdapt-get install liblua5.1-0-devcd lsyncd/cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncdmakemake install# 修改配置文件sync - rsyncvim /etc/lsyncd/lsyncd.conf.luaappend = true, # 修改启动文件 bin 路径vim /etc/init.d/lsyncd # 启动/etc/init.d/lsyncd start]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>lsyncd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisord]]></title>
    <url>%2FSupervisord.html</url>
    <content type="text"><![CDATA[参考博文：http://www.ttlsa.com/linux/using-supervisor-control-program/ 1.supervisord 介绍Supervisor (http://supervisord.org) 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。 除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。 2.supervisord 安装1.supervisor 是 Python 编写的，所以安装起来也很方便，可以直接用 pip123456shell&gt; yum install -y python-devel openssl openssl-develshell&gt; curl -O https://bootstrap.pypa.io/get-pip.pyshell&gt; python get-pip.pyshell&gt; pip install setuptoolsshell&gt; pip install -U setuptoolsshell&gt; pip install supervisor 2.安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件。 1shell&gt; echo_supervisord_conf &gt; /etc/supervisord.conf 3.修改配置文件，把 /etc/supervisord.conf 里 include 部分的的配置修改一下，目的是为了“一个进程对应一个管理的配置文件”，方便管理。 123shell&gt; mkdir /etc/supervisorshell&gt; sed -i &apos;s#\;\[include\]#\[include\]#&apos; /etc/supervisord.confshell&gt; sed -i &apos;/relative\/directory/a\files = /etc/supervisor/*.ini&apos; /etc/supervisord.conf 3.supervisord 管理进程配置3.1 /etc/supervisord.conf 主配置文件说明去除里面大部分注释和“不相关”的部分，我们可以先看这些配置： 123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini 3.1.管理进程配置说明路径：/etc/supervisor 12345678910111213141516[program:usercenter]directory = /home/leon/projects/usercenter ; 程序的启动目录command = gunicorn -c gunicorn.py wsgi:app ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = leon ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/usercenter_stdout.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 3.2 supervisord 进程管理配置文件示例 生产环境站点程序管理示例 12345678910111213[root@10 supervisor]# cat pc.yd.cc.ini[program:pc.yd.cc]directory = /data/wwwroot/pc.yd.cccommand = python3 /data/wwwroot/pc.yd.cc/application.pyautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/supervisord_logs/pc.yd.cc.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/supervisord_logs/pc.yd.cc.err 其他示例1 123456789101112[program:npc_filebeat_mysql]directory = /data/npcgame/npcgame_app_common/filebeat_mysqlcommand = /data/npcgame/npcgame_app_common/filebeat_mysql/filebeats -e -c /data/npcgame/npcgame_app_common/filebeat_mysql/filebeat_mysql.ymlautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/httplogs/npc_filebeat_mysql_access.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/httplogs/npc_filebeat_mysql_error.log 其他示例2 1234567891011[program:shadowsocks]command = /usr/local/bin/ssserver -c /etc/shadowsocks.jsonautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/shadowsocks/shadowsocks_access.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/shadowsocks/shadowsocks_error.log 4.supervisord 使用Supervisord安装完成后有两个可用的命令行： supervisor supervisorctl 4.1.启动或关闭Supervisord1234567# 初始启动Supervisord，启动、管理配置中设置的进程。shell&gt; supervisord或shell&gt; /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf# 关闭supervisordshell&gt; supervisorctl shutdown 4.2.验证Supervisord进程是否启动123shell&gt; ps aux|grep -i supervisordroot 31932 0.0 0.0 103324 964 pts/1 S+ 09:57 0:00 grep -i supervisordroot 32383 0.0 0.0 210480 14500 ? Ss Nov03 3:16 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf Supervisord的管理方式分为： shell命令行管理 supervisorctl命令行管理 4.3.shell命令行管理supervisordshell&gt; supervisorctl 动作 进程名 12345678910111213141516171819# 当进程的独立配置文件有变化时（增删进程），载入最新的配置文件。shell&gt; supervisorctl update# 停止某一个进程(programxxx)，programxxx为[program:blogdemon]里配置的值，这个示例就是blogdemon。shell&gt; supervisorctl stopp programxxx# 启动某个进程shell&gt; supervisorctl start programxxx# 重启某个进程shell&gt; supervisorctl restart programxxx# 停止全部进程shell&gt; supervisorctl stop all&gt; 注：start、restart、stop都不会载入最新的配置文件。# 载入最新的配置文件，并按新的配置启动、管理所有进程。shell&gt; supervisorctl reload 4.4.supervisorctl命令行管理123456789# 会进入 supervisorctl 的shell界面，然后可以执行不同的命令了shell&gt; supervisorctl&gt; status # 查看进程状态&gt; stop programxxx # 关闭 usercenter 程序&gt; start programxxx # 启动 usercenter 程序&gt; restart programxxx # 重启 usercenter 程序&gt; reread # 读取有更新（增加）的配置文件，不会启动新添加的程序&gt; update # 重启配置文件修改过的程序 5.其他除了 supervisorctl 之外，还可以配置 supervisrod 启动 web 管理界面，这个 web 后台使用 Basic Auth 的方式进行身份认证。除了单个进程的控制，还可以配置 group，进行分组管理。经常查看日志文件，包括 supervisord 的日志和各个 pragram 的日志文件，程序 crash 或抛出异常的信息一半会输出到 stderr，可以查看相应的日志文件来查找问题。Supervisor 有很丰富的功能，还有其他很多项配置，可以在官方文档获取更多信息：http://supervisord.org/index.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-install]]></title>
    <url>%2Fphp-install.html</url>
    <content type="text"><![CDATA[Building PHP from Sources安装环境依赖包$ yum -y install gcc gcc+ gcc-c++ gcc-g77 flex bison autoconf snmp automake\ bzip2-devel zlib-devel readline-devel ncurses-devel libjpeg-devel \ libpng-devel libtiff-devel freetype-devel pam-devel openssl-devel \ mod_ssl libxml2-devel gettext-devel pcre-devel curl-devel mysql-devel \ libevent-devel libtool-ltdl gmp-devel openldap openldap-devel \ ImageMagick-devel libtool net-snmp-devel libwebp libwebp-devel 下载编译包 libiconv $ cd /usr/local/src $ wget https://ftp.gnu.org/gnu/libiconv/libiconv-1.15.tar.gz libmcrypt $ wget https://ncu.dl.sourceforge.net/project/mcrypt/Libmcrypt/2.5.8/libmcrypt-2.5.8.tar.gz mcrypt $ wget https://ncu.dl.sourceforge.net/project/mcrypt/MCrypt/2.6.8/mcrypt-2.6.8.tar.gz mhash $ wget https://ncu.dl.sourceforge.net/project/mhash/mhash/0.9.9.9/mhash-0.9.9.9.tar.gz php $ wget http://cn2.php.net/distributions/php-7.1.12.tar.gz 解压 $ tar zxf libiconv-1.15.tar.gz $ tar zxf libmcrypt-2.5.8.tar.gz $ tar zxf mcrypt-2.6.8.tar.gz $ tar zxf mhash-0.9.9.9.tar.gz $ tar zxf php-7.1.12.tar.gz 安装编译包 加载lib $ echo &quot;/usr/lib&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/lib64&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/local/lib64&quot; &gt;&gt; /etc/ld.so.conf $ /sbin/ldconfig 安装libiconv ## libiconv库为需要做转换的应用程序提供了一个iconv命令，以实现一个字符编码到另一个字符编码的转换，比如它可以将UTF8编码转换成GB18030编码，反过来也行 $ cd /usr/local/src/libiconv-1.15 $ ./configure --prefix=/usr/local $ make &amp;&amp; make install $ /sbin/ldconfig 安装libmcrypt $ cd /usr/local/src/libmcrypt-2.5.8 $ ./configure &amp;&amp; make &amp;&amp; make install $ /sbin/ldconfig $ cd libltdl/ $ ./configure --prefix=/usr/local --enable-ltdl-install $ make &amp;&amp; make install $ /sbin/ldconfig 安装mhash $ cd /usr/local/src/libmcrypt-2.5.8 $ ./configure $ make &amp;&amp; make install 安装mcrypt $ cd /usr/local/src/mhash-0.9.9.9 $ ./configure $ make &amp;&amp; make install $ /sbin/ldconfig 安装php 编译php $ cd /usr/local/src/php-7.1.12 $ ./configure --prefix=/usr/local/php-7.1.12 \ --with-config-file-path=/usr/local/php-7.1.12/etc \ --enable-fpm --enable-pcntl \ --with-pear=/usr/share/php \ --with-mysql --with-mysqli \ --with-pdo_mysql --with-iconv-dir=/usr/local \ --with-zlib --with-bz2 \ --with-curl --with-libxml-dir \ --with-gd --with-jpeg-dir \ --with-png-dir --with-zlib-dir \ --with-freetype-dir --with-openssl \ --with-gettext --with-snmp \ --with-mhash --with-mcrypt \ --enable-gd-native-ttf --enable-gd-jis-conv \ --enable-shmop --enable-sockets \ --enable-zip --enable-ftp \ --enable-bcmath --enable-soap \ --enable-calendar --enable-dba \ --disable-ipv6 --enable-opcache $ make &amp;&amp; make install php. $ /usr/bin/make ZEND_EXTRA_LIBS=&apos;-liconv&apos; &amp;&amp; /usr/bin/make install $ ln -s /usr/local/php-7.1.12 /usr/local/php 安装php module依赖包 ImageMagick ## 下载ImageMagick $ wget http://transloadit.imagemagick.org/download/ImageMagick-7.0.7-11.tar.gz or $ wget http://transloadit.imagemagick.org/download/ImageMagick-6.9.9-23.tar.gz $ ## 编译依赖库ImageMagick，centos自带的ImageMagick版本较低 $ cd /usr/local/src $ tar -zxf ImageMagick-7.0.7-11.tar.gz $ cd ImageMagick-7.0.7-11 $ ./configure $ make &amp;&amp; make install $ /sbin/ldconfig libevent ## 下载libevent $ wget https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz ## 编译拓展libevent $ cd /usr/local/src $ tar xzf libevent-${libevent_ver}-stable.tar.gz $ cd libevent-${libevent_ver}-stable $ ./configure --prefix=/usr/local $ make &amp;&amp; make install $ /sbin/ldconfig 安装php module安装php module有两种手动方式，追求最新的功能可以手动编译安装，或者使用pecl(类似于pip) 安装 手动安装 imagick ## 下载imagick $ cd /usr/local/src $ wget http://pecl.php.net/get/imagick-3.4.3.tgz ## 编译拓展imagick $ tar zxf imagick-3.4.3.tgz $ cd imagick-3.4.3 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make &amp;&amp; make install memcache ## 下载memcache $ wget http://pecl.php.net/get/memcache-3.0.8.tgz ## 编译拓展memcache $ cd /usr/local/src $ tar zxf memcache-3.0.8.tgz $ cd memcache-3.0.8 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config --with-zlib-dir --enable-memcache $ make &amp;&amp; make install phpredis ## 下载phpredis $ wget https://pecl.php.net/get/redis-3.1.4.tgz ## 编译拓展redis $ cd /usr/local/src $ tar zxf redis-3.1.4.tgz $ cd redis-3.1.4 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config --enable-redis $ make &amp;&amp; make install mongo ## 下载mongo $ wget https://pecl.php.net/get/mongo-1.6.16.tgz ## 编译拓展mongo $ cd /usr/local/src $ tar xzf mongo-1.6.16.tgz $ cd mongo-1.6.16 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make &amp;&amp; make install xdebug ## 下载xdebug $ wget https://xdebug.org/files/xdebug-2.5.5.tgz ## 编译拓展xdebug ### 如果需要将 Xdebug 扩展和 OPcache 一起使用，必须在 Xdebug 扩展之前加载 OPcache 扩展。 $ cd /usr/local/src $ tar xzf xdebug-2.5.5.tgz $ cd xdebug-2.5.5 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config # make &amp;&amp; make install $ make -j `grep processor /proc/cpuinfo | wc -l` &amp;&amp; make install pecl安装 $ /usr/local/php/bin/pecl install imagick $ /usr/local/php/bin/pecl install memcache $ /usr/local/php/bin/pecl install redis $ /usr/local/php/bin/pecl install mongo ### 如果需要将 Xdebug 扩展和 OPcache 一起使用，必须在 Xdebug 扩展之前加载 OPcache 扩展。 $ /usr/local/php/bin/pecl install xdebug 配置php 配置php # set php-fpm config file. $ cp /usr/local/php/etc/php-fpm.conf{.,default} $ cat &gt; /usr/local/php/etc/php-fpm.conf &lt;&lt;EOF [global] pid = /usr/local/php-7.1.12/var/run/php-fpm.pid error_log = /usr/local/php-7.1.12/var/log/php-fpm.log log_level = error [www] listen = /usr/local/php/etc/php-cgi.socket user = nginx group = nginx listen.owner = nginx listen.group = nginx listen.mode = 0660 pm = static pm.max_children = 200 pm.start_servers = 20 pm.min_spare_servers = 5 pm.max_spare_servers = 30 pm.max_requests = 5000 request_slowlog_timeout = 5s slowlog = /usr/local/php-7.1.12/var/log/php-fpm.log.slow rlimit_files = 51200 EOF # set php.ini config file. $ cp /usr/local/src/php-7.1.12/php.ini-production /usr/local/php-7.1.12/etc/php.ini $ cp /usr/local/php-7.1.12/etc/php.ini{.,default} $ ext_path=`ls /usr/local/php-7.1.12/lib/php/extensions/` $ cat &gt;&gt; /usr/local/php-7.1.12/etc/php.ini &lt;&lt;EOF extension_dir = /usr/local/php/lib/php/extensions/${ext_path} extension = &quot;memcache.so&quot; extension = &quot;imagick.so&quot; extension = &quot;redis.so&quot; zend_extension = &quot;opcache.so&quot; output_buffering = On cgi.fix_pathinfo=0 EOF # 修改文件上传大小 $ sed -i &quot;s#^upload_max_filesize = 2M#upload_max_filesize = 5M#&quot; /usr/local/php-7.1.12/etc/php.ini # 限制php运行目录 $ sed -i &quot;s#^;open_basedir =#open_basedir = /tmp:/data/wwwroot/:/data/ftp/:/www/web#&quot; /usr/local/php-7.1.12/etc/php.ini # 关闭php版本信息 $ sed -i &quot;s#^expose_php = On#expose_php = Off#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^allow_url_fopen = On#allow_url_fopen = Off#&quot; /usr/local/php-7.1.12/etc/php.ini # opcache $ sed -i &quot;s#^;opcache.enable=0#opcache.enable=1#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.enable_cli=0#opcache.enable_cli=1#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.memory_consumption=64#opcache.memory_consumption=128#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.interned_strings_buffer=4#opcache.memory_consumption=8#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.max_accelerated_files=2000#opcache.max_accelerated_files=4000#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.revalidate_freq=2#opcache.revalidate_freq=60#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.fast_shutdown=0#opcache.fast_shutdown=1#&quot; /usr/local/php-7.1.12/etc/php.ini # disable_functions 本指令允许你基于安全原因禁止某些函数。接受逗号分隔的函数名列表作为参数。 # disable_functions 不受安全模式的影响。 本指令只能设置在 php.ini 中 $ sed -i &quot;s#^disable_functions =#disable_functions = passthru,ini_restore,eval#&quot; /usr/local/php-7.1.12/etc/php.ini # 修改时区,具体时区参考：http://php.net/manual/zh/timezones.php $ sed -i &quot;s#^;date.timezone =#date.timezone = Asia/Shanghai#&quot; /usr/local/php-7.1.12/etc/php.ini 配置php-fpm启动脚本 $ cat &gt; /etc/init.d/php-fpm &lt;&lt;EOF #! /bin/sh ### BEGIN INIT INFO # Provides: php-fpm # Required-Start: $remote_fs $network # Required-Stop: $remote_fs $network # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: starts php-fpm # Description: starts the PHP FastCGI Process Manager daemon ### END INIT INFO prefix=/usr/local/php exec_prefix=${prefix} php_fpm_BIN=${exec_prefix}/sbin/php-fpm php_fpm_CONF=${prefix}/etc/php-fpm.conf php_fpm_PID=${prefix}/var/run/php-fpm.pid php_opts=&quot;--fpm-config=${php_fpm_CONF}&quot; wait_for_pid () { try=0 while test $try -lt 35 ; do case &quot;$1&quot; in &apos;created&apos;) if [ -f &quot;$2&quot; ] ; then try=&apos;&apos; break fi ;; &apos;removed&apos;) if [ ! -f &quot;$2&quot; ] ; then try=&apos;&apos; break fi ;; esac echo -n . try=`expr $try + 1` sleep 1 done } case &quot;$1&quot; in start) echo -n &quot;Starting php-fpm &quot; $php_fpm_BIN --daemonize $php_opts &amp;&amp; chown -R nginx.nginx ${prefix}/etc/php-cgi.socket if [ &quot;$?&quot; != 0 ] ; then echo &quot; failed&quot; exit 1 fi wait_for_pid created $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; stop) echo -n &quot;Gracefully shutting down php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -QUIT `cat $php_fpm_PID` wait_for_pid removed $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed. Use force-quit&quot; exit 1 else echo &quot; done&quot; fi ;; status) if [ ! -r $php_fpm_PID ] ; then echo &quot;php-fpm is stopped&quot; exit 0 fi PID=`cat $php_fpm_PID` if ps -p $PID | grep -q $PID; then echo &quot;php-fpm (pid $PID) is running...&quot; else echo &quot;php-fpm dead but pid file exists&quot; fi ;; force-quit) echo -n &quot;Terminating php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -TERM `cat $php_fpm_PID` wait_for_pid removed $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; restart) $0 stop $0 start ;; reload) echo -n &quot;Reload service php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -USR2 `cat $php_fpm_PID` echo &quot; done&quot; ;; *) echo &quot;Usage: $0 {start|stop|force-quit|restart|reload|status}&quot; exit 1 ;; esac EOF $ chmod 755 /etc/init.d/php-fpm $ chkconfig --level 35 php-fpm on]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>PHP install from source</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TMG-error]]></title>
    <url>%2FTMG-error.html</url>
    <content type="text"><![CDATA[错误原因: 找不到证书。使用通过 IPSec 的 L2TP 协议的连接要求安装一个机器证书 window 2008 r2 系统安装TMG 2010 VPN 服务器报错，查看日志 错误原因: 找不到证书。使用通过 IPSec 的 L2TP 协议的连接要求安装一个机器证书，它也叫做计算机证书 客户只用到PPTP的连接，没用L2TP，于是决定将L2TP的IPsec策略禁用掉 开始-运行regedit.exe,打开注册表，找到 HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\Rasman\Parameters 新建一个DWORD值ProhibitIPsec，值设置为1 金山云搭建TMG 遇见的坑 问题1、内网地址是通过DHCP 获取的。 解决方案： 一、TMG-防火墙策略-需要添加允许DHCP 的协议 DHCP(答复) DHCP(允许) 二、开启启动时禁用和启用网卡12345C:\boot.bat （隐藏文件）set vif_name=lan(网卡名字)ping -n 20 127.0.0.1&gt;1.txtnetsh interface ip set interface &quot;%vif_name%&quot; disablednetsh interface ip set interface &quot;%vif_name%&quot; enabled 问题2、VPN网络无法访问其他主机，因为金山云没有回路由，现象就过去了，没反应。 解决方案: 增加路由 登入金山云控制台—虚拟私有网络—路由—新建路由 虚拟私有网络选择，云主机网段，目前网络写分配给VPN 自动获取的网段 下一条选择TMG 云主机]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>VPN 错误原因: 找不到证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各家云服务器商的对比]]></title>
    <url>%2Fcloud.html</url>
    <content type="text"><![CDATA[没有好坏，只有合不合适，仅代表个人和当下公司的状况发表一些看法，如有问题和事实不符合，可以联系删除。云计算机发展的越来越成熟，技术方面也越来越平衡，但还是要根据公司业务，选择一家合适的云。每家云都有自己的一些特点优势，还有一些自己的坑。建议也别一个篮子装，多接触接触对自己的能力提升也是有帮助的。 图仅共参考，在当下（随着时间，各家云都会发生变化），个人觉得还是比较靠谱的。 根据个人或者公司的情况，选择合适的云服务商。 按量分 量大就选择阿里腾讯，可以拿到比较好的折扣（月消耗在50万以上）（服务好，技术全） 量中等就选择金山云，白山云, ucloud等（技术还行，服务好） 友情介绍 需要的朋友，可以发邮件给我zj@s3v.cn, 可以给你们介绍，目前可以介绍金山云，腾讯云，白山云，七牛云, ucloud。因为当下公司有量，可以拿到6.5折，需要的可以联系。折扣可以对比，选择低的就好。]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>各家云服务器商的对比</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-re]]></title>
    <url>%2Fpython-re.html</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/chuxiuhong/p/5885073.html Python 正则表达式入门（初级篇）引子 首先说 正则表达式是什么？ 正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成“regex”，单数有regexp、regex，复数有regexps、regexes、regexen。 引用自维基百科https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F 定义是定义，太正经了就没法用了。我们来举个栗子：假如你在写一个爬虫，你得到了一个网页的HTML源码。其中有一段 1&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt; 你想要把这个hello world提取出来，但你这时如果只会python 的字符串处理，那么第一反应可能是 12s = &lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;start_index = s.find(&apos;&lt;h1&gt;&apos;) 然后从这个位置向下查找到下一个&lt;h1>出现这样做未尝不可，但是很麻烦不是吗。需要考虑多个标签，一不留神就多匹配到东西了，而如果想要非常准确的匹配到，又得多加循环判断，效率太低。 这时候，正则表达式就是首选的帮手。 干货开始入门级别 接着说我们刚才那个例子。我们如果拿正则处理这个表达式要怎么做呢？ 1234567import rekey = r&quot;&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;&quot;#这段是你要匹配的文本p1 = r&quot;(?&lt;=&lt;h1&gt;).+?(?=&lt;h1&gt;)&quot;#这是我们写的正则表达式规则，你现在可以不理解啥意思pattern1 = re.compile(p1)#我们在编译这段正则表达式matcher1 = re.search(pattern1,key)#在源文本中搜索符合正则表达式的部分print matcher1.group(0)#打印出来 你可以尝试运行上面的代码，看看是不是和我们想象的一样（博主是在python2.7环境下）发现代码挺少挺简单？往下看。而且正则表达式实际上要比看起来的那种奇形怪状要简单得多。 首先，从最基础的正则表达式说起。假设我们的想法是把一个字符串中的所有”python”给匹配到。我们试一试怎么做 1234567import rekey = r&quot;javapythonhtmlvhdl&quot;#这是源文本p1 = r&quot;python&quot;#这是我们写的正则表达式pattern1 = re.compile(p1)#同样是编译matcher1 = re.search(pattern1,key)#同样是查询print matcher1.group(0) 看完这段代码，你是不是觉得：卧槽？这就是正则表达式？直接写上去就行？确实，正则表达式并不像它表面上那么奇葩，如果不是我们故意改变一些符号的含义时，你看到的就是想要匹配的。所以，先把大脑清空，先认为正则表达式就是和想要匹配的字符串长得一样。在之后的练习中我们会逐步进化 初级 0.无论是python还是正则表达式都是区分大小写的，所以当你在上面那个例子上把”python”换成了”Python”，那就匹配不到你心爱的python了。 1.重新回到第一个例子中那个&lt;h1>hello world&lt;h1>匹配。假如我像这么写，会怎么样？ 123456import rekey = r&quot;&lt;h1&gt;hello world&lt;h1&gt;&quot;#源文本p1 = r&quot;&lt;h1&gt;.+&lt;h1&gt;&quot;#我们写的正则表达式，下面会将为什么pattern1 = re.compile(p1)print pattern1.findall(key)#发没发现，我怎么写成findall了？咋变了呢？ 有了入门级的经验，我们知道那两个&lt;h1>就是普普通通的字符，但是中间的是什么鬼？.字符在正则表达式代表着可以代表任何一个字符（包括它本身）findall返回的是所有符合要求的元素列表，包括仅有一个元素时，它还是给你返回的列表。 机智如你可能会突然问：那我如果就只是想匹配”.”呢？结果啥都给我返回了咋整？在正则表达式中有一个字符\，其实如果你编程经验较多的话，你就会发现这是好多地方的“转义符”。在正则表达式里，这个符号通常用来把特殊的符号转成普通的，把普通的转成特殊的23333（并不是特殊的“2333”，写完才发现会不会有脑洞大的想歪了）。举个栗子，你真的想匹配”chuxiuhong@hit.edu.cn“这个邮箱（我的邮箱），你可以把正则表达式写成下面这个样子： 123456import rekey = r&quot;afiouwehrfuichuxiuhong@hit.edu.cnaskdjhfiosueh&quot;p1 = r&quot;chuxiuhong@hit\.edu\.cn&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 发现了吧，我们在.的前面加上了转义符\，但是并不是代表匹配“.”的意思，而是只匹配“.”的意思！不知道你细不细心，有没有发现我们第一次用.时，后面还跟了一个+？那这个加号是干什么的呢？其实不难想，我们说了“.字符在正则表达式代表着可以代表任何一个字符（包括它本身）”，但是”hello world”可不是一个字符啊。+的作用是将前面一个字符或一个子表达式重复一遍或者多遍。比方说表达式“ab+”那么它能匹配到“abbbbb”，但是不能匹配到”a”，它要求你必须得有个b，多了不限，少了不行。你如果问我有没有那种“有没有都行，有多少都行的表达方式”，回答是有的。*跟在其他符号后面表达可以匹配到它0次或多次比方说我们在王叶内遇到了链接，可能既有http://开头的，又有https://开头的，我们怎么处理？ 123456import rekey = r&quot;http://www.nsfbuhwe.com and https://www.auhfisna.com&quot;#胡编乱造的网址，别在意p1 = r&quot;https*://&quot;#看那个星号！pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;http://&apos;, &apos;https://&apos;] 2.比方说我们有这么一个字符串”cat hat mat qat”，你会发现前面三个是实际的单词，最后那个是我胡编乱造的（上百度查完是昆士兰英语学院的缩写= =）。如果你本来就知道”at”前面是c、h、m其中之一时这才构成单词，你想把这样的匹配出来。根据已经学到的知识是不是会想到写出来三个正则表达式进行匹配？实际上不需要。因为有一种多字符匹方式[]代表匹配里面的字符中的任意一个还是举个栗子，我们发现啊，有的程序员比较过分，，在这对标签上，大小写混用，老害得我们抓不到想要的东西，我们该怎么应对？是写16*16种正则表达式挨个匹配？no 123456import rekey = r&quot;lalala&lt;hTml&gt;hello&lt;/Html&gt;heiheihei&quot;p1 = r&quot;&lt;[Hh][Tt][Mm][Ll]&gt;.+?&lt;/[Hh][Tt][Mm][Ll]&gt;&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;&lt;hTml&gt;hello&lt;/Html&gt;&apos;] 我们既然有了范围性的匹配，自然有范围性的排除。[^]代表除了内部包含的字符以外都能匹配还是cat,hat,mat,qat这个例子，我们想匹配除了qat以外的，那么就应该这么写： 123456import rekey = r&quot;mat cat hat pat&quot;p1 = r&quot;[^p]at&quot;#这代表除了p以外都匹配pattern1 = re.compile(p1)print pattern1.findall(key) 输出为了方便我们写简洁的正则表达式，它本身还提供下面这样的写法 &gt; 正则表达式 代表的匹配字符 [0-9] 0123456789任意之一 [a-z] 小写字母任意之一 [A-Z] 大写字母任意之一 \d 等同于[0-9] \D 等同于[^0-9]匹配非数字 \w 等同于[a-z0-9A-Z_]匹配大小写字母、数字和下划线 \W 等同于[^a-z0-9A-Z_]等同于上一条取非 3.介绍到这里，我们可能已经掌握了大致的正则表达式的构造方式，但是我们常常会在实战中遇到一些匹配的不准确的问题。比方说： 123456import rekey = r&quot;chuxiuhong@hit.edu.cn&quot;p1 = r&quot;@.+\.&quot;#我想匹配到@后面一直到“.”之间的，在这里是hitpattern1 = re.compile(p1)print pattern1.findall(key) 输出结果 1[&apos;@hit.edu.&apos;] 呦呵！你咋能多了呢？我理想的结果是@hit.，你咋还给我加量了呢？这是因为正则表达式默认是“贪婪”的，我们之前讲过，“+”代表是字符重复一次或多次。但是我们没有细说这个多次到底是多少次。所以它会尽可能“贪婪”地多给我们匹配字符，在这个例子里也就是匹配到最后一个“.”。我们怎么解决这种问题呢？只要在“+”后面加一个“？”就好了。 123456import rekey = r&quot;chuxiuhong@hit.edu.cn&quot;p1 = r&quot;@.+?\.&quot;#我想匹配到@后面一直到“.”之间的，在这里是hitpattern1 = re.compile(p1)print pattern1.findall(key) 输出结果 1[&apos;@hit.&apos;] 加了一个“?”我们就将贪婪的“+”改成了懒惰的“+”。这对于[abc]+,\w*之类的同样适用。 小测验：上面那个例子可以不使用懒惰匹配，想一种方法得到同样的结果 个人建议：在你使用”+”,”*”的时候，一定先想好到底是用贪婪型还是懒惰型，尤其是当你用到范围较大的项目上时，因为很有可能它就多匹配字符回来给你！！！ 为了能够准确的控制重复次数，正则表达式还提供{a,b}(代表a&lt;=匹配次数&lt;=b) 还是举个栗子，我们有sas,saas,saaas，我们想要sas和saas，我们怎么处理呢？ 123456import rekey = r&quot;saas and sas and saaas&quot;p1 = r&quot;sa&#123;1,2&#125;s&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;saas&apos;, &apos;sas&apos;] 如果你省略掉{1,2}中的2，那么就代表至少匹配一次，那么就等价于？如果你省略掉{1,2}中的1，那么就代表至多匹配2次。 下面列举一些正则表达式里的元字符及其作用 元字符 说明 . 代表任意字符 逻辑或操作符 [ ] 匹配内部的任一字符或子表达式 [^] 对字符集和取非 - 定义一个区间 \ 对下一字符取非（通常是普通变特殊，特殊变普通） * 匹配前面的字符或者子表达式0次或多次 *? 惰性匹配上一个 + 匹配前一个字符或子表达式一次或多次 +? 惰性匹配上一个 ? 匹配前一个字符或子表达式0次或1次重复 {n} 匹配前一个字符或子表达式 {m,n} 匹配前一个字符或子表达式至少m次至多n次 {n,} 匹配前一个字符或者子表达式至少n次 {n,}? 前一个的惰性匹配 ^ 匹配字符串的开头 \A 匹配字符串开头 $ 匹配字符串结束 [\b] 退格字符 \c 匹配一个控制字符 \d 匹配任意数字 \D 匹配数字以外的字符 \t 匹配制表符 \w 匹配任意数字字母下划线 \W 不匹配数字字母下划线]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python re 正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps-八荣八耻]]></title>
    <url>%2F8r8c.html</url>
    <content type="text"><![CDATA[随着云计算机告诉发展，现在的运维比以前维护起来更加方便了，做的事情也变得和原先运维做的事情不一样了，面临更多新的挑战。云运维，八荣八耻，节省时间和精力，从容应付业务增长，保持稳定的执行效率。 一、以可配置为荣，以硬编码为耻 本地配置,程序⽣生成 (txt/ini/cfg) 集中配置, 动态⽣生成(Yaml/Json) 环境变量量(代码⽆无侵⼊入&amp;语⾔言⽆无关性) 服务⾃自动发现,⾃自动注册(zookeeper/consul) 二、以互备为荣，以单点为耻 互容互备一直是优良架构的设计重点。 使用了LVS+Keeplived+VRRP做转换，这样可以方便负载均衡，动态升级，隔离故障。 Nginx可以加Haproxy或LVS做负载均衡。MySQL可以做主从切换，或者是MMM的高可用成熟解决方案。我们的消息队列之前用rabbitmq做，现在主要是redis和kafka集群化，其中kafka已经迁到了Mesos容器平台里。 服务的自动发现、注册，我们可以使用consul、etcd、doozer（Heroku公司产品），还有zookeeper。主要区别是算法不一样，zookeeper用的是paxos算法，而consul用的是raft算法。目前看来consul比较流行，因为consul的自动发现和自动注册更加容易使用。etcd主要是CoreOS在主推，CoreOS本身就是一个滚动发布的针对分布式部署的操作系统，大家可以去关注一下它。还有一个是hadoop和elk，大数据平台的可扩展性是标配，很容易互备。 三、以随时重启为荣，以不能迁移为耻 四、以整体交付为荣，以部分交付为耻 五、以无状态为荣，以有状态为耻 六、以标准化为荣，以特殊化为耻 在标准化方面，我们在这几个方面改良： 1.统一输入输出 统一入口,我们用一个统一的文本，到现在也在用，然后推送到所有的边缘，服务器上面的组件，要用到的参数，都能从配置里读出来。代码管理方面我们也使用git，git wiki，批量部署我们用ansible（早在2012年，我做了一些比较后，就在公司里推行ansible，看来还是很明智的决定）。 2.统一的流程管理 运维中使用python最多，所以我们使用了yaml和playbook。跳板机，通过VPN登陆，目前我们也在试用一个带有审计功能的堡垒机，可以把每个人的操作录制下来，然后再去回放观察，改进我们的工作流程。 七、以自动化工具为荣，以手动+人肉为耻 用的是bash、sed、awk, bat ，python ,ansblie, go 八、以无人值守为荣，以人工介入为耻 运维部门要做的事情有三件： 1.运维自动化 运维平台自动化，django 搭建运维平台，网上特别多的列子，找找，结合自己的业务搭建，省去人工维护。 2.监控要常态 结合云平台监控，结合zabbix, prometheus 3.性能可视化 参考资料: https://blog.csdn.net/u013815546/article/details/61961104]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>八荣八耻 云运维 devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openswan]]></title>
    <url>%2Fopenswan.html</url>
    <content type="text"><![CDATA[安装 openswan 及其环境一、openswan 介绍 OpenSWan是linux选Ipsec及I2tp协议的一个不错的实现方案。他支持和ipsec相关的大多数的扩展（RFC+IETF drafts）。Openswan项目起源于FreeS/WAN 2.04项目，该项目的功能很强大，可以很大程度上保证数据在跨网传输中的安全性、完整性，特别是通过它，可以很好地实现跨机房或异地办公场所实现局域网互联解决方案，如果和openvpn工具配合，可以实现将注入门户网站的多机房互访及vpn的各种强大解决方案. ucloud和公司网络打通,实现内网互通：环境:服务器：(外) 106.75.x.x (内) 10.10.68.61公司:(外) 58.22.x.x（内）192.168.99.168 二、安装 openswan 及其环境(两台都要装)2.1 软件安装Centos:12yum install -y gmp gmp-devel gawk flex bison iproute2 iptables sed awk cut python xmlto lsofyum install -y openswan Ubuntu:12apt-get updateapt-get install -y openswan lsof (ubuntu 会交互安装，第一个询问启用 X.509 证书的时候选择 no，第二个只要点 ok 就可以。) 2.2、开启 linux 主机的路由功能（所有为ipsec vpn server 的主机都要开启）vim /etc/sysctl.conf123## Controls IP packet forwardingnet.ipv4.ip_forward = 1 （开启主机路由转发）12##Controls source route verificationnet.ipv4.conf.default.rp_filter = 0 （关闭源路由验证）修改 /etc/sysctl.conf文件，加入以下内容: 12net.ipv4.ip_forward = 1net.ipv4.conf.default.rp_filter = 0 修改完成后执行 sysctl -p 加载配置。 2.3、在控制台上的防火墙添加 ipsec vpn 所用的端口12云服务商（阿里 腾讯 金山）开放端口 UDP 500 4500两边服务器有限制，iptab 也要开放 2.4 测试udp端口1nc -vuz 58.22.x.x 500 Connection to 58.22.x.x 500 port [udp/isakmp] succeeded! 2.5 验证环境1ipsec verify （一个 N/A 和一个 DISABLED 不影响 ipsec vpn 的建立，Ubuntu 主机可能在checking /bin/sh 会多一个 warning，也不影响。） 123456789101112131415161718192021Verifying installed system and configuration filesVersion check and ipsec on-path [OK]Libreswan 3.15 (netkey) on 2.6.32-754.9.1.el6.x86_64Checking for IPsec support in kernel [OK] NETKEY: Testing XFRM related proc values ICMP default/send_redirects [OK] ICMP default/accept_redirects [OK] XFRM larval drop [OK]Pluto ipsec.conf syntax [OK]Hardware random device [N/A]Two or more interfaces found, checking IP forwarding [OK]Checking rp_filter [OK]Checking that pluto is running [OK] Pluto listening for IKE on udp 500 [OK] Pluto listening for IKE/NAT-T on udp 4500 [OK] Pluto ipsec.secret syntax [OK]Checking &apos;ip&apos; command [OK]Checking &apos;iptables&apos; command [OK]Checking &apos;prelink&apos; command does not interfere with FIPSChecking for obsolete ipsec.conf options [OK]Opportunistic Encryption [DISABLED] 三、配置服务3.1 检测服务正常（所有为 ipsec vpn server 的主机）12345service ipsec startStarting pluto IKE daemon for IPsec: [ OK ]service ipsec statuspluto (pid 1397) is running...IPsec connections: loaded 3, active 1 3.2 配置认证 key（所有为 ipsec vpn server 的主机）vim /etc/ipsec.secrets12345#include /etc/ipsec.d/*.secrets#源IP 目标IP: PSK &quot;(key)&quot; （0.0.0.0 即为所有 vpn 都使用这个 key）0.0.0.0 0.0.0.0 : PSK &quot;boyihuyu.com&quot; （注意空格格式不能错） 3.3 配置VPN主体3.3.1 跨外网云主机间（云主机和其他公司内网 linux 主机）互通192.168.99.168:cat /etc/ipsec.d/boyihuyu.conf12345678910111213141516171819conn BY-to-UC ike=3des-sha1 authby=secret phase2=esp phase2alg=3des-sha1 compress=no type=tunnel pfs=yes leftid=106.75.x.x left=106.75.x.x leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.x.x right=192.168.99.168 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start 106.75.x.x:cat /etc/ipsec.d/ucloud.conf 12345678910111213141516171819conn UC-to-BY ike=3des-sha1 authby=secret phase2=esp phase2alg=3des-sha1 compress=no type=tunnel pfs=yes leftid=106.75.x.x left=10.10.68.61 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.x.x. right=58.22.x.x rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=add 对端网络设备（B）配置参数：Peer 的 ip 为云主机的外网 ip 即 A.A.A.A第一阶段选择 ikev1 主模式（main mode），参数为 3des、sha、group2。第二阶段选择模式为 tunnel，参数为 esp、3des、sha。启用 pfs 和 nat-t（nat 穿越）。感兴趣流为 b.b.0.0/16 到 a.a.0.0/16，即用户端网段到云主机网段。 四、测试完成与错误定位4.1 测试12345ipsec auto --up BY-to-UC002 &quot;BY-to-UC&quot; #371: initiating Quick Mode PSK+ENCRYPT+TUNNEL+PFS+UP+IKEV1_ALLOW+IKEV2_ALLOW+SAREF_TRACK+IKE_FRAG_ALLOW &#123;using isakmp#370 msgid:76bf0615 proposal=3DES(3)_000-SHA1(2)_000 pfsgroup=OAKLEY_GROUP_MODP1536&#125;117 &quot;BY-to-UC&quot; #371: STATE_QUICK_I1: initiate002 &quot;BY-to-UC&quot; #371: transition from state STATE_QUICK_I1 to state STATE_QUICK_I2004 &quot;BY-to-UC&quot; #371: STATE_QUICK_I2: sent QI2, IPsec SA established tunnel mode &#123;ESP/NAT=&gt;0x26978c24 &lt;0xdf95b93d xfrm=3DES_0-HMAC_SHA1 NATOA=none NATD=106.75.x.x:4500 DPD=passive&#125; 这个状态即为启动成功，两端可互相 ping 通。1ping 10.10.68.61 4.2 VPN自动启动1chkconfig ipsec on 将/etc/ipsec.conf 文件中的 auto=add 改为 auto=start 4.3 其他主机路由其他云主机如果要通过 ipsec 访问对端要增加相应的路由，或者网关指向本地的 ipsec服务器。 4.4 故障排查 发生no connection named “xxxxx”的报错时基本为配置文件错误或者conn名字错误，检查conn名称、配置文件格式，并查看/var/log/messages中具体错误参数/格式提示。发生第一阶段（STATEMAINI1）或者第二阶段（STATEQUICKI1）初始化超时报错的时候，多为两端参数配置错误导致的协商失败，需要查看/var/log/secure以及对端的日志确定具体哪个参数协商错误。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>vpn openvpn Ipsec OpenSWan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Forefront TMG 2010]]></title>
    <url>%2FForefront-TMG-2010.html</url>
    <content type="text"><![CDATA[一、Forefront TMG 2010 介绍Forefront TMG 是一款全面的安全网关解决方案，可帮助员工抵御来自网络的威胁。通过集成防火墙、VPN、入侵防护、恶意软件检查和 URL 筛选功能，Forefront TMG 还可提供简单且统一的外围安全防护。 二、部署2.1、线上环境外网IP: a.x.x.x内网IP：b.x.x.x操作系统: windows 2008 r2 x64 2.2 安装 TMG注意点： 1、安装过程中会启动防火墙，建议修改远程登入端口。 2、为以防安装过程中登入不上服务器，建议先把服务器密码改的简单点，不行可以通过后台进行登入。后面记得改回来。 3、Windows Event Collector 和 Windows Firewall 服务要改成手动，不然后面服务器重启网卡会起不来，连不上服务器。 2.2.1 打补丁，重启服务器。（比较花时间）2.2.2 添加虚拟网卡ucloud 只有一个内网IP，要做TMG 需要另外在添加一卡虚拟网卡。1) 网络–属性–更多适配器设置 修改网卡名字为inner 2) 控制面板–操作–设备管理器–添加硬件–手动安装–网络设配器–microsoft–microsoft loopback adapter–完成 3) 控制面板–网络和共享中心–更多适配器–找到新的网卡 命名out 设置IP b.x.x.x 千万别重启了 2.2.3 安装下载相关安装包：TMG_CHS_EE_EVAL_amd64.exe运行 TMG_CHS_EE_EVAL_amd64.exe 安装程序默认下一步 选择运行准备工具 选择默认 安装 选择接受 填入单位 定义内部网络选择添加 添加内部网络段 安装过程有点久，可以先做点其他的事情 三、基础配置TMG3.1、网络配置 3.2、配置系统 默认按就好 3.3、自定义部署 选择不更新 3.4、web 访问策略 3.5 新建访问规则（最重要的一部，配置内网可以互通） 3.6 设置内网地址 切记要保存配置并运用，否则系统会进不去，网络连不上。 四、VPN 配置(包含权限控制)4.1、定义地址分配 4.2、启用pptp和l2tp/ipsec 启用VPN 4.3、创建用户和组 先创建组 把用户添加到相应的权限组 4、4 创建子网 4.5 创建用户集 4.6 创建防火墙规则 协议 所有出站通讯从 VPN 客户端到 ucloud_c用户 对应的权限集 基本配置都这样，其他的可以根据这些自行添加]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>TMG vpn windows Forefront TMG 2010</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-ssl]]></title>
    <url>%2Fnginx-ssl.html</url>
    <content type="text"><![CDATA[参考博文：【Nginx的SSL配置优化】https://www.linpx.com/p/ssl-configuration-optimization.html 一、SSL Labsssllabs：查看https网站的安全级别： https://www.ssllabs.com/ssltest/index.html 未加入ssl优化配置的安全级别F 配置了ssl优化参数的安全级别A+ 二、创建dhparam nginx.pem秘钥 一般网站使用的SSL证书都是RSA证书，这种证书基本都是2048位的密钥，但是证书密钥交换密钥必须要比证书密钥更长才能安全。 而默认的创建dhparam.pem只有1024位，所以我们需要手动生成一个更强的密钥4096位。 1234# 执行时间很长，建议使用screen生成mkdir -p /usr/local/nginx/ssl-key/dh_sslcd /usr/local/nginx/ssl-key/dh_sslopenssl dhparam -out nginx.pem 4096 三、ssl配置及优化配置如下，只包含ssl部分的配置，未包含其他比较重要的配置，如缓存、跳转、防盗链和强制HTTPS等等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162upstream www.test.com_ssl &#123; server 127.0.0.1 weight=20 max_fails=2 fail_timeout=8s;&#125;server&#123; listen 443 ssl; server_name www.test.com; # SSL base ssl on; ssl_certificate /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.crt; ssl_certificate_key /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.key; ssl_dhparam /usr/local/nginx/ssl-key/dh_ssl/nginx.pem; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets on; # SSL ciphers ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers &apos;ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS&apos;; ssl_prefer_server_ciphers on; # OCSP Stapling #ssl_trusted_certificate /usr/local/nginx/ssl-key/GlobalSign/chain.pem; #ssl_stapling on; #ssl_stapling_verify on; #resolver 8.8.8.8 8.8.4.4 valid=300s; #resolver 119.29.29.29 223.5.5.5 valid=300s; #resolver_timeout 5s; # HSTS add_header Strict-Transport-Security max-age=15768000; #add_header X-Frame-Options DENY; #add_header X-Content-Type-Options nosniff; location / &#123; proxy_redirect off; proxy_pass http://www.test.com_ssl; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream timeout invalid_header http_500 http_502 http_503 http_504; # http_404; &#125; client_max_body_size 100m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_read_timeout 90; proxy_send_timeout 90; proxy_buffer_size 64k; proxy_buffers 32 32k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 64k; large_client_header_buffers 4 16k; error_log /data/httplogs/www.test.com-ssl-error.log; access_log /data/httplogs/www.test.com-ssl-access.log weblog;&#125; 配置解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364server &#123; listen 443 ssl; # listen 443 ssl http2; # 使用HTTP/2，需要Nginx1.9.7以上版本 server_name www.test.com; # SSL base ssl基础配置区块，SSL证书文件位置 ssl on; ssl_certificate /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.crt; # https证书，其实是个公钥，它会被发送到连接服务器的每个客户端 ssl_certificate_key /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.key; # 证书私钥是用来解密的，所以它的权限要得到保护。让nginx的主进程能够读取。当然私钥和证书可以放在一个证书文件中，这种方式也只有公钥证书才发送到client # SSL ciphers 加密算法及交换秘钥配置区块 ssl_dhparam /usr/local/nginx/ssl-key/dh_ssl/nginx.pem; # DH-Key交换密钥文件位置 ssl_ciphers &apos;ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS&apos;; # 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher &apos;RC4:HIGH:!aNULL:!MD5&apos;（后面是你所指定的套件加密算法） 来看所支持算法。 ssl_prefer_server_ciphers on; #由服务器协商最佳的加密算法 # OCSP Stapling OCSP配置区块 ssl_trusted_certificate /usr/local/nginx/ssl-key/GlobalSign/chain.pem; # OCSP Stapling的证书位置 ssl_stapling on; # OCSP Stapling开启,OCSP是用于在线查询证书吊销情况的服务，使用OCSP Stapling能将证书有效状态的信息缓存到服务器，提高TLS握手速度 ssl_stapling_verify on; # OCSP Stapling验证开启 #resolver 8.8.8.8 8.8.4.4 valid=300s; # 海外dns（美国） resolver 119.29.29.29 223.5.5.5 valid=300s; # 国内dns（腾讯和阿里） # 用于查询OCSP服务器的DNS resolver_timeout 5s; # 查询域名超时时间 # HSTS 配置区块 add_header Strict-Transport-Security max-age=10886400; # 开启HSTS，并设置有效期为“10886400秒”（最低不低于18周） # add_header Strict-Transport-Security &quot;max-age=6307200; includeSubdomains; preload&quot;; #开启HSTS，并设置有效期为“6307200秒”（6个月），包括子域名(根据情况可删掉)，预加载到浏览器缓存(根据情况可删掉) add_header X-Frame-Options DENY; # 禁止被嵌入框架 add_header X-Content-Type-Options nosniff; # 防止在IE9、Chrome和Safari中的MIME类型混淆攻击 # SSL optimize ssl优化配置区块 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 指令用于启动特定的加密协议，nginx在1.1.13和1.0.12版本后默认是ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2，TLSv1.1与TLSv1.2要确保OpenSSL &gt;= 1.0.1 ，SSLv3 现在还有很多地方在用但有不少被攻击的漏洞。 ssl_session_cache shared:SSL:50m; # Session Cache，将Session缓存到服务器，这可能会占用更多的服务器资源 # ssl_session_cache builtin:1000 shared:SSL:10m; # 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 ssl_session_tickets on; # 开启浏览器的Session Ticket缓存 ssl_session_timeout 1d; # SSL session过期时间，系统默认5分钟太短了，可以设成30m即30分钟甚至4h……&#125; ssl_ciphers加密套件配置ssl_ciphers加密套件配置可以直接通过这个链接来查看。https://mozilla.github.io/server-side-tls/ssl-config-generator/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-rewrite]]></title>
    <url>%2Fnginx-rewrite.html</url>
    <content type="text"><![CDATA[参考：http://www.cnblogs.com/kevingrace/p/6398488.html 一、nginx rewrite规则1.rewrite语法 nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断，但不支持else。 该模块需要PCRE支持，因此应在编译nginx时指定PCRE源码目录, nginx安装方法。 12345678910rewrite regex replacement [flag]关键字 正则表达式 替换值 标志位例子：rewrite ^/(.*) http://www.etiantian.org/$1 permanent;解释：^/(.*) 表示匹配所有$1 取前面regex部分括号里的内容permanent 永久301重定向，即跳转到后面的http://www.etiantian.org/$1地址上 2.rewrite flags标记位 flag description last 本条规则匹配完成后，继续向下匹配新的location URL规则。（基本上都用这个Flag，表示rewrite。） break 本条规则匹配完成即终止，不在匹配后面的任何规则 redirect 返回302临时重定向，浏览器地址栏会显示跳转后的URL地址 permanent 返回301永久重定向，浏览器地址栏会显示跳转后的URL地址。原有的url支持正则，重写的url不支持正则 3.正则表达式匹配规则 ~ 为区分大小写匹配 ~* 为不区分大小写匹配 !~和!~* 分别为区分大小写不匹配及不区分大小写不匹配 4.文件及目录匹配 -f 和!-f 用来判断是否存在文件 -d 和!-d 用来判断是否存在目录 -e 和!-e 用来判断是否存在文件或目录 -x 和!-x 用来判断文件是否可执行 5.rewrite指令优先级rewrite可配置区块：rewrite一般配置在server全局区块，也经常搭配if条件区块来使用： server区块：配置在server区块的rewrite可以说是全局的，所有请求优先匹配该区块的rewrite指令。 if区块：通过正则或条件匹配，将命中的请求进行重写，再去匹配接下去的location进行处理请求。配置在if区块的目的就是更好的让下面的location命中，然后去处理请求。 location区块：可以配置在location区块，但没有多大意义，已经被location命中的请求一般直接进行处理了，再重写没意义。 rewrite指令优先级 执行server块的rewrite指令(这里的块指的是server关键字后{ }包围的区域，其它xx块类似) 执行if区块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步uri被重写，则重新循环执行1-3，直到找到真实存在的文件 如果循环超过10次，则返回500 Internal Server Error错误 通过配置break来停止 注意：在location里面的rewrite指令，应使用break而不是last , 使用last将循环10次匹配，然后返回500错误。 二、if指令规则不支持else，rewrite常搭配if条件语句来执行： 1.if指令语法123456# 语法：if (condition) &#123;...&#125; 默认值：无 作用域：server,location 对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。 2.if指令条件if条件(conditon)可以是如下任何内容: 12345671）一个变量名 false如果这个变量是空字符串或者以0开始的字符串；2）使用= != 比较的一个变量和字符串3）是用~ ~* 与正则表达式匹配的变量，如果这个正则表达式中包含&#125;，;则整个表达式需要用&quot; 或&apos; 包围4）使用-f !-f 检查一个文件是否存在5）使用-d !-d 检查一个目录是否存在6）使用-e !-e 检查一个文件、目录、符号链接是否存在7）使用-x !-x 检查一个文件是否可执行 3.if指令实例123456if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break; &#125; if ($request_method = POST) &#123; return 405; &#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-tcp]]></title>
    <url>%2Fnginx-tcp.html</url>
    <content type="text"><![CDATA[Nginx TCP AND UDP LOAD BALANCER 前言Nginx从Nginx Plus(商业授权版) 1.7.7 开始支持 TCP和UDP的负载均衡;Nginx开源版本从1.9.0起开始支持TCP的负载均衡，从1.9.13版本开始支持UDP和UNIX-domain sockets。 Nginx开源版本默认没有开启TCP负载均衡，开启需要在编译构建的时候新增–with-stream 参数，而Nginx Plus则默认就已经开启不需要额外参数。 下面是几个简单的Nginx配置(Example Configuration) TCP server { listen 127.0.0.1:12345; proxy_pass 127.0.0.1:8080; } server { listen 12345; proxy_connect_timeout 1s; proxy_timeout 1m; proxy_pass example.com:12345; } UDP server { listen 53 udp; proxy_responses 1; proxy_timeout 20s; proxy_pass dns.example.com:53; } UNIX-domain sockets server { listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; } Nginx TCP负载均衡算法与Nginx http负载均衡一样，Nginx TCP负载均衡也支持如下负载均衡算法： Round Robin: 对所有的backend轮询发送请求，算是最简单的方式了，也是默认的分配方式；例如： upstream stream_backend { server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; ... } Least Connections(least_conn): 跟踪和backend当前的活跃连接数目，最少的连接数目说明这个backend负载最轻，将请求分配给他，这种方式会考虑到配置中给每个upstream分配的weight权重信息；例如： upstream dns_servers { least_conn; server 192.168.136.130:53; server 192.168.136.131:53; ... } Least Time(least_time): 请求会分配给响应最快和活跃连接数最少的backend；(该算法目前仅在Nginx Plus上支持)；例如： upstream stream_backend { least_time first_byte; server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; } Hash(hash key): client-server基于hash key计算hash值后,根据得到的hash值通过某种映射分配到backend。key值可以包括text, variables。例如： upstream stream_backend { hash $remote_addr; server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; } Nginx TCP健康检查开源版本的Nginx软件可以对上游服务器(upstream servers)的响应执行基本检查，尽可能重试失败的请求（也称为Passive Health Checks）。 NGINX Plus则额外增加了对外部应用程序运行状况检查（也称为Active Health Checks）和检查缓慢启动功能(slow‑start)，可以对负载平衡组中新增和恢复的服务器正常添加。 Passive Health Checks:Passive Health Checks (被动健康检查)意味着NGINX或NGINX Plus会监控服务通信是否可用，如果不可用，NGINX将尝试恢复。如果仍然无法恢复，NGINX会考虑该服务不可用，并暂时停止向该服务器发送请求，直到被再次被视为活动。 Nginx和Nginx Plus都支持下面指令，来判断服务是否不可用： fail_timeout - 设置考虑服务器不可用的多次失败尝试的时间，以及服务器不可用的时间（默认为10秒）。 max_fails - 在fail_timeout时间内设置失败尝试次数，以考虑服务器不可用（默认为1连接）尝试。 例1 该示例显示，如果NGINX无法向某个服务器发送请求或至少三次未收到此服务器的响应，则立即认为该服务器不可用30秒： upstream backend { server backend1.example.com; server backend2.example.com max_fails=3 fail_timeout=30s; } 例2 在该例显示，假设有7个连接，那么有5个连接将转到backend1.example.com:12345(因为权重为5，weight=5)，剩下的连接到第二和第三个服务器。如果在与服务器通信期间发生错误，则连接将被传递到下一个服务器，依此类推，直到所有正在运行的服务器都将被尝试。 如果与所有服务器的通信失败，则连接将关闭。 upstream backend { server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend2; server backend3.example.com:12345 resolve; server backup1.example.com:12345 backup; } Active Health ChecksNGINX Plus可以通过使用health_check指令包含在位置块中来配置最简单的运行状况检查。，并检查响应。 例1 以下示例 - 向每个服务发送带自定义的TCP请求。 返回良好的200的服务器被认为是健康的; 否则它们被标记为失败。 stream { ... upstream stream_backend { zone upstream_backend 64k; server backend1.example.com:12345; } match http { send &quot;GET / HTTP/1.0\r\nHost: localhost\r\n\r\n&quot;; expect ~* &quot;200 OK&quot;; } server { listen 12345; health_check match=http; proxy_pass stream_backend; } } 更多health-check参考资料http-health-check tcp-health-check 简单测试都在一个机器上， Nginx监听30003端口，然后开两个窗口，用nc监听 7773，7774端口。思路如下： / nc -l 7773 telnet--&gt; Nginx(30003) --&gt; \ nc -l 7774 使用nc监听端口 $ nc -l 7773 $ nc -l 7774 Nginx配置 stream { upstream backend { server 127.0.0.1:7773; server 127.0.0.1:7774; } server { listen 127.0.0.1:30003; proxy_timeout 20s; proxy_pass backend; } } 测试 $ telnet 127.0.0.1 30003 第一次访问会代理到 7773端口，第二次访问会到7774端口。 线上配置文件stream { upstream stream_backend { least_conn; server 127.0.0.1:8801 max_fails=2 fail_timeout=30s; server 127.0.0.1:8802 max_fails=2 fail_timeout=30s; server 127.0.0.1:8803 max_fails=2 fail_timeout=30s; } server { listen 8800; proxy_timeout 10m; proxy_connect_timeout 60; proxy_pass stream_backend; } } PS： 如果upstream组中只有一个服务器，max_fails，fail_timeout和slow_start参数都将被忽略，并且这样的服务器将永远不会被视为不可用。 参考文档官方文档 1: ngx_stream_proxy_module 官方文档 2: tcp-load-balancing Nginx的TCP负载均衡介绍 nginx-database-load-balancer-mysql-or-mariadb-galera-cluster]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-install]]></title>
    <url>%2Fnginx-install.html</url>
    <content type="text"><![CDATA[Building nginx from Sources http://nginx.org/en/docs/configure.html 下载对应版本的源码包。 $ cd /usr/local/src $ sudo wget http://nginx.org/download/nginx-1.12.0.tar.gz $ sudo wget https://ftp.pcre.org/pub/pcre/pcre-8.40.tar.gz $ sudo wget http://zlib.net/zlib-1.2.11.tar.gz 同级目录解压。 $ sudo tar xf nginx-1.12.0.tar.gz $ sudo tar xf pcre-8.40.tar.gz $ sudo tar xf zlib-1.2.11.tar.gz 安装相关的编译依赖包 $ sudo apt-get -y install autoconf automake build-essential pkg-config \ libperl-dev libxml2 libxslt1-dev libgeoip-dev zlib1g-dev 创建nginx用户,并禁止其登陆 $ sudo useradd -s /sbin/nologin nginx 编译安装 $ sudo cd /usr/local/src/nginx-1.12.0 $ sudo ./configure --user=nginx --group=nginx \ --prefix=/usr/local/nginx-1.12.0 \ --conf-path=/usr/local/nginx-1.12.0/conf/nginx.conf \ --pid-path=/var/log/nginx/nginx.pid \ --with-pcre=../pcre-8.40 \ --with-zlib=../zlib-1.2.11 \ --with-stream \ --with-stream_ssl_module \ --with-http_ssl_module \ --with-http_v2_module \ --with-http_geoip_module \ --with-http_realip_module \ --with-http_xslt_module \ --with-file-aio \ --with-http_perl_module \ --with-http_auth_request_module \ --with-http_gzip_static_module \ --with-http_secure_link_module \ --with-http_sub_module \ --with-http_stub_status_module $ sudo make &amp;&amp; make install $ sudo ln -s /usr/local/nginx-1.12.0 /usr/local/nginx 调整配置文件 $ sudo vim /usr/local/nginx/conf/nginx.conf user nginx nginx; worker_processes auto; ## Binds worker processes to the sets of CPUs. ## Each CPU set is represented by a bitmask of allowed CPUs. There should be a separate set defined for each of the worker processes. ## By default, worker processes are not bound to any specific CPUs. worker_cpu_affinity auto; error_log /var/log/nginx/error.log notice; pid /var/log/nginx/nginx.pid; ## Specifies the value for maximum file descriptors that can be opened by this process. worker_rlimit_nofile 51200; events { use epoll; ## Sets the maximum number of simultaneous connections that can be opened by a worker process. ## It should be kept in mind that this number includes all connections (e.g. connections with proxied servers, among others), not only connections with clients. Another consideration is that the actual number of simultaneous connections cannot exceed the current limit on the maximum number of open files, which can be changed by worker_rlimit_nofile. ## maxclient = worker_processes * worker_connections / cpu_number worker_connections 30000; } http { include mime.types; default_type application/octet-stream; log_format weblog &apos;$http_x_forwarded_for $remote_port &quot;$request&quot; $status [$time_local] &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_referer&quot; $body_bytes_sent &apos; &apos;$remote_addr $gzip_ratio&apos;; sendfile on; server_tokens off; tcp_nopush on; tcp_nodelay on; keepalive_timeout 60; request_pool_size 4k; ## Allows accurate tuning of per-connection memory allocations. ## This directive has minimal impact on performance and should not generally be used. ## By default, the size is equal to 256 bytes on 32-bit platforms and 512 bytes on 64-bit platforms. connection_pool_size 512; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 256k; large_client_header_buffers 4 1024k; client_max_body_size 10m; client_body_buffer_size 256k; output_buffers 4 32k; postpone_output 1460; server_names_hash_bucket_size 128; fastcgi_connect_timeout 180s; fastcgi_send_timeout 180s; fastcgi_read_timeout 180s; fastcgi_buffer_size 2048k; fastcgi_buffers 4 1024k; fastcgi_busy_buffers_size 2048k; fastcgi_temp_file_write_size 2048k; gzip on; gzip_http_version 1.1; gzip_comp_level 2; gzip_min_length 1100; gzip_buffers 16 8k; gzip_vary on; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain text/css application/json text/xml application/xml application/xml+rss text/javascript application/javascript application/x-javascript; ## The following includes are specified for virtual hosts include vhosts/*.conf; } server { listen 443 ssl default; # server_name silent.live www.silent.live blog.silent.live devops.silent.live; server_name silent.live www.silent.live; root /data/wwwroot/silent.live/webroot; index index.shtml index.html; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate /etc/letsencrypt/live/silent.live/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/silent.live/privkey.pem; ## Specifies that server ciphers should be preferred over client ciphers when the SSLv3 and TLS protocols are used. ssl_prefer_server_ciphers on; # ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH&quot;; ssl_ciphers &apos;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&apos;; ## Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits ssl_dhparam /usr/local/nginx/sslkey/dh_ssl/nginx_dh_2048.pem; ## The special value auto (1.11.0) instructs nginx to use a list built into the OpenSSL library when using OpenSSL 1.0.2 or higher, or prime256v1 with older versions. ## Prior to version 1.11.0, the prime256v1 curve was used by default. ssl_ecdh_curve auto; ## This will create a cache shared between all worker processes. ## The cache size is specified in bytes (in this example: 50 MB). ## According to the Nginx documentation can 1MB store about 4000 sessions, so for this example, we can store about 200000 sessions, and we will store them for 180 minutes. ## If you expect more traffic, increase the cache size accordingly. ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ## Requires nginx &gt;= 1.5.9 ssl_session_tickets off; # ssl_session_ticket_key /usr/local/nginx/sslkey/tls_session/tls_session_ticket.key; ## OCSP Stapling, Requires nginx &gt;= 1.3.7 ssl_stapling on; ssl_stapling_verify on; ## verify chain of trust of OCSP response using Root CA and Intermediate certs. # ssl_trusted_certificate /path/to/signed_cert_plus_intermediates; resolver 8.8.8.8 8.8.4.4 valid=300s; resolver_timeout 5s; ssi on; ssi_silent_errors off; ssi_types text/shtml; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; access_log off; } location = /favicon.ico { rewrite (.*) /static/favicon.ico; } # location = /robots.txt { # rewrite (.*) /static/robots.txt; # } location / { add_header Cache-Control no-cache; ## HSTS # add_header Strict-Transport-Security &quot;max-age=63072000; includeSubDomains; preload&quot;; add_header Strict-Transport-Security &quot;max-age=63072000&quot;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; } error_page 404 /static/404.html; access_log /data/httplog/silent.live_access_ssl.log weblog; error_log /data/httplog/silent.live_error_ssl.log; }]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-install]]></title>
    <url>%2Fjenkins-install.html</url>
    <content type="text"><![CDATA[Installing JenkinsPrefaceJenkins是一个用Java编写的开源的持续集成工具。在与Oracle发生争执后，项目从Hudson项目复刻。 Jenkins提供了软件开发的持续集成服务。它运行在Servlet容器中（例如Apache Tomcat）。 它支持软件配置管理（SCM）工具（包括AccuRev SCM、CVS、Subversion、Git、Perforce、Clearcase和RTC），可以执行基于Apache Ant和Apache Maven的项目，以及任意的Shell脚本和Windows批处理命令。Jenkins的主要开发者是川口耕介。Jenkins是在MIT许可证下发布的自由软件。 System requirement尽量使用Java 8, 还建议使用512MB以上RAM的系统。 Begin InstallJenkins 提供了多种安装方式。 Installing Jenkins with Docker 假设你已经安装好docker,那么你可以直接执行： $ sudo docker pull jenkins $ sudo docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins 这将把jenkins数据存储在主机/your/home上，因此请确保/your/home目录能够被容器中的jenkins用户访问（jenkins user - uid 1000）或在执行docker run时使用-u some_other_user参数。 您可能需要自定义运行Jenkins的JVM，通常是传递系统属性或调整堆内存设置。为此使用JAVA_OPTS环境变量： 例如: 下面为修改JVM默认的时区，则可以这样运行： $ sudo docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=-Duser.timezone=GMT jenkins or $ sudo docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=-Duser.timezone=&quot;Australia/Sydney&quot; jenkins 更多详情可以参考： https://hub.docker.com/r/library/jenkins https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+with+Docker Installing Jenkins on Ubuntu Installation $ wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add - $ sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos; $ sudo apt-get update $ sudo apt-get install jenkins Upgrade 一旦这样安装，您可以通过运行以下命令来更新到更高版本的Jenkins（当它出来时）： $ sudo apt-get update $ sudo apt-get install jenkins （aptitude或apt-get没有任何区别。） What does this package do? 开始时，jenkins将作为一个守护进程启动。更多详情请查看/etc/init.d/jenkins。 创建“jenkins“用户以运行此服务。 日志文件将被放入/var/log/jenkins/jenkins.log。如果您正在对Jenkins进行故障排除，请检查此文件。 /etc/default/jenkins 将预先配置参数，例如JENKINS_HOME。 如果您的服务器8080端口已经被占用，请编辑/etc/default/jenkins以替换该行 HTTP_PORT = 8080 默认情况下，Jenkins监听端口8080.使用浏览器访问此端口以开始配置。 更多详情可以参考：&lt;https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Ubuntu&gt; Installing Jenkins on Red Hat distributions RedHat和CentOS 在安装方式上区别并不大，这里以RedHat为例 Installation 将Jenkins源添加到yum repos，并且开始安装 $ sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo $ sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key $ sudo yum install jenkins Installation of a stable version(可选) 以上述方法安装的Jenkins默认是最新版，如果需要安装LTS版本(长期支持版)，则可以： $ sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo $ sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key $ sudo yum install jenkins Installation of Java Jenkins需要Java才能运行，但默认情况下，某些发行版不包括此类。要安装Open Java Development Kit（OpenJDK），请运行以下操作： $ sudo yum install java PS: 尽量安装Java 8,RedHat系列自带的JDK 基本都是java 7. What does this package do? 开始时，jenkins将作为一个守护进程启动。更多详情请查看/etc/init.d/jenkins。 创建“jenkins“用户以运行此服务,如果您通过配置文件将其更改为其他用户，则必须更改/var/ log/jenkins，/var/lib/jenkins和/var/cache/jenkins的所有者。 日志文件将被放入/var/log/jenkins/jenkins.log。如果您正在对Jenkins进行故障排除，请检查此文件。 /etc/sysconfig/jenkins 将预先配置参数 默认情况下，Jenkins监听端口8080.使用浏览器访问此端口以开始配置。请注意，内置防火墙可能需要打开才能从其他计算机访问此端口 添加了Jenkins RPM源: /etc/yum.repos.d/jenkins.repo 更多详情可以参考：https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Red+Hat+distributions Installing Jenkins on any system 经常看到有教程是这么写的： Tomcat + Jenkins,其实jenkins再带jetty，那么最简单的方式应该是 $ wet http://mirrors.jenkins.io/war-stable/latest/jenkins.war $ sudo java -jar jenkins.war 上述无论是docker安装 ，rpm安装，deb安装，还是Tomcat + Jenkins 都是对其的封装和润色。 Reference官方文档 | https://jenkins.io/doc/ 官方下载地址 | https://jenkins.io/download/ Jenkins Wiki | https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins 维基百科 | https://zh.wikipedia.org/wiki/Jenkins_(%E8%BD%AF%E4%BB%B6)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>jenkins install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka-REST-Proxy]]></title>
    <url>%2Fkafka-REST-Proxy.html</url>
    <content type="text"><![CDATA[Kafka REST Proxy一、业务场景需求 某公司A，需要把游戏日志传给另外一家公司B。架构大致是，游戏服务器把日志传到kafka消息队列，kafka在到es进行数据分析。由于服务器是公司B自己提供，公司A就需要提供一个外网接口让对方把数据写到云ukafka。 由于ukafka只有内网IP，zookeeper中只能注册一个地址，通过nginx代理或者ssh端口转发都不能做到外网正常使用，除非节点本身有外网IP。这个时候就需要用到Kafka REST Proxy。 二、Kafka REST Proxy 介绍 Kafka REST代理为Kafka集群提供RESTful接口。它可以轻松生成和使用消息，查看集群状态，以及在不使用本机Kafka协议或客户端的情况下执行管理操作。用例示例包括从任何语言构建的任何前端应用程序向Kafka报告数据，将消息提取到尚不支持Kafka的流处理框架，以及脚本管理操作。 kafka rest proxy 是rest api接口，通过这个代理把数据转发到kafka的。主要有两部分组成 - Schema Registry提供元数据的存储和解析。 - Producer的序列化和Consumer的反序列化都会去Schema Registry读取对应的Schema 通过Kafka REST Proxy API接口做代理，把外网传输数据转发到内网kafka中。 相关资料1 https://github.com/confluentinc/kafka-rest相关资料2 https://docs.confluent.io/current/kafka-rest/docs/index.html 三、安装1、安装jdk1.8 以上 下载JDK12cd /usr/local/src/kafkawget -c http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm?AuthParam=1493105955_1f866324e85307d5f9b495e276577b05 安装JDK1234567891011121314# 检查jdk 是否安装rpm -qa | grep jdk# 安装jdkcd /usr/local/src/kafkarpm -ivh jdk-8u131-linux-x64.rpm# 设置环境cat &gt;&gt; /etc/profile&lt;&lt;&quot;EOF&quot;export JAVA_HOME=/usr/java/jdk1.8.0_131export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATHEOF# 加载环境变量. /etc/profile 2、添加相关源 vim /etc/yum.repos.d/confluent.repo12345678910111213[Confluent.dist]name=Confluent repository (dist)baseurl=http://packages.confluent.io/rpm/3.1/6gpgcheck=1gpgkey=http://packages.confluent.io/rpm/3.1/archive.keyenabled=1[Confluent]name=Confluent repositorybaseurl=http://packages.confluent.io/rpm/3.1gpgcheck=1gpgkey=http://packages.confluent.io/rpm/3.1/archive.keyenabled=1 3、安装1yum install confluent-kafka-rest confluent-schema-registry -y 4、修改confluent-schema-registry 配置 vim /etc/schema-registry/schema-registry.properties1234listeners=http://0.0.0.0:8080 ## 提供给kafka-rest 连接的端口kafkastore.connection.url=10.10.41.3x:2181,10.10.187.3x:2181,10.10.87.5x:2181 ## 实际kafka的zookeeperkafkastore.topic=_schemasdebug=false 启动1schema-registry-start /etc/schema-registry/schema-registry.properties 5、修改confluent-kafka-rest配置 vim /etc/kafka-rest/kafka-rest.properties12345#id=kafka-rest-test-server#port=9092 ## 自定义端口 默认 8082schema.registry.url=http://localhost:8080 ## 上面schema 端口zookeeper.connect=10.10.41.3x:2181,10.10.187.3x:2181,10.10.87.5x:2181## 实际kafka的zookeeper 启动1kafka-rest-start /etc/kafka-rest/kafka-rest.properties 测试 发送消息123curl -X POST -H &quot;Content-Type: application/vnd.kafka.json.v1+json&quot; --data &apos;&#123;&quot;records&quot;:[&#123;&quot;value&quot;:&#123;&quot;foo&quot;:&quot;bar2&quot;&#125;&#125;]&#125;&apos; &quot;http://x.x.x.x:8082/topics/opstest&quot; # 正常返回结果&#123;&quot;offsets&quot;:[&#123;&quot;partition&quot;:0,&quot;offset&quot;:5,&quot;error_code&quot;:null,&quot;error&quot;:null&#125;],&quot;key_schema_id&quot;:null,&quot;value_schema_id&quot;:null&#125; 接收消息1234./kafka-console-consumer.sh --zookeeper 10.10.x.x:2181 --from-beginning --topic opstest# 结果&#123;&quot;foo&quot;:&quot;bar&quot;&#125;&#123;&quot;foo&quot;:&quot;bar2&quot;&#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Kafka REST Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka-install]]></title>
    <url>%2Fkafka-install.html</url>
    <content type="text"><![CDATA[系统更新123sudo add-apt-repository ppa:openjdk-r/ppasudo apt-get update sudo apt-get install openjdk-8-jdk 安装 zookeeper1234567wget http://apache.fayea.com/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar xf zookeeper-3.4.10.tar.gz -C /usr/localcd /usr/local/zookeeper-3.4.10/confcp -pv zoo_sample.cfg zoo.cfgvim /usr/local/zookeeper/conf/zoo.cfgmkdir -p /data/zookeeper 安装 kafka1234567wget http://www-eu.apache.org/dist/kafka/0.10.2.1/kafka_2.12-0.10.2.1.tgztar xf kafka_2.12-0.10.2.1.tgz -C /usr/localcd /usr/local &amp;&amp; ln -s kafka_2.12-0.10.2.1 kafkavim /usr/local/kafka/config/server.propertiesnohup bin/kafka-server-start.sh config/server.properties &amp; 安装 supervisor 守护进程12345678910python get-pip.py pip install setuptoolspip install -U setuptoolspip install supervisorecho_supervisord_conf &gt; /etc/supervisord.confmkdir /etc/supervisorsed -i &apos;s#\;\[include\]#\[include\]#&apos; /etc/supervisord.confsed -i &apos;/relative\/directory/a\files = /etc/supervisor/*.ini&apos; /etc/supervisord.confmkdir /data/httplogssupervisord -c /etc/supervisord.conf kafka 启动12./kafka-console-producer.sh --broker-list 10.10.32.92:9092 --topic log./kafka-topics.sh --create --zookeeper 10.10.32.92:2181 --replication-factor 1 --partitions 1 --topic log swap 关闭123echo &quot;vm.swappiness = 1&quot; &gt;&gt; /etc/sysctl.confsysctl vm.swappiness=1swapoff -a &amp;&amp; swapon -a 安装 elasticsearch123456789wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpecho &quot;deb https://artifacts.elastic.co/packages/5.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-5.x.listsudo apt-get update &amp;&amp; sudo apt-get install elasticsearchcp -pv /etc/elasticsearch/elasticsearch.yml&#123;,.default&#125;vim /etc/elasticsearch/elasticsearch.ymlmkdir -m 755 -p /data/elasticsearch/&#123;elasticsearch_logs,elasticsearch_data&#125;chown -R elasticsearch:elasticsearch /data/elasticsearch/etc/init.d/elasticsearch start 安装 node12345wget https://nodejs.org/dist/v6.11.2/node-v6.11.2-linux-x64.tar.xztar xvf node-v6.11.2-linux-x64.tar.xz mv node-v6.11.2-linux-x64 /usr/local/cd /usr/local/ &amp;&amp; ln -s node-v6.11.2-linux-x64/ nodechown root:root -R node-v6.11.2-linux-x64/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>kafka install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS-Certbot]]></title>
    <url>%2FHTTPS-Certbot.html</url>
    <content type="text"><![CDATA[HTTPS-使用Certbot自动配置Let’s Encrypt证书1. HTTPS基本介绍 现在各大厂商都在推行HTTPS，比如谷歌要求多个顶级域名要用HTTPS来加密，苹果要求开发者全部采用HTTPS等等。那什么是HTTPS呢？其实HTTPS只是HTTP的一个拓展，是在HTTP的基础上利用SSL/TLS来加密数据包的。工作流程如下： An overview of the SSL or TLS handshake 图片来自IBM Knowledge Center: An overview of the SSL or TLS handshakehttps://www.ibm.com/support/knowledgecenter/en/SSFKSJ_7.1.0/com.ibm.mq.doc/sy10660_.htm 注意第(2)步Server给Client发送了一个Server certificates，这个里面包含有Server的一些信息，如域名、公司信息、序列号和签名信息组成等，这个证书可以个人生成，也可以由权威机构签发，当然个人的就不受大众信任，而权威机构签发的证书则会被信任。 具体的可以参考：细说 CA 和证书https://www.barretlee.com/blog/2016/04/24/detail-about-ca-and-certs/ 2. Let’s Encrypt CA的证书提供商有许多个，有收费的有免费的，而Let’s Encrypt就是其中之一的免费提供商。https://letsencrypt.org/ 2.1 如何获取Let’s Encript的证书呢？ 要从Let’s Encript获取某个域名的证书，需要证明那你对该域名拥有控制权，对于该证明你可以使用某个使用ACME协议的软件来实现，而Certbot就是官方出的一个ACME客户端。 3. Certbot介绍 先介绍一些Certbot相关概念。 3.1 Authenticators和Installers Certbot支持两种类型的plugin，一种是用来获取和安装证书的，成为称为Authenticators；另外一种是用来安装证书的，称为Installers。有的plugin支持一种，有的两种都支持，如nginx。 安装证书：自动修改配置文件，如修改nginx的某个.conf文件 Authenticators plugin使用certonly命令来获取证书，而Installers plugin使用install命令来安装证书。 3.2 plugin说明 下面列举几个常用的plugin作简要说明： Webroot：本地有运行webserver并且有能力修改其配置，就可以用该种方式（创建隐藏文件.well-known），获取证书时无需暂停webserver的运行。 Standalone：服务器未运行webserver可以使用该方式，要保持80或443端口开放。 Nginx：自动获取和安装证书（自动修改配置文件）。 3.3 Certbot使用流程 Certbot的使用包含以下几个部分： 安装Certbot 生成证书 配置Web Server 更新证书 3.4 Certbot安装 安装Certbot参考：Certbot，直接选择软件和操作系统即可。 https://certbot.eff.org/lets-encrypt/centosrhel7-apache centos 61234wget https://dl.eff.org/certbot-autosudo mv certbot-auto /usr/local/bin/certbotsudo chown root /usr/local/bin/certbotsudo chmod 0755 /usr/local/bin/certbot centos 71yum install python2-certbot-nginx 3.4 获取证书 对于nginx可以使用certbot –nginx来获取和安装证书。1certbot --nginx certonly 1234567891011121314151617181920212223Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator nginx, Installer nginxEnter email address (used for urgent renewal and security notices) (Enter &apos;c&apos; tocancel): 278202253@qq.com- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Please read the Terms of Service athttps://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You mustagree in order to register with the ACME server athttps://acme-v02.api.letsencrypt.org/directory- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(A)gree/(C)ancel: A- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Would you be willing to share your email address with the Electronic FrontierFoundation, a founding partner of the Let&apos;s Encrypt project and the non-profitorganization that develops Certbot? We&apos;d like to send you email about our workencrypting the web, EFF news, campaigns, and ways to support digital freedom.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: nWhich names would you like to activate HTTPS for?选择你需要证书的站点 自己编译安装的nginx 需要增加软连接报错1The error was: NoInstallationError(&quot;Could not find a usable &apos;nginx&apos; binary. Ensure nginx exists, the binary is executable, and your PATH is set correctly.&quot;,) 解决1ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx 报错1nginx: [emerg] open() &quot;/etc/nginx/nginx.conf&quot; failed (2: No such file or directory) 解决1ln -s /usr/local/nginx/conf /etc/nginx 报错123456789101112131415161718192021222324252627certbot --nginx certonlyTraceback (most recent call last): File &quot;/usr/bin/certbot&quot;, line 9, in &lt;module&gt; load_entry_point(&apos;certbot==0.24.0&apos;, &apos;console_scripts&apos;, &apos;certbot&apos;)() File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 378, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 2566, in load_entry_point return ep.load() File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 2260, in load entry = __import__(self.module_name, globals(),globals(), [&apos;__name__&apos;]) File &quot;/usr/lib/python2.7/site-packages/certbot/main.py&quot;, line 17, in &lt;module&gt; from certbot import account File &quot;/usr/lib/python2.7/site-packages/certbot/account.py&quot;, line 17, in &lt;module&gt; from acme import messages File &quot;/usr/lib/python2.7/site-packages/acme/messages.py&quot;, line 7, in &lt;module&gt; from acme import challenges File &quot;/usr/lib/python2.7/site-packages/acme/challenges.py&quot;, line 11, in &lt;module&gt; import requests File &quot;/usr/lib/python2.7/site-packages/requests/__init__.py&quot;, line 58, in &lt;module&gt; from . import utils File &quot;/usr/lib/python2.7/site-packages/requests/utils.py&quot;, line 32, in &lt;module&gt; from .exceptions import InvalidURL File &quot;/usr/lib/python2.7/site-packages/requests/exceptions.py&quot;, line 10, in &lt;module&gt; from .packages.urllib3.exceptions import HTTPError as BaseHTTPError File &quot;/usr/lib/python2.7/site-packages/requests/packages/__init__.py&quot;, line 95, in load_module raise ImportError(&quot;No module named &apos;%s&apos;&quot; % (name,))ImportError: No module named &apos;requests.packages.urllib3&apos; 解决1pip2.7 install --upgrade --force-reinstall &apos;requests==2.6.0&apos; urllib3 获取完之后可以通过certbot certificates命令查看证书： root@node01:~# certbot certificates Saving debug log to /var/log/letsencrypt/letsencrypt.log——————————————————————————-Found the following certs: Certificate Name: www.youdomain.com Domains: www.youdomain.com Expiry Date: 2018-09-03 02:08:54+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/www.youdomain.com/fullchain.pem Private Key Path: /etc/letsencrypt/live/www.youdomain.com/privkey.pem 3.5 配置Web Server 不同Web Server的配置方式不同，这里以Nginx为例，在配置文件youdomain.conf中添加：12345678910111213141516server &#123; listen [::]:80; root /var/www/youdomain; index index.html index.htm; server_name www.yourdomain.com; charset utf-8; #................. listen 443 ssl; ssl_certificate /etc/letsencrypt/live/www.yourdomain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.yourdomain.com/privkey.pem; &#125; 需要了解Nginx的使用 配置完之后更新配置即可(nginx -s reload)，到这里证书配置就完成了，正常情况下该域名HTTPS就可以访问了。 3.7 更新证书 由于Let’s Encrypt颁发的证书的有效期只有90天，这就需要更新证书。 Renewing certificateshttps://certbot.eff.org/docs/using.html#renewing-certificates 更新命令1certbot renew 计划任务自动更新12crontab -e15 2 20 */2 * certbot renew 如果使用了nginx plugin，则更新时需要使用certbot renew –quiet –installer node，否则会自动安装证书导致错误。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>https Certbot Let’s Encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-valine]]></title>
    <url>%2Fhexo-valine.html</url>
    <content type="text"><![CDATA[hexo 评论页面报错 Code 403: 访问被api域名白名单拒绝，请检查你的安全域名设置. 关于Valine和LeanCloud Valine是一款基于Leancloud的快速、简洁且高效的无后端评论系统。Valine诞生于2017年8月7日，理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo等博客程序在使用Valine。她完全不需要账号，一个昵称就够了，为了方便以后联系也可以留下邮箱，甚至可以如路人般水一下而不留一点痕迹，给人一种清新脱俗、小家碧玉的感觉，这多少符合现在互联网顶贴水楼的习惯。同时她又支持Gravatar的头像和Markdown的语法，方便大家展现个性化的头像和多变的评论样式。另外Valine还支持文章阅读量统计，next主题也是集成此功能的，如需要请在主题配置文件中搜索“leancloud_visitors”字段启用。具体请网络搜索或查看官方说明 .https://valine.js.org/visitor.html LeanCloud是行业领先的一站式后端云服务提供商，专注于为开发者提供一流的工具、平台和服务。LeanCloud于2013年9月发布，主要提供包括数据存储、文件存储与CDN、消息推送和实时通信在内的后端云服务，同时提供支撑后端代码的云引擎和云函数等开发工具，全面涵盖移动开发的需求；同时也提供了易于集成的全平台SDK，支持iOS、Android应用和游戏开发，以及包括微信小程序在内的web开发。帮助客户脱繁重的后端开发负担，最大限度地降低开发成本、缩短开发周期、加快迭代速度，在激烈的市场竞争中胜出。https://leancloud.cn/ 在snippet主题中启用Valine 本人使用的是Hexo博客系统的snippet（v6.0.5）版本主题，所有操作设置仅对应该系统和主题版本，其他博客系统或主题请参考官方说明。在此提一下next主题现在主要有v5.1.x和v6.x两个版本，其中v5.1.x版本现已停止更新并迁移到新的仓库升级为v6.x，具体请参考官方说明。https://github.com/shenliyang/hexo-theme-snippet 获取APP ID 和 APP Key注册LeanCloud （过程跳过），注册后请到注册邮箱内验证邮箱。登录后点击页面右上角的控制台，进去后点击创建应用，应用名称随便填(如valine)并创建，之后将鼠标移到应用标签上并点击设置按钮 进去后点击设置中的“应用Key”，就可以看到APP ID 和 APP Key了。 配置next主题 请打开next的配置文件_config.yml，搜索valine找到下面的字段，复制上面的APP ID和APP Key分别粘贴到appid和appkey，注意ID和Key是可以复制的，冒号后面空一格再粘贴。将enable: false改为enable: true即可启用Valine评论，其他的选项除非你知道是什么，否则请保持默认设置。如果已开启其他评论，请先关闭。然后执行hexo clean和 hexo s 两个命令进行本地预览，查看是否正常启用。1234567891011## Valine评论valine: enable: true appId: ID appKey: Key placeholder: 说点什么吧 notify: false verify: false avatar: mm meta: nick,mail pageSize: 10 管理评论数据 回到刚才的网页页面，点击“存储”(或者登录&gt;选择你创建的应用&gt;存储)，应该可以看到“Comment”文件，点击就可以查看管理评论数据了。如果没有“Comment”文件，你可以自己评论一条然后刷新管理页面。 关于自带的评论邮件提醒功能请谨慎使用，首先应”登录Leancloud&gt;选择你的评论应用&gt;设置&gt;邮件模板“，然后参照官方说明进行设置并保存。请注意修改链接为你的博客或者网站首页。由于邮件提醒功能使用的Leancloud的密码重置邮件提醒，只能传递昵称、邮箱两个属性，所以邮件提醒链接无法直达指定文章页。发送次数过多，可能会暂时被Leancloud 屏蔽邮件发送功能。https://valine.js.org/notify.html Valine目前使用的是Gravatar作为评论列表头像。请自行登录或注册Gravatar，然后修改自己的头像。评论的时候，留下在Gravatar注册时所使用的邮箱即可。如果你修改了头像后发现没有更新，请不要慌张，因为gravatar.cat.net 有七天的缓存期，安静的等待吧。 当然，你也可以配合使用 panjunwen 开发的 Valine-Admin (https://github.com/panjunwen/Valine-Admin)进行评论数据管理和邮件提醒等。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>hexo valine LeanCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+GitHub]]></title>
    <url>%2Fhexo-GitHub.html</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 1、什么是 Hexo？ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 2、部署2.1 部署环境 centos 7.5 hexo nginx github git cloudflare （cdn + 域名） 2.2 安装Git Windows：下载并安装 git. Mac：使用 Homebrew, MacPorts 1brew install git Linux (Ubuntu, Debian)： 1sudo apt-get install git-core Linux (Fedora, Red Hat,CentOS)： 1sudo yum install git-core 2.3安装 Node.js 安装 Node.js 的最佳方式是使用 nvm。 cURL:1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh Wget:1$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js。1$ nvm install stable 或者您也可以下载 安装程序 来安装。 3、安装hexo 执行以下命令:1$ npm install -g hexo-cli 安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，指定文件夹的目录如下： 1234567├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 接下来要做的就是修改配置文件了，在根目录下找到文件：_config.yml,安装自己的需要进行修改，一般修改下网站标题，作者就可以了 12345678910111213# Sitetitle: Fenpho //网站标题subtitle: //网站副标题description://网站描述author: fenpho//网站作者language: zh-CN//语言timezone://时区# URLand root as &apos;/child/&apos;url: https://fenpho.github.io/ //网站链接root: / //网站根目录permalink: :year/:month/:day/:title/ //时间格式 具体的修改方法可以参考官网：Hexo 4、本地预览 生成静态文件123$ hexo generate //也可以使用缩写 : $ hexo g 启动服务器默认情况下，访问网址为：http://localhost:4000/。1$ hexo server 运行网上面的命令后，打开浏览器输入http://localhost:4000/即可看到页面了，有木有很激动 5、选取主题hexo链接 接下来你需要做进一步的网站美化工作，到官网去选取一个喜欢的主题吧！我采用了一个叫做TKL的主题： 5.1 下载 确定需要使用的主体之后，打开主题的官网下载安装主题即可： 运行如下命令（去主题的github页面找类似下面的命令）1$ git clone https://github.com/shenliyang/hexo-theme-snippet.git 命令中的后面的hexo-theme-snippet为存储的目录名字，可以随便修改 5.2 更新 更新主题相关文件12cd themes/hexo-theme-snippetgit pull 5.3 使用 修改根目录下的博客配置文件 _config.yml （不是主题下面的配置文件）主题属性 theme 为 hexo-theme-snippet.配置主题，这个需要根据不同主题的说明来配置，也可以不配置好了，主题安装好了，此时需要使用如下命令： 12hexo clean &amp;&amp; hexo ghexo server 完成后刷新页面看一下吧 6、添加文章 创建一条博文，运行下面的命令，或者直接新建一个Markdown文件，新建文件需要手动添加文章头部（注意目录source/_posts）1hexo new &quot;your-post-name&quot; 如果想要在新建的同时生成对应的文件夹，用于存放文档的资源文件，如图片，音视频等：将配置文件中的post_asset_folder的值从false改为true即可1post_asset_folder: true 7、文章分类7.1 categories 在根目录下scaffolds/post.md中，添加一行categories:（同理可应用在page.md和photo.md）123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;categories: &apos;工具&apos;top：100--- 7.2 tags 在文章的开头配置1234567891011---layout: posttitle: 标题date: 2017-05-26 09:00author: &quot;zj&quot;categories: &apos;工具&apos; - 目录名字 tags: - 标签1 - 标签2--- 7.3 归档展示样式 配置博客首页归档展示样式。修改主题的配置文件themes目录下对应的主题下面的_config.yml中:123456&gt; # 博客首页展示文本/访问路径/自定义归档名称menu: home: / essay: /categories/随笔 write: /categories/写作 about: /about 8、添加文章置顶功能 原理：在Hexo生成首页HTML时，将top值高的文章排在前面，达到置顶功能。修改Hexo文件夹下的node_modules/hexo-generator-index/lib/generator.js，在生成文章之前进行文章top值排序。以下是最终的generator.js12345678910111213141516171819202122232425262728&apos;use strict&apos;;var pagination = require(&apos;hexo-pagination&apos;);module.exports = function(locals)&#123; var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; if(a.top == b.top) return b.date - a.date; else return b.top - a.top; &#125; else if(a.top &amp;&amp; !b.top) &#123; return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; &#125;); var paginationDir = config.pagination_dir || &apos;page&apos;; return pagination(&apos;&apos;, posts, &#123; perPage: config.index_generator.per_page, layout: [&apos;index&apos;, &apos;archive&apos;], format: paginationDir + &apos;/%d/&apos;, data: &#123; __index: true &#125; &#125;);&#125;; 9、部署到GitHub9.1 在 GitHub 上的操作 新建一个 Repository在 Repository name 下填写 yourname.github.io,Description (optional) 下填写一些简单的描述（不写也没有关系），如图所示： 创建成功之后，进入仓库的设置（点击setting）界面如下图所示： 找到pages选项，选择master branch作为主页 简单两步 yourname.github.io 这个域名就配置成功了。 创建key服务器上生成key123ssh-keygen -t rsa -C &quot;xxx@qq.com&quot;cat /root/.ssh/id_rsa.pub 把上面cat 的key 添加 github 位置 settings deploy-keys注意上传的权限要给 测试1ssh -T git@github.com Ok1Hi xxxx! You ve successfully authenticated, but GitHub does not provide shell access. 9.2、本地操作 为 Hexo 安装 Git 插件安装 hexo-deployer-git，否则会报 ERROR Deployer not found: git 的错误。1npm install hexo-deployer-git --save 修改你的 _config.yml 配置文件，在结尾处加上如下内容：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:fenpho/fenpho.github.io.git branch: master 注意repo中的地址为你自己新建的仓库的路径 生成静态文件和部署：1hexo g &amp; d 最后出现如下提示就代表成功啦！1INFO Deploy done: git]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>hexo GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Charles]]></title>
    <url>%2FCharles.html</url>
    <content type="text"><![CDATA[Charles其实是一款代理服务器，通过过将自己设置成系统（电脑或者浏览器）的网络访问代理服务器，然后截取请求和请求结果达到分析抓包的目的。该软件是用Java写的，能够在Windows，Mac，Linux上使用。安装Charles的时候要先装好Java环境。 Charles的主要功能： （1）截取Http 和 Https 网络封包。 （2）支持重发网络请求，方便后端调试。 （3）支持修改网络请求参数。 （4）支持网络请求的截获并动态修改。 （5）支持模拟慢速网络。 安装方式官方4.1.2版本破解:charles.jar文件 破解方式 先把官方的4.1.2版本安装好以后 替换/Applications/Charles.app/Contents/Java/charles.jar 完成破解. iOS设备的抓包 1 在 Mac 中打开 Charles 应用. 2 设置手机HTTP代理: 确保iOS设备与Mac设备在同一局域网内, 添加代理ip地址(Mac内网ip)和端口号(8888),这里以iPhone为例 3 在iOS设备上访问接口数据, 在Charles弹出的确认窗(mac设备屏幕上)中选择Allow, 允许即可 https 抓包 1 如果要抓https的包, 还需要在iOS设备(手机端，需要抓包的程序端) 上多做一步, 用iOS设备的Safari浏览器访问: http://www.charlesproxy.com/getssl 浏览器会下载SSL证书并提示安装.2 安装后在Charles中选择需要代理地址, 右击, 选中 Enable SSL Proxying，这样就可以抓取 HTTPS 数据包了. 安卓设备的抓包 类似的设置 引用charles的破解方法]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>charles</tag>
      </tags>
  </entry>
</search>
