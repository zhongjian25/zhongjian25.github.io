<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[qiniu_bucket_domain]]></title>
    <url>%2Fqiniu-bucket-domain.html</url>
    <content type="text"><![CDATA[环境需求 cdn 在腾讯云 存储在七牛云 每次配置cdn,都需要找七牛云配置源站域名绑定到相应的存储上面。 但七牛云的控制台上并没有这个信息。 只能更具API 来获取 七牛API获取 Bucket 空间域名 代码 Python2.7123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#!/usr/bin/env python# -*- coding: utf-8 -*-from qiniu import Auth# import bucketimport platformimport requests# from requests.auth import AuthBasefrom qiniu.compat import is_py2, is_py3from qiniu import configimport qiniu.auth### 版本号可能会变,https://github.com/qiniu/python-sdk/blob/master/qiniu/__init__.py 这边去确认__version__ = &apos;7.2.6&apos;_sys_info = &apos;&#123;0&#125;; &#123;1&#125;&apos;.format(platform.system(), platform.machine())_python_ver = platform.python_version()USER_AGENT = &apos;QiniuPython/&#123;0&#125; (&#123;1&#125;; ) Python/&#123;2&#125;&apos;.format( __version__, _sys_info, _python_ver)_session = None_headers = &#123;&apos;User-Agent&apos;: USER_AGENT&#125;access_key = &apos;填入ak&apos;secret_key = &apos;填入sk&apos;bucket_name = &quot;存储空间名&quot;auth = Auth(access_key, secret_key)def _get(url, params, auth): try: r = requests.get( url, params=params, auth=qiniu.auth.RequestsAuth(auth) if auth is not None else None, timeout=config.get_default(&apos;connection_timeout&apos;), headers=_headers) except Exception as e: return None, ResponseInfo(None, e) return __return_wrapper(r)def __return_wrapper(resp): if resp.status_code != 200 or resp.headers.get(&apos;X-Reqid&apos;) is None: return None, ResponseInfo(resp) resp.encoding = &apos;utf-8&apos; ret = resp.json(encoding=&apos;utf-8&apos;) if resp.text != &apos;&apos; else &#123;&#125; if ret is None: # json null ret = &#123;&#125; return ret, ResponseInfo(resp)class ResponseInfo(object): &quot;&quot;&quot;七牛HTTP请求返回信息类 该类主要是用于获取和解析对七牛发起各种请求后的响应包的header和body。 Attributes: status_code: 整数变量，响应状态码 text_body: 字符串变量，响应的body req_id: 字符串变量，七牛HTTP扩展字段，参考 http://developer.qiniu.com/docs/v6/api/reference/extended-headers.html x_log: 字符串变量，七牛HTTP扩展字段，参考 http://developer.qiniu.com/docs/v6/api/reference/extended-headers.html error: 字符串变量，响应的错误内容 &quot;&quot;&quot; def __init__(self, response, exception=None): &quot;&quot;&quot;用响应包和异常信息初始化ResponseInfo类&quot;&quot;&quot; self.__response = response self.exception = exception if response is None: self.status_code = -1 self.text_body = None self.req_id = None self.x_log = None self.error = str(exception) else: self.status_code = response.status_code self.text_body = response.text self.req_id = response.headers.get(&apos;X-Reqid&apos;) self.x_log = response.headers.get(&apos;X-Log&apos;) if self.status_code &gt;= 400: ret = response.json() if response.text != &apos;&apos; else None if ret is None or ret[&apos;error&apos;] is None: self.error = &apos;unknown&apos; else: self.error = ret[&apos;error&apos;] if self.req_id is None and self.status_code == 200: self.error = &apos;server is not qiniu&apos; def ok(self): return self.status_code == 200 and self.req_id is not None def need_retry(self): if self.__response is None or self.req_id is None: return True code = self.status_code if (code // 100 == 5 and code != 579) or code == 996: return True return False def connect_failed(self): return self.__response is None or self.req_id is None def __str__(self): if is_py2: return &apos;, &apos;.join( [&apos;%s:%s&apos; % item for item in self.__dict__.items()]).encode(&apos;utf-8&apos;) elif is_py3: return &apos;, &apos;.join([&apos;%s:%s&apos; % item for item in self.__dict__.items()]) def __repr__(self): return self.__str__()if __name__ == &quot;__main__&quot;: options = &#123; &apos;tbl&apos;: bucket_name, &#125; url = &apos;http://api.qiniu.com/v6/domain/list&apos; print(bucket_name) ret, info = _get(url, options, auth) print(info)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>七牛云 Bucket 空间域名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-disk]]></title>
    <url>%2Fwindow-disk.html</url>
    <content type="text"><![CDATA[如何在Windows Server上启用磁盘清理工具默认情况下，Windows Server2008/2008R2/2012/2012R2 中不存在磁盘清理可执行文件cleanmgr.exe和关联的磁盘清理按钮。（Win2016默认是安装了磁盘清理cleanmgr服务） 那么如何启用磁盘清理工具： 转到“程序和功能”，然后在“功能”部分中，启用/安装 “桌面体验”。 这样做的缺点是，你需要在安装后重新启动服务器，并在服务器上安装其他不需要的组件。 [推荐] - 如果你的系统不是Windows Server 2012 R2 ，那么你真正需要做的就是将服务器上已有的一些文件复制到特定的系统文件夹中(找不到可以默认全局搜一下cleanmgr) 为了使用cleanmgr.exe，你需要复制服务器上已存在的两个文件，cleanmgr.exe和cleanmgr.exe.mui。参考下表查找操作系统的文件。 Operating System Architecture File Location Windows Server 2008 R2 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.1.7600.16385_none_c9392808773cd7da\cleanmgr.exe Windows Server 2008 R2 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.1.7600.16385_en-us_b9cb6194b257cc63\cleanmgr.exe.mui Windows Server 2008 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.0.6001.18000_en-us_b9f50b71510436f2\cleanmgr.exe.mui Windows Server 2008 64-bit C:\Windows\winsxs\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.0.6001.18000_none_c962d1e515e94269\cleanmgr.exe Windows Server 2008 32-bit C:\Windows\winsxs\x86_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.0.6001.18000_en-us_5dd66fed98a6c5bc\cleanmgr.exe.mui Windows Server 2008 32-bit C:\Windows\winsxs\x86_microsoft-windows-cleanmgr_31bf3856ad364e35_6.0.6001.18000_none_6d4436615d8bd133\cleanmgr.exe Windows Server 2012 64-bit C:\Windows\WinSxS\amd64_microsoft-windows-cleanmgr_31bf3856ad364e35_6.2.9200.16384_none_c60dddc5e750072a\cleanmgr.exe Windows Server 2012 64-bit C:\Windows\WinSxS\amd64_microsoft-windows-cleanmgr.resources_31bf3856ad364e35_6.2.9200.16384_en-us_b6a01752226afbb3\cleanmgr.exe.mui 找到文件后，将它们移动到以下位置（Server 2012非R2及更早版本）： 将Cleanmgr.exe复制 到 %systemroot%\System32. 将Cleanmgr.exe.mui复制 到 %systemroot%\System32\zh-CN. 现在可以通过 从命令提示符运行Cleanmgr.exe来启动磁盘清理工具。 注意：Windows Server 2012 R2 必须安装桌面体验。使用Powershell命令 PS&gt; Install-WindowsFeature Desktop-Experience 参考链接Disk Cleanup on Windows Server 2008 Without Installing Desktop Experience How to enable the Disk Cleanup tool on Windows Server 2008 R2 Disk Cleanup option on drive’s general properties and cleanmgr.exe is not present in Windows Server 2008 or Windows Server 2008 R2 by default)]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘清理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-base]]></title>
    <url>%2Flinux-base.html</url>
    <content type="text"><![CDATA[!参考由于之前的线上的版本是CentOS6，鉴于该系统实在老旧目前正慢慢的往CentOS7和Ubuntu16上升级。 一般如果使用云服务器，厂商都会对镜像做一些优化，不太需要我们怎么操心。 新版的系统CentOS7和Ubuntu16对比CentOS6进步不是一点点，至少烦人的Python2和Gcc版本过低问题，在这里是完全没有了。 一、SSHD调整1.1、配置文件 备份配置文件 1$ cp -pv /etc/ssh/sshd_config&#123;,.old&#125; 修改端口 12$ sed -i &quot;s/#Port 22$/Port 5831/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/Port 22$/Port 5831/g&quot; /etc/ssh/sshd_config 禁用 DNS查询 123$ -i &quot;s/#UseDNS yes/UseDNS no/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/#PubkeyAuthentication yes/PubkeyAuthentication yes/g&quot; /etc/ssh/sshd_config 密钥登陆 12345$ sed -i &quot;s/#AuthorizedKeysFile/AuthorizedKeysFile/g&quot; /etc/ssh/sshd_config# 设置ssh在接收登录请求之前是否检查用户家目录和rhosts文件的权限和所有权。这通常是必要的，因为新手经常会把自己的目录和文件设成任何人都有写权限。$ sed -i &quot;s/#StrictModes yes/StrictModes yes/g&quot; /etc/ssh/sshd_config 开启或者禁止密码登陆 1234# 建议是能用密钥，就不需要在用密码了。如果是个人用户，保存好密钥，修改好端口那么服务器正常 就不会被人从SSHD这边攻破；# 如果是独立IP的企业用户或者有堡垒机，那么在开启密码登陆的时候 应该要做好IP/权限限制$ sed -i &quot;s/#PasswordAuthentication yes/PasswordAuthentication yes/g&quot; /etc/ssh/sshd_config$$ sed -i &quot;s/PasswordAuthentication no/PasswordAuthentication yes/g&quot; /etc/ssh/sshd_config 禁止空密码 12$ sed -i &quot;s/PermitEmptyPasswords yes/PermitEmptyPasswords no/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/#PermitEmptyPasswords no/PermitEmptyPasswords no/g&quot; /etc/ssh/sshd_config 开启或者禁止root登陆 1234# 现有的Redhat系的Linux都是默认允许root登陆的;# Ubuntu的Linux默认都是禁止root登陆(但是大部分的云服务器商，在初始化的时候都会默认开)。$ sed -i &quot;s/#PermitRootLogin yes/PermitRootLogin yes/g&quot; /etc/ssh/sshd_config$ sed -i &quot;s/PermitRootLogin no/PermitRootLogin yes/g&quot; /etc/ssh/sshd_config 最新版本的Redhat/CentOS 7.4已经弃用RSAAuthentication，这里就提一下。 1$ sed -i &quot;s/#RSAAuthentication yes/RSAAuthentication yes/g&quot; /etc/ssh/sshd_config 二、SSHD密钥生成 直接使用ssh-keygen生成密钥 123$ ssh-keygen -b 4096or$ ssh-keygen -t rsa -b 4096 将生成好的私钥自己保存好，公钥复制到机器上去，比如： 12345$ ssh_rsa=&quot;ssh-dss AAAAB3NzaC1k ... Zk=&quot;$ mkdir /root/.ssh$ chmod 700 /root/.ssh$ echo $&#123;ssh_rsa&#125; &gt;&gt; /root/.ssh/authorized_keys$ chmod 600 /root/.ssh/authorized_keys 三、常用的软件现在的云厂商在他们默认的镜像里面已经安装好大部分的软件包。 Redhat/CentOS Redhat默认没有的依赖包还是很多的。12345678910111213141516171819202122#常用的epel源一般是要安装上去，如果你不放心这种非官方维护的源，那么就不要安装了。$ yum -y install epel-release# 生成缓存$ yum makecache#常用的工具包$ yum -y install wget bash-completion zsh git mlocate man unzip procps-ng\ net-tools bind-utils tcpdump nmap mtr psmisc tree screen dmidecode\ at openssl openssl-devel readline-devel telnet ntpdate coreutils\ deltarpm nss#接下是开发工具全家桶，基本上这些安装完，后面编译什么东西都很顺利了。。。$ yum -y install vim gcc gcc-c++ make cmake autoconf automake \ texinfo pcre pcre-devel zlib-devel zlib ncurses ncurses-devel\ bison bison-devel curl curl-devel glibc glibc-devel glib2 glib2-devel\ bzip2 bzip2-devel libxslt libxslt-devel libxml2 libxml2-devel \ libxml2-static gd gd-devel freetype freetype-devel libjpeg libjpeg-devel\ libpng libpng-devel openldap openldap-devel openssl openssl-devel \ readline-devel expat-devel gettext-devel libicu-devel perl-Digest-SHA \ deltarpm perl-devel nss Ubuntu Ubuntu/Debian默认安装的依赖包基本是完全满足我们正常的需求了。1234567891011121314151617181920212223$ sudo apt-get update#development tools$ apt-get -y install build-essential git autoconf automake cmake pkg-config \ libperl-dev python-dev python3-dev python-pip python3-pip libssl-dev \ libpcre3-dev libpcrecpp0 libxslt1-dev libcurl4-openssl-dev libxml2 \ libxml2-dev libreadline-dev libreadline6-dev libtinfo-dev#Security tools$ apt-get -y install nmap libpam-pwquality#network tools$ apt-get -y install traceroute tcpdump nload#imgs &amp; font$ apt-get -y install imagemagick libjpeg-dev libjpeg8-dev libpng12-dev libgd2-dev \ libfreetype6 libfreetype6-dev#常用的工具$ apt-get -y install unzip lrzsz screen tree sysv-rc-conf unattended-upgrades$ apt-get -y autoremove$ update-grub 更新CA证书 1$ update-ca-certificates --fresh 设置自动更新安全补丁(可选) 12345$ vim /etc/apt/apt.conf.d/10periodic APT::Periodic::Update-Package-Lists &quot;1&quot;; APT::Periodic::Download-Upgradeable-Packages &quot;1&quot;; APT::Periodic::AutocleanInterval &quot;7&quot;; APT::Periodic::Unattended-Upgrade &quot;1&quot;; 四、修改sudo, 支持sudo无密码(可选)主要是针对Ubuntu的用户，大部分的Redhat/CentOS用户都喜欢root。1234$ sudo cp -pv /etc/sudoers /etc/sudoers.old# 建议是用visudo来修改/etc/sudoers。$ sudo vim /etc/sudoers xiaoqiang ALL=(ALL) NOPASSWD: ALL 五、网络 时间同步 时间同步的话，建议如果对时间敏感的业务要做一个计划任务1$ /usr/sbin/ntpdate -u pool.ntp.org &gt;/dev/null 2&gt;&amp;1;/sbin/hwclock --systohc &gt;/dev/null 2&gt;&amp;1 修改DNS 如果使用云服务器，正常是不建议直接修改他们已经配置好的DNS。 我们可以在原先的基础上加上几条用来备份。 Redhat/CentOS 12$ vim /etc/resolv.conf dns-nameservers 1.1.1.1 Ubuntu 不能直接修改/etc/resolv.conf(你下一次重启或者重启网络服务之后，就会失效，如果你需要一个临时的连接一个dns的话，那么这是一个好的选择) 方法112$ sudo vim /etc/network/interfaces dns-nameservers 1.1.1.1 方法212$ sudo vim /etc/resolvconf/resolv.conf.d/base nameserver 1.1.1.1 修改完之后保存，然后执行1$ sudo resolvconf -u 然后，你会发现/etc/resolv.conf文件中多了几行，这几行是resolve程序自动写入的：123# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTENnameserver 1.1.1.1 六、系统优化 limits.conf 修改open files , 默认为102412345678先使用`ulimit -n`查看当前的open files，如果是默认的值,则修改$ sudo ulimit -n$ sudo ulimit -n 65535$ sudo vim /etc/security/limits.conf * soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 swapfile分区 小内存的机器，难免会用到swap，这里先看看怎么创建swap分区1234$ sudo dd if=/dev/zero of=/tmp/swapfile06 bs=1M count=4000$ sudo chmod 600 /tmp/swapfile06$ sudo mkswap /tmp/swapfile06$ sudo swapon /tmp/swapfile06 然后我们应该让系统优先使用内存，这样可以有效的避免OOM。 修改vm.swappiness，这个系统默认值为30。1234$ sysctl -a | grep vm.swappines$ sysctl -w vm.swappiness = 1$ vim /etc/sysctl.conf vm.swappiness = 1 sysctl.conf(可选) sysctl.conf的调优就复杂了。网络上有很多关于sysctl.conf的调优教程。 个人认为那些教程有点误人子弟的味道，因为sysctl.conf涉及到内存，网络带宽，TCP/IP堆栈和虚拟内存系统等高级选项，用sysctl可以读取设置超过五百个系统变量。而且不同德内核版本sysctl.conf里面的参数也不一定相同。 在这种情况下其实是很难有一个通用的sysctl.conf来应对全部的业务场景。 下面是金山云Ubuntun16系统的sysctl.conf，经供参考。12345678910111213141516171819202122232425$ cat sysctl.confnet.ipv4.ip_forward = 1net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1net.bridge.bridge-nf-call-ip6tables = 0net.bridge.bridge-nf-call-iptables = 0net.bridge.bridge-nf-call-arptables = 0kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 1024 65535net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.eth0.rp_filter = 0net.ipv4.conf.eth1.rp_filter = 0net.ipv4.conf.all.arp_announce = 2net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.eth0.arp_announce = 2net.ipv4.conf.eth1.arp_announce = 2 IP欺骗防护1234$ /etc/host.conforder hosts,bindmulti onnospoof on 七、密码复杂度 CentOS/Redhat的密码复杂度 12345678是通过配置/etc/pam.d/system-auth-ac或者/etc/pam.d/system-auth来实现的,下面是一个例子设置密码复杂度：密码至少14位;与前一次密码至少有三个位不同;大、小写字母，字数都至少2个。$ cp -rvp /etc/pam.d/system-auth&#123;,.old&#125;$ sed -i &apos;s/password requisite/#password requisite/&apos; /etc/pam.d/system-auth$ sed -i &apos;/pam_cracklib.so/a \password requisite pam_cracklib.so try_first_pass retry=6 type= minlen=14 difok=3 ucredit=2 lcredit=2 dcredit=2&apos; /etc/pam.d/system-auth Ubuntu使用crablib实现系统密码复杂度管理 1234567891011121314151617181920安装软件包：$ apt-get install libpam-cracklib修改PAM配置文件：$ vim /etc/pam.d/common-password在 &quot;password requisite pam_cracklib.so&quot;后加上参数retry=N：用户最多可以几次输入密码后报错。默认是1次。difok=N：新密码有几个字符不能和旧密码相同，默认是5个。另外如果新密码有1/2的字符于旧不同，也会被接受。diginore=N：默认当新密码有23个字符时，difok选项会被忽略。minlen=N：最小密码长度。dcredit=N：阿拉伯数字个数。N&gt;=0，代表新密码最多可以有多少个阿拉伯数字；N&lt;0，最少要有多少个数字。ucredit=N：大写字母个数。N&gt;=0，代表新密码最多可以有多少大写字母；N&lt;0，最少要有多少个大写字母。lcredit=N：小写字母个数。N&gt;=0，代表新密码最多可以有多少小写字母；N&lt;0，最少要有多少个小写字母。ocredit=N：特殊字符个数。N&gt;=0，代表新密码最多可以有多少特殊字符；N&lt;0，最少要有多少个特殊字符。例如： 密码最多尝试3次，新密码最短8个字符，要有3个字符不能与旧密码相同，最少要有1个数字、1个大写字母、1个小写字母、1个特殊字符。password requisite pam_cracklib.so retry=3 minlen=8 difok=3 dcredit=-1 lcredit=-1 ocredit=-1 ucredit=-1 八、防火墙/selinux防火墙学问就很深，改天写点教程吧，这里写不完的。。。 说说怎么临时和永久关闭Selinux(Selinux目前是redhat系的Linux预装的安全软件，功能十分强大，但是对新手还是要有一段时间的学习期) 临时关闭 123456$ getenforce Enforcing$ setenforce 0$ getenforce Permissive 永久关闭： 12345$ vim /etc/sysconfig/selinuxSELINUX=enforcing 改为 SELINUX=disabled重启系统reboot]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux主机初始化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPSec VPN]]></title>
    <url>%2FIPSec-VPN.html</url>
    <content type="text"><![CDATA[安装 openswan 及其环境一、 openswan 介绍OpenSWan是linux选Ipsec及I2tp协议的一个不错的实现方案。他支持和ipsec相关的大多数的扩展（RFC+IETF drafts）。Openswan项目起源于FreeS/WAN 2.04项目，该项目的功能很强大，可以很大程度上保证数据在跨网传输中的安全性、完整性，特别是通过它，可以很好地实现跨机房或异地办公场所实现局域网互联解决方案，如果和openvpn工具配合，可以实现将注入门户网站的多机房互访及vpn的各种强大解决方案. 能实现 IPsec 的目前总体上有 openswan，libreswan，strongswan 这3种。 libreswan 是基于 openswan 的 fork，所以现在各个发行版基本已经看不到 openswan 的身影了。 当然也有使用 strongswan 的。 二、环境实现目标：外网服务器和公司网络打通,实现内网互通： 环境: 外部服务器: （外网）106.75.20.16 (内) 10.10.68.61 （VPN） 测试 10.10.68.62 公司: (外网) 58.22.123.82（内）192.168.99.168 （VPN） 测试 192.168.99.169 架构图 三、安装 openswan 及其环境(两台都要装)3.1 软件安装centos7:123yum -y install ppp libreswan xl2tpd firewalld lsofyum install -y openswan centos6:12345678yum -y remove libevent-develyum -y install libevent2-develyum -y install nss-devel nspr-devel pkgconfig pam-devel \ libcap-ng-devel libselinux-devel lsof \ curl-devel flex bison gcc ppp make iptables gmp-devel \ fipscheck-devel unbound-devel xmlto libpcap-devel xl2tpdyum install -y openswan Ubuntu:12apt-get updateapt-get install -y openswan lsof (ubuntu 会交互安装，第一个询问启用 X.509 证书的时候选择 no，第二个只要点 ok 就可以。) 3.2、开启 linux 主机的路由功能（所有为ipsec vpn server 的主机都要开启）12345678910# vim /etc/sysctl.conf## 开启主机路由转发net.ipv4.ip_forward = 1## 关闭源路由验证net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.eth0.rp_filter = 0net.ipv4.conf.eth1.rp_filter = 0## 关闭icmp重定向# sysctl -a | egrep &quot;ipv4.*(accept|send)_redirects&quot; | awk -F &quot;=&quot; &apos;&#123;print$1&quot;= 0&quot;&#125;&apos; &gt;&gt; /etc/sysctl.conf 修改完成后执行 sysctl -p 加载配置。 3.3 检测服务正常（所有为 ipsec vpn server 的主机）12345# service ipsec startStarting pluto IKE daemon for IPsec: . [ OK ]# service ipsec statuspluto (pid 23914) is running...IPsec connections: loaded 3, active 1 3.4、在控制台上的防火墙添加 ipsec vpn 所用的端口两边开启UDP 端口500，4500 3.4 测试udp端口1234nc -vuz 58.22.123.82 500Connection to 58.22.123.82 500 port [udp/isakmp] succeeded! nc -vuz 58.22.123.82 4500Connection to 58.22.123.82 4500 port [udp/isakmp] succeeded! 3.5 VPN自动启动1chkconfig ipsec on 将/etc/ipsec.conf 文件中的 auto=add 改为 auto=start 四、验证环境ipsec verify （一个 N/A 和一个 DISABLED 不影响 ipsec vpn 的建立，Ubuntu 主机可能在checking /bin/sh 会多一个 warning，也不影响。）12345678910111213141516171819202122# ipsec verifyVerifying installed system and configuration filesVersion check and ipsec on-path [OK]Libreswan 3.15 (netkey) on 2.6.32-431.1.2.0.1.el6.x86_64Checking for IPsec support in kernel [OK] NETKEY: Testing XFRM related proc values ICMP default/send_redirects [OK] ICMP default/accept_redirects [OK] XFRM larval drop [OK]Pluto ipsec.conf syntax [OK]Hardware random device [N/A]Two or more interfaces found, checking IP forwarding [OK]Checking rp_filter [OK]Checking that pluto is running [OK] Pluto listening for IKE on udp 500 [OK] Pluto listening for IKE/NAT-T on udp 4500 [OK] Pluto ipsec.secret syntax [OK]Checking &apos;ip&apos; command [OK]Checking &apos;iptables&apos; command [OK]Checking &apos;prelink&apos; command does not interfere with FIPSChecking for obsolete ipsec.conf options [OK]Opportunistic Encryption [DISABLED] 五、配置服务5.1 配置认证 key（所有为 ipsec vpn server 的主机）123456# vim /etc/ipsec.secrets##include /etc/ipsec.d/*.secrets##源IP 目标IP: PSK &quot;(key)&quot; （0.0.0.0 即为所有 vpn 都使用这个 key）0.0.0.0 0.0.0.0 : PSK &quot;www.172173.com&quot; （注意空格格式不能错） 5.3 配置ipsec.conf12345678910111213# cat /etc/ipsec.confversion 2# basic configurationconfig setup # which IPsec stack to use, &quot;netkey&quot; (the default), &quot;klips&quot; or &quot;mast&quot;. # For MacOSX use &quot;bsd&quot; protostack=netkey //使用2.6内核内建模块netkey，2.6以下是KLIPS模块 nat_traversal=yes //nat穿透 virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v4:25.0.0.0/8,%v4:100.64.0.0/10,%v6:fd00::/8,%v6:fe80::/10 dumpdir=/var/run/pluto/ logfile=/var/log/pluto.log //log locationinclude /etc/ipsec.d/*.conf 5.2 配置VPN主体公司服务器：192.168.99.168 12345678910111213141516171819202122# cat /etc/ipsec.d/campany.conf conn BY-to-UC # 第一阶段（两端要保持一致） ike=3des-sha1 authby=secret //使用预共享密钥方式进行认证 # 第二阶段（两端要保持一致 phase2=esp //用于连接的ESP加密/认证算法。 phase2alg=3des-sha1 compress=no //所有计划的IPsec sa都要包含IPCOMP(压缩)。如果KLIPS没有配置IPCOMP支持，会忽略该选项。 type=tunnel //使用tunnel隧道模式 pfs=yes //完全加密 leftid=106.75.20.16 left=106.75.20.16 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.123.82 right=192.168.99.168 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start //add代表只是添加，但并不会连接，如果为start则代表着启动自动连接 外部服务器：106.75.20.16 12345678910111213141516171819202122# cat /etc/ipsec.d/outside.conf conn UC-to-BY # 第一阶段（两端要保持一致） ike=3des-sha1 authby=secret //使用预共享密钥方式进行认证 # 第二阶段（两端要保持一致 phase2=esp //用于连接的ESP加密/认证算法。 phase2alg=3des-sha1 compress=no //所有计划的IPsec sa都要包含IPCOMP(压缩)。如果KLIPS没有配置IPCOMP支持，会忽略该选项。 type=tunnel //使用tunnel隧道模式 pfs=yes //完全加密 leftid=106.75.20.16 left=10.10.68.61 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.123.82 right=58.22.123.82 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start //add代表只是添加，但并不会连接，如果为start则代表着启动自动连接 第一阶段选择 ikev1 主模式（main mode），参数为 3des、sha、group2。 第二阶段选择模式为 tunnel，参数为 esp、3des、sha。 启用 pfs 和 nat-t（nat 穿越）。 六、测试完成与错误定位6.1 测试12345ipsec auto --up BY-to-UC002 &quot;BY-to-UC&quot; #371: initiating Quick Mode PSK+ENCRYPT+TUNNEL+PFS+UP+IKEV1_ALLOW+IKEV2_ALLOW+SAREF_TRACK+IKE_FRAG_ALLOW &#123;using isakmp#370 msgid:76bf0615 proposal=3DES(3)_000-SHA1(2)_000 pfsgroup=OAKLEY_GROUP_MODP1536&#125;117 &quot;BY-to-UC&quot; #371: STATE_QUICK_I1: initiate002 &quot;BY-to-UC&quot; #371: transition from state STATE_QUICK_I1 to state STATE_QUICK_I2004 &quot;BY-to-UC&quot; #371: STATE_QUICK_I2: sent QI2, IPsec SA established tunnel mode &#123;ESP/NAT=&gt;0x26978c24 &lt;0xdf95b93d xfrm=3DES_0-HMAC_SHA1 NATOA=none NATD=106.75.20.16:4500 DPD=passive&#125; 这个状态即为启动成功，两端可互相 ping 通。1IPsec SA established tunnel mode 排查错误常用命令1234ipsec auto --status //状态tail -f /var/log/ipsec.log //ipsec日志tail -f /var/log/secure //安全日志tail -f /var/log/messages //系统日志 6.2 其他主机路由 其他云主机如果要通过 ipsec 访问对端要增加相应的路由，或者网关指向本地的 ipsec服务器。12345678910111213141516在10.10.68.62 （外部测试）上，执行：# route add -net 192.168.0.0/24 gw 10.10.68.61 dev eth0在10.10.68.61 （外部VPN）上，执行：# route add -net 192.168.0.0/24 gw 10.10.68.61 dev eth0在192.168.99.168 (公司VPN)上执行 ：# route add -net 10.10.0.0/16 gw 192.168.99.168 dev eth0 在192.168.99.169（公司测试）上执行：或者 公司可以在三层交换机上添加以下路由，就所有的公司内网服务器都可以到外网服务器内网，不需要每台都加 # route add -net 10.10.0.0/16 gw 192.168.99.168 dev eth0 6.3 故障排查 1)、发生no connection named “xxxxx”的报错时基本为配置文件错误或者conn名字错误，检查conn名称、配置文件格式，并查看/var/log/messages中具体错误参数/格式提示。 12initiating all conns with alias=&quot;net-to-net&quot;no connection named &quot;net-to-net&quot; 2）、发生第一阶段（STATEMAINI1）或者第二阶段（STATEQUICKI1）初始化超时报错的时候，多为两端参数配置错误导致的协商失败，需要查看/var/log/secure以及对端的日志确定具体哪个参数协商错误。 12010 &quot;sample&quot; #2: STATE_QUICK_I1: retransmission; will wait 20s for response010 &quot;sample&quot; #2: STATE_QUICK_I1: retransmission; will wait 40s for response 6.4 测试相互ping]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>openswan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window-2016-mstsc]]></title>
    <url>%2Fwindow-2016-mstsc.html</url>
    <content type="text"><![CDATA[错误连接无法继续，因为未启用身份验证，并且远程计算机需要启用身份验证进行连接。 场景自带远程工具mstsc连接成功，用第三方远程工具提示如下图 目标服务器 Windows Server 2016 解决1、先用自带远程工具 mstsc 连接到Windows Server 2016 2、开始-运行-gpedit.msc，进入组策略编辑器 3、找到左侧边栏计算机配置-管理模板-Windows组件-远程桌面服务-远程桌面会话主机-安全项 4、修改&quot;远程（RDP）连接要求使用指定的安全层&quot;，改为启用，安全层选择RDP]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>连接无法继续，因为未启用身份验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-form]]></title>
    <url>%2Fdjango-form.html</url>
    <content type="text"><![CDATA[Field required=True, 是否允许为空 widget=None, HTML插件 label=None, 用于生成Label标签或显示内容 initial=None, 初始值 help_text=&apos;&apos;, 帮助信息(在标签旁边显示) error_messages=None, 错误信息 {&apos;required&apos;: &apos;不能为空&apos;, &apos;invalid&apos;: &apos;格式错误&apos;} validators=[], 自定义验证规则 localize=False, 是否支持本地化 disabled=False, 是否可以编辑 label_suffix=None Label内容后缀 CharField(Field) max_length=None, 最大长度 min_length=None, 最小长度 strip=True 是否移除用户输入空白 IntegerField(Field) max_value=None, 最大值 min_value=None, 最小值 FloatField(IntegerField) ... DecimalField(IntegerField) max_value=None, 最大值 min_value=None, 最小值 max_digits=None, 总长度 decimal_places=None, 小数位长度 BaseTemporalField(Field) input_formats=None 时间格式化 DateField(BaseTemporalField) 格式：2015-09-01 TimeField(BaseTemporalField) 格式：11:12 DateTimeField(BaseTemporalField)格式：2015-09-01 11:12 DurationField(Field) 时间间隔：%d %H:%M:%S.%f ... RegexField(CharField) regex, 自定制正则表达式 max_length=None, 最大长度 min_length=None, 最小长度 error_message=None, 忽略，错误信息使用 error_messages={&apos;invalid&apos;: &apos;...&apos;} EmailField(CharField) ... FileField(Field) allow_empty_file=False 是否允许空文件 ImageField(FileField) ... 注：需要PIL模块，pip3 install Pillow 以上两个字典使用时，需要注意两点： - form表单中 enctype=&quot;multipart/form-data&quot; - view函数中 obj = MyForm(request.POST, request.FILES) URLField(Field) ... BooleanField(Field) ... NullBooleanField(BooleanField) ... ChoiceField(Field) ... choices=(), 选项，如：choices = ((0,&apos;上海&apos;),(1,&apos;北京&apos;),) required=True, 是否必填 widget=None, 插件，默认select插件 label=None, Label内容 initial=None, 初始值 help_text=&apos;&apos;, 帮助提示 ModelChoiceField(ChoiceField) ... django.forms.models.ModelChoiceField queryset, # 查询数据库中的数据 empty_label=&quot;---------&quot;, # 默认空显示内容 to_field_name=None, # HTML中value的值对应的字段 limit_choices_to=None # ModelForm中对queryset二次筛选 ModelMultipleChoiceField(ModelChoiceField) ... django.forms.models.ModelMultipleChoiceField TypedChoiceField(ChoiceField) coerce = lambda val: val 对选中的值进行一次转换 empty_value= &apos;&apos; 空值的默认值 MultipleChoiceField(ChoiceField) ... TypedMultipleChoiceField(MultipleChoiceField) coerce = lambda val: val 对选中的每一个值进行一次转换 empty_value= &apos;&apos; 空值的默认值 ComboField(Field) fields=() 使用多个验证，如下：即验证最大长度20，又验证邮箱格式 fields.ComboField(fields=[fields.CharField(max_length=20), fields.EmailField(),]) MultiValueField(Field) PS: 抽象类，子类中可以实现聚合多个字典去匹配一个值，要配合MultiWidget使用 SplitDateTimeField(MultiValueField) input_date_formats=None, 格式列表：[&apos;%Y--%m--%d&apos;, &apos;%m%d/%Y&apos;, &apos;%m/%d/%y&apos;] input_time_formats=None 格式列表：[&apos;%H:%M:%S&apos;, &apos;%H:%M:%S.%f&apos;, &apos;%H:%M&apos;] FilePathField(ChoiceField) 文件选项，目录下文件显示在页面中 path, 文件夹路径 match=None, 正则匹配 recursive=False, 递归下面的文件夹 allow_files=True, 允许文件 allow_folders=False, 允许文件夹 required=True, widget=None, label=None, initial=None, help_text=&apos;&apos; GenericIPAddressField protocol=&apos;both&apos;, both,ipv4,ipv6支持的IP格式 unpack_ipv4=False 解析ipv4地址，如果是::ffff:192.0.2.1时候，可解析为192.0.2.1， PS：protocol必须为both才能启用 SlugField(CharField) 数字，字母，下划线，减号（连字符） ... UUIDField(CharField) uuid类型 Django Form内置字段 参考]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>Django基础之form表单的所有内置字段</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog log forwarding]]></title>
    <url>%2FRsyslog-log-forwarding.html</url>
    <content type="text"><![CDATA[wriren by: CQhttps://www.920430.com rsyslog 日志转发前言使用rsyslog日志收集是尽量保证日志的原始性不去做任何处理 ，直接收集入到队列，如kafka、redis，这样做的的好处时，减少日志客户端rsyslog的性能压力，从而不影响所在服务器上正常业务，并且保持原始日志也便于各自业务方处理，自己写的日志自己最熟悉。 日志收集客户端rsyslog 可以使用守护进程的工具做守护,如supervisor、monit等 rsyslog提供三个远程日志传输方式： UDP: 数据包传输可信度不高 TCP: 数据包传输可信度比较高 RELP: 数据包传输可信度最高，避免数据丢失，比较新的协议，目前应用较少 下面介绍的RELP方式 rsyslog client:查看rsyslog版本$ sudo rsyslogd -v rsyslogd 7.4.4, compiled with: FEATURE_REGEXP: Yes FEATURE_LARGEFILE: No GSSAPI Kerberos 5 support: Yes FEATURE_DEBUG (debug build, slow code): No 32bit Atomic operations supported: Yes 64bit Atomic operations supported: Yes Runtime Instrumentation (slow code): No uuid support: Yes 备份原先的配置$ sudo cp -pv /etc/rsyslog.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/20-ufw.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/50-default.conf{,.old} 安装rsyslog-relp# CentOS # yum install rsyslog-relp # Ubuntu $ sudo apt-get install rsyslog-relp 修改rsyslog.confCentOS $ sudo vim /etc/rsyslog.conf $ModLoad omrelp $SystemLogRateLimitInterval 0 $SystemLogRateLimitBurst 0 $MaxMessageSize 16k # $MaxOpenFiles 5000 Ubuntu $ sudo vim /etc/rsyslog.conf $ModLoad omrelp $SystemLogRateLimitInterval 0 $SystemLogRateLimitBurst 0 $ActionQueueFileName locals # unique name prefix for spool files $ActionQueueMaxDiskSpace 15g # 15gb space limit (use as much as possible) $ActionQueueSaveOnShutdown on # save messages to disk on shutdown $ActionQueueType LinkedList # run asynchronously $ActionResumeRetryCount -1 # infinite retries if host is down $ActionQueueTimeoutEnqueue 0 # discard messages instead of throttling the log emitter when the queue has reached its limit $ActionQueueDequeueSlowdown 0 # no slowdown of the log emitter $ActionQueueDiscardSeverity 6 # discard info level messages when reaching discard mark $MaxMessageSize 16k # $MaxOpenFiles 5000 禁止日志写到/var/log/syslog，同时启用local3。 none表示什么都不记录ubuntu: $ sudo vim /etc/rsyslog.d/50-default.conf #*.*;auth,authpriv.none -/var/log/syslog *.*;auth,authpriv.none,local3.none -/var/log/syslog # local3.* @@192.168.99.200:514 local3.* :omrelp:192.168.99.200:20514 centos: *.info;mail.none;authpriv.none;cron.none,local3.none /var/log/messages # local3.* @@x.x.243.239:514 local3.* :omrelp:x.x.243.239:20514 验证rsyslog配置$ sudo rsyslogd -N 1 rsyslogd: version 7.4.4, config validation run (level 1), master config /etc/rsyslog.conf rsyslogd: End of config validation run. Bye 重启rsyslogd$ sudo service rsyslog restart rsyslog server:查看rsyslog版本$ sudo rsyslogd -v rsyslogd 7.4.4, compiled with: FEATURE_REGEXP: Yes FEATURE_LARGEFILE: No GSSAPI Kerberos 5 support: Yes FEATURE_DEBUG (debug build, slow code): No 32bit Atomic operations supported: Yes 64bit Atomic operations supported: Yes Runtime Instrumentation (slow code): No uuid support: Yes 备份原先的配置$ sudo cp -pv /etc/rsyslog.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/20-ufw.conf{,.old} $ sudo cp -pv /etc/rsyslog.d/50-default.conf{,.old} 安装rsyslog-relp# CentOS # yum install rsyslog-relp # Ubuntu $ sudo apt-get install rsyslog-relp 修改rsyslog.conf$ sudo vim /etc/rsyslog.conf # provides UDP syslog reception # $ModLoad imudp # $UDPServerRun 514 $ModLoad imrelp $InputRELPServerRun 20514 # provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 $MaxMessageSize 16k # $MaxOpenFiles 5000 $InputTCPMaxSessions 1024 $EscapeControlCharactersOnReceive off 禁止日志写到/var/log/syslog，同时启用local3, none表示什么都不记录$ sudo vim /etc/rsyslog.d/50-default.conf #*.*;auth,authpriv.none -/var/log/syslog *.*;auth,authpriv.none,local3.none -/var/log/syslog 自定义配置文件$ sudo vim /etc/rsyslog.d/51-gamelog.conf $template cocsFormat, &quot;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg%\n&quot; $template COCS, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/cocs_%$year%%$month%%$day%.log $template BUGS, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/bug_%$year%%$month%%$day%.log $template UNKNOWN, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/unknown_%$year%%$month%%$day%.log&quot; # http://www.rsyslog.com/doc/master/configuration/properties.html if $programname startswith &apos;cocs&apos; then ?COCS;cocsFormat &amp; stop if $programname startswith &apos;bugs&apos; then ?BUGS &amp; stop if $syslogfacility-text == &apos;local3&apos; then ?UNKNOWN 验证rsyslog配置$ sudo rsyslogd -N 1 rsyslogd: version 7.4.4, config validation run (level 1), master config /etc/rsyslog.conf rsyslogd: End of config validation run. Bye 目录权限sudo chown -R syslog.syslog /data/rsyslog 重启rsyslogd$ sudo service rsyslog restart 测试logger命令可以使用系统自带的logger命令来测试 $ logger -it bugs -p local3.info &apos;{&quot;@timestamp&quot;:&quot;2017-2-22T15:40:53.820Z&quot;,&quot;beat&quot;:{&quot;hostname&quot;:&quot;12.10.x.x&quot;,&quot;name&quot;:&quot;x.x.231.98&quot;,&quot;version&quot;:&quot;5.0.2&quot;},&quot;category&quot;:&quot;game_user_rank_record&quot;,&quot;db_name&quot;:&quot;androidxxx&quot;,&quot;input_type&quot;:&quot;log&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;log&quot;:&quot;{\&quot;i_user_id\&quot;:1432320,\&quot;i_ser_id\&quot;:8012,\&quot;gamekey\&quot;:\&quot;210_16_3_33\&quot;,\&quot;account_id\&quot;:145439,\&quot;user_name\&quot;:\&quot;时间歌声\&quot;,\&quot;user_level\&quot;:1,\&quot;vip_level\&quot;:0,\&quot;user_power\&quot;:331792,\&quot;rank_type\&quot;:3,\&quot;rank\&quot;:140,\&quot;add_time\&quot;:1490716793,\&quot;parama\&quot;:\&quot;342\&quot;}&quot;,&quot;offset&quot;:75196044,&quot;source&quot;:&quot;/data/xxxx/logs/game_user_rank_record_2017-03-28.log&quot;,&quot;time&quot;:&quot;2017-03-28 23:59:53&quot;,&quot;type&quot;:&quot;22222&quot;}&apos; logger命令解释-i 在每行都记录进程ID -t bugs 每行记录都加上“bugs”这个标签,即syslogtag -p local3.notice 设置记录的设备和级别 调试模式$ sudo rsyslogd -nd 配置列子# $template cocsFormat, &quot;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg%\n&quot; # $template DEBUG, &quot;/data/rsyslog/%fromhost-ip%/DEBUG_%$year%%$month%%$day%.log&quot; $template USER_ONLINE_AMOUNT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_user_online_amount_%$year%%$month%%$day%.log&quot; $template ACTION_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_action_%$year%%$month%%$day%.log&quot; $template LOGIN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_login_%$year%%$month%%$day%.log&quot; $template PAYMENT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_payment_%$year%%$month%%$day%.log&quot; $template RESOURCE_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_resource_%$year%%$month%%$day%.log&quot; $template REGISTER_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_register_%$year%%$month%%$day%.log&quot; $template PETS_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_pets_edit_%$year%%$month%%$day%.log&quot; $template PROPS_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_props_edit_%$year%%$month%%$day%.log&quot; $template CURRENCY_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_currency_%$year%%$month%%$day%.log&quot; $template HERO_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_hero_edit_%$year%%$month%%$day%.log&quot; $template EQUIPMENT_EDIT_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_equipment_edit_%$year%%$month%%$day%.log&quot; $template MSG_PROCESS_TIME_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_msg_process_time_%$year%%$month%%$day%.log&quot; $template GAMEKEY_STATIC_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_gamekey_static_%$year%%$month%%$day%.log&quot; $template SERVER_ID_STATIC_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_server_id_static_%$year%%$month%%$day%.log&quot; $template UNKNOWN_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_unknown_%$year%%$month%%$day%.log&quot; $template BUGS_LOG, &quot;/data/rsyslog/%fromhost-ip%/%$year%%$month%%$day%/xxxgame_bugs_%$year%%$month%%$day%.log&quot; if $programname startswith &apos;xxx&apos; and $msg contains &apos;register_log&apos; then ?REGISTER_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;login_log&apos; then ?LOGIN_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;resource_log&apos; then ?RESOURCE_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;payment_log&apos; then ?PAYMENT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;action_log&apos; then ?ACTION_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;online_amount_log&apos; then ?USER_ONLINE_AMOUNT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;pets_edit_log&apos; then ?PETS_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;props_edit_log&apos; then ?PROPS_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;currency_log&apos; then ?CURRENCY_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;hero_edit_log&apos; then ?HERO_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;equipment_edit_log&apos; then ?EQUIPMENT_EDIT_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;msg_process_time&apos; then ?MSG_PROCESS_TIME_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;gamekey_static_log&apos; then ?GAMEKEY_STATIC_LOG &amp; stop if $programname startswith &apos;xxx&apos; and $msg contains &apos;server_id_static_log&apos; then ?SERVER_ID_STATIC_LOG &amp; stop if $syslogfacility-text == &apos;local3&apos; and $syslogseverity &lt;= &apos;5&apos; then ?BUGS_LOG &amp; stop if $syslogfacility-text == &apos;local3&apos; then ?UNKNOWN_LOG]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Rsyslog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows-multi-user]]></title>
    <url>%2Fwindows-multi-user.html</url>
    <content type="text"><![CDATA[一、安装远程桌面服务；cmd 运行 1appwiz.cpl 添加功能 等待安装完成 二、在远程桌面会话主机配置中将”限制每个用户只能进行一个会话”的勾去掉。 三、确认自己的计算机开启了远程连接 四、限制连接数量cmd 运行 gpedit.msc， -- 本地计算机 策略 计算机配置\管理模板\Windows 组件\远程桌面服务\远程桌面会话主机\连接 限制连接数量中进行配置； 五、记得更新一下策略，使设置尽快生效。1gpupdte /force]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Win2008 R2实现多用户远程连接设置方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac-python-error-matplotlib]]></title>
    <url>%2Fmac-python-error-matplotlib.html</url>
    <content type="text"><![CDATA[环境123ProductName: Mac OS XProductVersion: 10.12.6Python 2.7.10 安装金山云cdn sdk1234567891011121314151617sudo pip2.7 install ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) |################################| 696kB 343kB/s Requirement already satisfied: docutils&gt;=0.10 in /Library/Python/2.7/site-packages (from ksc-sdk-python) (0.14)Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /Library/Python/2.7/site-packages (from ksc-sdk-python) (0.9.4)Collecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) |################################| 235kB 345kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlERROR: matplotlib 1.3.1 requires nose, which is not installed.ERROR: matplotlib 1.3.1 requires tornado, which is not installed.Installing collected packages: six, python-dateutil, pyyaml, ksc-sdk-python Found existing installation: six 1.4.1ERROR: Cannot uninstall &apos;six&apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. 问题原因是Apple预安装的这个six库出于安全原因被设置为sudo也不可以执行操作，所以需要依赖于高版本的库就需要更新six，但是没有six的权限，所以就会报错。 --ignore-installed 其作用是忽略已安装的某些模块 解决方案一、跳过验证12345678910111213141516171819sudo pip2.7 install --ignore-installed ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) |################################| 696kB 268kB/s Collecting docutils&gt;=0.10 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/50/09/c53398e0005b11f7ffb27b7aa720c617aba53be4fb4f4f3f06b9b5c60f28/docutils-0.14-py2-none-any.whl (543kB) |################################| 552kB 332kB/s Collecting jmespath&lt;1.0.0,&gt;=0.7.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whlCollecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) |################################| 235kB 445kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlERROR: matplotlib 1.3.1 requires nose, which is not installed.ERROR: matplotlib 1.3.1 requires tornado, which is not installed.Installing collected packages: docutils, jmespath, six, python-dateutil, pyyaml, ksc-sdk-pythonSuccessfully installed docutils-0.14 jmespath-0.9.4 ksc-sdk-python-1.3.10 python-dateutil-2.8.0 pyyaml-3.13 six-1.12.0 安装成功了，但还是有报错 二、更新版本12345678910111213141516171819brew install python2sudo pip2.7 install ksc-sdk-pythonCollecting ksc-sdk-python Downloading https://files.pythonhosted.org/packages/00/3f/65fafafe3b02ed6c362124ab20e29abe0b8e1d54337985fdc837416c1b54/ksc_sdk_python-1.3.10-py2.py3-none-any.whl (692kB) 100% |################################| 696kB 416kB/s Collecting jmespath&lt;1.0.0,&gt;=0.7.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whlCollecting docutils&gt;=0.10 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/50/09/c53398e0005b11f7ffb27b7aa720c617aba53be4fb4f4f3f06b9b5c60f28/docutils-0.14-py2-none-any.whl (543kB) 100% |################################| 552kB 157kB/s Collecting python-dateutil&lt;3.0.0,&gt;=2.1 (from ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) 100% |################################| 235kB 97kB/s Collecting pyyaml==3.13 (from ksc-sdk-python)Collecting six&gt;=1.5 (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;ksc-sdk-python) Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whlInstalling collected packages: jmespath, docutils, six, python-dateutil, pyyaml, ksc-sdk-pythonSuccessfully installed docutils-0.14 jmespath-0.9.4 ksc-sdk-python-1.3.10 python-dateutil-2.8.0 pyyaml-3.13 six-1.12.0 更新Python 版本，后彻底解决。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>ERROR: matplotlib 1.3.1 requires nose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pure-ftp-install]]></title>
    <url>%2FPure-ftp-install.html</url>
    <content type="text"><![CDATA[Install Pure-ftpFTP 簡介 FTP (File Transfer Protocol) 是在因特网上已行之多年的文件传输协议，透过这个通讯协议，可以将远程计算机的档案数据传送回本机端 (下载)，也可以把本机的档案数据传输至远程计算机 (上传) ﹔而所谓的 FTP Server，就是一部专门提供给客户端进行档案上传与下载服务的服务器。 我们都知道 Web Server 是用 http 来做数据传输的协议，其除了可让 Client 端浏览网页外，同时也提供档案上传与下载的服务，不过它比较适用于小档案的传输，而在对大文件传输时，所表现的稳定度及传输效率就不那么高了。所以想改善 http 传输档案上的缺失及效能，最好的方式就是架设一台 FTP Server 了。 用来架设 FTP Server 的软件有好几种，其中最老牌的算是 wu-ftpd，不过也由于其树大招风的关系，使得在安全性方面会有比较大的隐忧。不过还好后来又陆续发展出一些安全性较佳的服务器软件，比方像 proftpd、vsftpd 及 pure-ftpd 等，而本章将会针对 pure-ftpd 及 vsftpd 这两个服务器软件来做介绍。 FTP 的联机流程 在还没开始介绍流程之前，要先来了解一下两台计算机间 TCP 联机建立的过程： 当 Client 向 Server 提出主动联机请求时，会送出联机过程的第一个 TCP 封包给对方，而此时 TCP 封包中的 SYN (同步旗标) 位值设定为 1，代表的是一个联机的启动 ﹔接着 Server 端也必须启动自己的联机并做响应的确认，因此会向 Client 端送出联机过程的第二个封包，此时该封包的 SYN 及 ACK (回应确认旗标) 位值皆设定为 1 ﹔最后在 Client 端收到对方的封包后，必须做响应确认的动作，因此会送出联机过程的第三个封包给 Server，此时封包的 ACK 位值设定为 1。至此双方的联机才正式建立起来，这就是所谓的 TCP Three-Way Handshake ( TCP 三段式交握 )。 了解了 TCP 联机建立的观念后，底下就来说明 FTP 联机的过程。不过在此之前，要先了解的是，FTP Client 能采取的联机模式有两种，分别是主动模式 (Active mode) 及被动模式 (Passive mode)，所以接着会以这两种不同模式来叙述联机过程。 主动模式下的 FTP 联机 当 FTP Client 一开始要连上 FTP Server 时，会先随机产生一个大于 1024 的 port ( 假设 3000 port )，来主动对 FTP Server 的 21 port 做联机，等完成了 TCP 三段式交握后，联机才正式建立起来，而这个 3000 port 与 21 port 所建立的联机信道，就叫做命令信道 (command channel )。之所以会称其为命令通道，当然是只能执行一些基本指令而已啰。 现在若是 Client 端想要下载或上传数据时，还要另外建立起一条数据信道 (data channel ) 来作为数据传输使用。由于 Client 是采取主动模式 (可以想象 Client 要求 Server 做主动联机，也就是 Server 主动连 Client )，因此本身会再开启另一个大于 1024 的 port ( 假设 5000 port )，然后透过命令通道通知 Server 已准备好这个 data channel 的端口，接着 Server 就以 20 port 来主动与 Client 端的 5000 port 建立联机，就在完成了另一次的三段式交握后，此 data channel 便建立起来，至此 Client 方可开始做数据传输。 被动模式下的 FTP 联机 一开始 command channel 的建立，与上面所述相同，不再重复，这里只针对 data channel 的建立做说明。由于此时 Client 是希望采取被动模式 (可以想象 Client 要求 Server 做被动联机，也就是 Client 主动连 Server)，所以会先透过 command channel 来通知 Server 这个讯息，Sever 收到后就随机开启一个大于 1024 的 port (假设 8000 port)，并经由 command channel 知会 Client 已准备好 data channel 的端口，接着 Client 也随机开启一个大于 1024 的 port (假设 9000 port) 来主动与 Server 建立联机，而完成的三段式交握后，此 8000 port 与 9000 port 之间的 data channel 便建立起来了。 编译安装Pure-ftp$ cd /usr/local/src/ $ wget ftp://ftp.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.45.tar.gz $ tar xf pure-ftpd-1.0.45.tar.gz &amp;&amp; cd pure-ftpd-1.0.45 $ ./configure --prefix=/usr/local/pure-ftpd-1.0.45 \ --with-cookie --with-throttling \ --with-ratios --with-quotas --with-sysquotas \ --with-tls --with-welcomemsg \ --with-uploadscript --with-virtualhosts \ --with-virtualchroot --with-puredb \ --with-diraliases --with-peruserlimits \ --with-paranoidmsg --with-altlog --with-nonroot $ make &amp;&amp; make install $ ln -s /usr/local/pure-ftpd-1.0.45 /usr/local/pure-ftpd $ cp -pv /usr/local/pure-ftpd/etc/pure-ftpd.conf{,.default} $ vim /usr/local/pure-ftpd-1.0.45/etc/pure-ftpd.conf ChrootEveryone yes # 启用chroot BrokenClientsCompatibility no # 兼容不同客户端 MaxClientsNumber 100 # 客户端最大连接数 Daemonize yes # 后台运行 MaxClientsPerIP 16 # 每个ip最大连接数 VerboseLog no # 记录日志 DisplayDotFiles no # 显示隐藏文件 AnonymousOnly no # 只允许匿名用户访问 NoAnonymous yes # 不允许匿名用户连接 SyslogFacility none # 不将日志在syslog日志中显示 AltLog clf:/var/log/pureftpd.log # clf格式日志文件位置 DontResolve yes # 不进行客户端DNS解析 MaxIdleTime 5 # 最大空闲时间 #MySQLConfigFile /usr/local/pure-ftpd/etc/pureftpd-mysql.conf # 用户数据库文件 MySQL PureDB /usr/local/pure-ftpd/etc/pureftpd.pdb # 用户数据库文件 PIDFile /var/run/pure-ftpd.pid PAMAuthentication no # 取消使用PAM验证 UnixAuthentication yes # /etc/passwd 文件验证 #MinUID 500 # 验证登录用户的最小UID LimitRecursion 30000 8 # 浏览限制，文件30000，目录8层 AnonymousCanCreateDirs no # 不允许匿名用户创建目录 MaxLoad 10 # 超出负载后禁止下载 PassivePortRange 49000 50000 # 被动模式端口范围 AntiWarez yes # 禁止下载匿名用户上传但未经验证的文件 UserBandwidth 1024 # 所有用户最大带宽（KB） Umask 133:022 # 创建文件/目录默认掩码 AllowUserFXP yes # 仅运行用户进行FXP传输 AllowAnonymousFXP no # 不能删除/写入隐藏文件 ProhibitDotFilesWrite no # 不能删除/写入隐藏文件 ProhibitDotFilesRead no # 禁止读取隐藏文件 AutoRename no # 有同名文件时自动重新命名 AnonymousCantUpload yes # 不允许匿名用户上传文件 MaxDiskUsage 90 # 当磁盘使用量打到90%时禁止上传 CreateHomeDir yes # 如果虚拟用户的目录不存在则自动创建#需要ftp根目录权限为755 CustomerProof yes # 防止命令误操作 Bind 0.0.0.0,52759 # 绑定端口 yum 安装$ yum -y install pure-ftpd 设置系统用户$ useradd -s /sbin/nologin -u 600 -d ${ftpdir} -M vftp $ chown -R vftp.vftp ${ftpdir} $ # 或者 $ groupadd ftpgroup $ useradd -g ftpgroup -d /dev/null -s /sbin/nologin ftpuser $ mkdir /data/ftpdata $ chown ftpuser.ftpgroup /data/ftpdata 设置Pure-ftp虚拟用户$ /usr/local/pure-ftpd/bin/pure-pw useradd ftpuser -u 600 -g 600 -d ${ftpdir} -m $ 或者 $ sudo pure-pw mkdb $ ./pure-pw useradd 虚拟用户名 -u 系统用户 -g 系统组 -d 目录 -m $ # 当使用pure-pw 生成虚拟用户之后一定要使用pure-pw mkdb命令生成数据库文件， 否则pure-ftp启动之后也无法验证虚拟用户 $ /usr/local/pure-ftpd/bin/pure-pw mkdb /usr/local/pure-ftpd/etc/pureftpd.pdb -f /usr/local/pure-ftpd/etc/pureftpd.passwd 查看用户比如创建好的用户为someuser，则 $ pure-pw show someuser 修改用户密码$ sudo pure-pw passwd someuser 之后，通过更新来提交更改 $ sudo pure-pw 启动pure-ftpd/usr/local/pure-ftpd/sbin/pure-ftpd /usr/local/pure-ftpd/etc/pure-ftpd.conf or /etc/init.d/pure-ftpd start 重启/etc/init.d/pure-ftpd restart https://wiki.archlinux.org/index.php/Pure-FTPd]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Pure ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum-errno-256]]></title>
    <url>%2Fyum-errno-256.html</url>
    <content type="text"><![CDATA[Centos7.5 [yum update -y] 更新报错环境 CentOS Linux release 7.5.1804 (Core) 现象12345678910111213141516171819202122232425262728293031[root@x.x.x.x ~]# yum update -y Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package polkit.x86_64 0:0.112-18.el7 will be updated---&gt; Package polkit.x86_64 0:0.112-18.el7_6.1 will be an update--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================== Package Arch Version Repository Size==============================================================================================================================================================================Updating: polkit x86_64 0.112-18.el7_6.1 updates 168 kTransaction Summary==============================================================================================================================================================================Upgrade 1 PackageTotal download size: 168 kDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.polkit-0.112-18.el7_6.1.x86_64 FAILED http://mirrors.ucloud.cn/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpm: [Errno -1] Package does not match intended download. Suggestion: run yum --enablerepo=updates clean metadataTrying other mirror.Error downloading packages: polkit-0.112-18.el7_6.1.x86_64: [Errno 256] No more mirrors to try. 解决方案1234wget http://mirror.centos.org/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpmsudo yum localinstall -y polkit-0.112-18.el7_6.1.x86_64.rpm# 或者sudo yum install http://mirror.centos.org/centos/7/updates/x86_64/Packages/polkit-0.112-18.el7_6.1.x86_64.rpm -y 参考1https://qiita.com/HiroshiAkutsu/items/9fdc65ce6147793d0a01]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>yum update Errno 256</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-win32net]]></title>
    <url>%2Fpython-win32net.html</url>
    <content type="text"><![CDATA[python windows 用户管理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060# -*- coding: utf-8 -*-&apos;&apos;&apos;window 用户管理.. important:: 用salt 也可以用这个模块 依赖模块:depends: - pythoncom - pywintypes - win32api - win32con - win32net - win32netcon - win32profile - win32security - win32ts - wmi.. note:: 目前只适用于本地用户帐户，而不是域帐户。&apos;&apos;&apos;# Import Python libsfrom __future__ import absolute_import, unicode_literals, print_functionimport loggingimport timefrom datetime import datetimetry: from shlex import quote as _cmd_quote # pylint: disable=E0611except Exception: from pipes import quote as _cmd_quote# Import Salt libsimport salt.utils.argsimport salt.utils.dateutilsimport salt.utils.platformfrom salt.ext import sixfrom salt.ext.six import string_typesfrom salt.exceptions import CommandExecutionErrorlog = logging.getLogger(__name__)try: import pywintypes import wmi import pythoncom import win32api import win32con import win32net import win32netcon import win32profile import win32security import win32ts HAS_WIN32NET_MODS = Trueexcept ImportError: HAS_WIN32NET_MODS = False# Define the module&apos;s virtual name__virtualname__ = &apos;user&apos;def __virtual__(): &apos;&apos;&apos; 需要Windows和Windows模块 &apos;&apos;&apos; if not salt.utils.platform.is_windows(): return False, &apos;Module win_useradd: Windows Only&apos; if not HAS_WIN32NET_MODS: return False, &apos;Module win_useradd: Missing Win32 Modules&apos; return __virtualname__def _to_unicode(instr): &apos;&apos;&apos; 用于转换为Unicode字符串的内部函数 The NetUser* series of API calls in this module requires input parameters to be Unicode Strings. This function ensures the parameter is a Unicode String. This only seems to be an issue in Python 2. All calls to this function should be gated behind a ``if six.PY2`` check. Args: instr (str): String to convert Returns: str: Unicode type string &apos;&apos;&apos; if instr is None or isinstance(instr, six.text_type): return instr else: return six.text_type(instr, &apos;utf-8&apos;)def add(name, password=None, fullname=None, description=None, groups=None, home=None, homedrive=None, profile=None, logonscript=None): &apos;&apos;&apos; 添加用户 参数: name (str): User name password (str, optional): User&apos;s password in plain text. fullname (str, optional): The user&apos;s full name. description (str, optional): A brief description of the user account. groups (str, optional): A list of groups to add the user to. (see chgroups) home (str, optional): The path to the user&apos;s home directory. homedrive (str, optional): The drive letter to assign to the home directory. Must be the Drive Letter followed by a colon. ie: U: profile (str, optional): An explicit path to a profile. Can be a UNC or a folder on the system. If left blank, windows uses it&apos;s default profile directory. logonscript (str, optional): Path to a login script to run when the user logs on. Returns: bool: True if successful. False is unsuccessful. CLI Example: .. code-block:: bash salt &apos;*&apos; user.add name password &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) password = _to_unicode(password) fullname = _to_unicode(fullname) description = _to_unicode(description) home = _to_unicode(home) homedrive = _to_unicode(homedrive) profile = _to_unicode(profile) logonscript = _to_unicode(logonscript) user_info = &#123;&#125; if name: user_info[&apos;name&apos;] = name else: return False user_info[&apos;password&apos;] = password user_info[&apos;priv&apos;] = win32netcon.USER_PRIV_USER user_info[&apos;home_dir&apos;] = home user_info[&apos;comment&apos;] = description user_info[&apos;flags&apos;] = win32netcon.UF_SCRIPT user_info[&apos;script_path&apos;] = logonscript try: win32net.NetUserAdd(None, 1, user_info) except win32net.error as exc: log.error(&apos;Failed to create user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False update(name=name, homedrive=homedrive, profile=profile, fullname=fullname) ret = chgroups(name, groups) if groups else True return retdef update(name, password=None, fullname=None, description=None, home=None, homedrive=None, logonscript=None, profile=None, expiration_date=None, expired=None, account_disabled=None, unlock_account=None, password_never_expires=None, disallow_change_password=None): # pylint: disable=anomalous-backslash-in-string &apos;&apos;&apos; 更新Windows用户的设置。name是唯一必需的参数。 只有在传递参数值时，才会更改设置。 .. versionadded:: 2015.8.0 Args: name (str): The user name to update. password (str, optional): New user password in plain text. fullname (str, optional): The user&apos;s full name. description (str, optional): A brief description of the user account. home (str, optional): The path to the user&apos;s home directory. homedrive (str, optional): The drive letter to assign to the home directory. Must be the Drive Letter followed by a colon. ie: U: logonscript (str, optional): The path to the logon script. profile (str, optional): The path to the user&apos;s profile directory. expiration_date (date, optional): The date and time when the account expires. Can be a valid date/time string. To set to never expire pass the string &apos;Never&apos;. expired (bool, optional): Pass `True` to expire the account. The user will be prompted to change their password at the next logon. Pass `False` to mark the account as &apos;not expired&apos;. You can&apos;t use this to negate the expiration if the expiration was caused by the account expiring. You&apos;ll have to change the `expiration_date` as well. account_disabled (bool, optional): True disables the account. False enables the account. unlock_account (bool, optional): True unlocks a locked user account. False is ignored. password_never_expires (bool, optional): True sets the password to never expire. False allows the password to expire. disallow_change_password (bool, optional): True blocks the user from changing the password. False allows the user to change the password. Returns: bool: True if successful. False is unsuccessful. CLI Example: .. code-block:: bash salt &apos;*&apos; user.update bob password=secret profile=C:\\Users\\Bob home=\\server\homeshare\bob homedrive=U: &apos;&apos;&apos; # pylint: enable=anomalous-backslash-in-string if six.PY2: name = _to_unicode(name) password = _to_unicode(password) fullname = _to_unicode(fullname) description = _to_unicode(description) home = _to_unicode(home) homedrive = _to_unicode(homedrive) logonscript = _to_unicode(logonscript) profile = _to_unicode(profile) # Make sure the user exists # Return an object containing current settings for the user try: user_info = win32net.NetUserGetInfo(None, name, 4) except win32net.error as exc: log.error(&apos;Failed to update user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # Check parameters to update # Update the user object with new settings if password: user_info[&apos;password&apos;] = password if home: user_info[&apos;home_dir&apos;] = home if homedrive: user_info[&apos;home_dir_drive&apos;] = homedrive if description: user_info[&apos;comment&apos;] = description if logonscript: user_info[&apos;script_path&apos;] = logonscript if fullname: user_info[&apos;full_name&apos;] = fullname if profile: user_info[&apos;profile&apos;] = profile if expiration_date: if expiration_date == &apos;Never&apos;: user_info[&apos;acct_expires&apos;] = win32netcon.TIMEQ_FOREVER else: try: dt_obj = salt.utils.dateutils.date_cast(expiration_date) except (ValueError, RuntimeError): return &apos;Invalid Date/Time Format: &#123;0&#125;&apos;.format(expiration_date) user_info[&apos;acct_expires&apos;] = time.mktime(dt_obj.timetuple()) if expired is not None: if expired: user_info[&apos;password_expired&apos;] = 1 else: user_info[&apos;password_expired&apos;] = 0 if account_disabled is not None: if account_disabled: user_info[&apos;flags&apos;] |= win32netcon.UF_ACCOUNTDISABLE else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_ACCOUNTDISABLE if unlock_account is not None: if unlock_account: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_LOCKOUT if password_never_expires is not None: if password_never_expires: user_info[&apos;flags&apos;] |= win32netcon.UF_DONT_EXPIRE_PASSWD else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_DONT_EXPIRE_PASSWD if disallow_change_password is not None: if disallow_change_password: user_info[&apos;flags&apos;] |= win32netcon.UF_PASSWD_CANT_CHANGE else: user_info[&apos;flags&apos;] &amp;= ~win32netcon.UF_PASSWD_CANT_CHANGE # Apply new settings try: win32net.NetUserSetInfo(None, name, 4, user_info) except win32net.error as exc: log.error(&apos;Failed to update user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False return Truedef delete(name, purge=False, force=False): &apos;&apos;&apos; 删除用户 Args: name (str): The name of the user to delete purge (bool, optional): Boolean value indicating that the user profile should also be removed when the user account is deleted. If set to True the profile will be removed. Default is False. force (bool, optional): Boolean value indicating that the user account should be deleted even if the user is logged in. True will log the user out and delete user. Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.delete name &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) # Check if the user exists try: user_info = win32net.NetUserGetInfo(None, name, 4) except win32net.error as exc: log.error(&apos;User not found: %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # Check if the user is logged in # Return a list of logged in users try: sess_list = win32ts.WTSEnumerateSessions() except win32ts.error as exc: log.error(&apos;No logged in users found&apos;) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) # Is the user one that is logged in logged_in = False session_id = None for sess in sess_list: if win32ts.WTSQuerySessionInformation(None, sess[&apos;SessionId&apos;], win32ts.WTSUserName) == name: session_id = sess[&apos;SessionId&apos;] logged_in = True # If logged in and set to force, log the user out and continue # If logged in and not set to force, return false if logged_in: if force: try: win32ts.WTSLogoffSession(win32ts.WTS_CURRENT_SERVER_HANDLE, session_id, True) except win32ts.error as exc: log.error(&apos;User not found: %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False else: log.error(&apos;User %s is currently logged in.&apos;, name) return False # Remove the User Profile directory if purge: try: sid = getUserSid(name) win32profile.DeleteProfile(sid) except pywintypes.error as exc: (number, context, message) = exc.args if number == 2: # Profile Folder Not Found pass else: log.error(&apos;Failed to remove profile for %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False # And finally remove the user account try: win32net.NetUserDel(None, name) except win32net.error as exc: log.error(&apos;Failed to delete user %s&apos;, name) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) return False return Truedef getUserSid(username): &apos;&apos;&apos; 获取 用户安全ID Args: username (str): The user name for which to look up the SID Returns: str: The user SID CLI Example: .. code-block:: bash salt &apos;*&apos; user.getUserSid jsnuffy &apos;&apos;&apos; if six.PY2: username = _to_unicode(username) domain = win32api.GetComputerName() if username.find(&apos;\\&apos;) != -1: domain = username.split(&apos;\\&apos;)[0] username = username.split(&apos;\\&apos;)[-1] domain = domain.upper() return win32security.ConvertSidToStringSid( win32security.LookupAccountName(None, domain + &apos;\\&apos; + username)[0])def setpassword(name, password): &apos;&apos;&apos; 设置密码 Args: name (str): The user name for which to set the password password (str): The new password Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.setpassword jsnuffy sup3rs3cr3t &apos;&apos;&apos; return update(name=name, password=password)def addgroup(name, group): &apos;&apos;&apos; 添加用户到组 Args: name (str): The user name to add to the group group (str): The name of the group to which to add the user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.addgroup jsnuffy &apos;Power Users&apos; &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) group = _to_unicode(group) name = _cmd_quote(name) group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) user = info(name) if not user: return False if group in user[&apos;groups&apos;]: return True cmd = &apos;net localgroup &quot;&#123;0&#125;&quot; &#123;1&#125; /add&apos;.format(group, name) ret = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) return ret[&apos;retcode&apos;] == 0def removegroup(name, group): &apos;&apos;&apos; 把用户从组中移除 Args: name (str): The user name to remove from the group group (str): The name of the group from which to remove the user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.removegroup jsnuffy &apos;Power Users&apos; &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) group = _to_unicode(group) name = _cmd_quote(name) group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) user = info(name) if not user: return False if group not in user[&apos;groups&apos;]: return True cmd = &apos;net localgroup &quot;&#123;0&#125;&quot; &#123;1&#125; /delete&apos;.format(group, name) ret = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) return ret[&apos;retcode&apos;] == 0def chhome(name, home, **kwargs): &apos;&apos;&apos; 更改家目录 Args: name (str): The name of the user whose home directory you wish to change home (str): The new location of the home directory Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chhome foo \\\\fileserver\\home\\foo True &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) home = _to_unicode(home) kwargs = salt.utils.args.clean_kwargs(**kwargs) persist = kwargs.pop(&apos;persist&apos;, False) if kwargs: salt.utils.args.invalid_kwargs(kwargs) if persist: log.info(&apos;Ignoring unsupported \&apos;persist\&apos; argument to user.chhome&apos;) pre_info = info(name) if not pre_info: return False if home == pre_info[&apos;home&apos;]: return True if not update(name=name, home=home): return False post_info = info(name) if post_info[&apos;home&apos;] != pre_info[&apos;home&apos;]: return post_info[&apos;home&apos;] == home return Falsedef chprofile(name, profile): &apos;&apos;&apos; 修改配置文件目录 Args: name (str): The name of the user whose profile you wish to change profile (str): The new location of the profile Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chprofile foo \\\\fileserver\\profiles\\foo &apos;&apos;&apos; return update(name=name, profile=profile)def chfullname(name, fullname): &apos;&apos;&apos; 修改全名 Args: name (str): The user name for which to change the full name fullname (str): The new value for the full name Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chfullname user &apos;First Last&apos; &apos;&apos;&apos; return update(name=name, fullname=fullname)def chgroups(name, groups, append=True): &apos;&apos;&apos; Change the groups this user belongs to, add append=False to make the user a member of only the specified groups Args: name (str): The user name for which to change groups groups (str, list): A single group or a list of groups to assign to the user. For multiple groups this can be a comma delimited string or a list. append (bool, optional): True adds the passed groups to the user&apos;s current groups. False sets the user&apos;s groups to the passed groups only. Default is True. Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.chgroups jsnuffy Administrators,Users True &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) if isinstance(groups, string_types): groups = groups.split(&apos;,&apos;) groups = [x.strip(&apos; *&apos;) for x in groups] if six.PY2: groups = [_to_unicode(x) for x in groups] ugrps = set(list_groups(name)) if ugrps == set(groups): return True name = _cmd_quote(name) if not append: for group in ugrps: group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) if group not in groups: cmd = &apos;net localgroup &quot;&#123;0&#125;&quot; &#123;1&#125; /delete&apos;.format(group, name) __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) for group in groups: if group in ugrps: continue group = _cmd_quote(group).lstrip(&apos;\&apos;&apos;).rstrip(&apos;\&apos;&apos;) cmd = &apos;net localgroup &quot;&#123;0&#125;&quot; &#123;1&#125; /add&apos;.format(group, name) out = __salt__[&apos;cmd.run_all&apos;](cmd, python_shell=True) if out[&apos;retcode&apos;] != 0: log.error(out[&apos;stdout&apos;]) return False agrps = set(list_groups(name)) return len(ugrps - agrps) == 0def info(name): &apos;&apos;&apos; Return user information Args: name (str): Username for which to display information Returns: dict: A dictionary containing user information - fullname - username - SID - passwd (will always return None) - comment (same as description, left here for backwards compatibility) - description - active - logonscript - profile - home - homedrive - groups - password_changed - successful_logon_attempts - failed_logon_attempts - last_logon - account_disabled - account_locked - password_never_expires - disallow_change_password - gid CLI Example: .. code-block:: bash salt &apos;*&apos; user.info jsnuffy &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) ret = &#123;&#125; items = &#123;&#125; try: items = win32net.NetUserGetInfo(None, name, 4) except win32net.error: pass if items: groups = [] try: groups = win32net.NetUserGetLocalGroups(None, name) except win32net.error: pass ret[&apos;fullname&apos;] = items[&apos;full_name&apos;] ret[&apos;name&apos;] = items[&apos;name&apos;] ret[&apos;uid&apos;] = win32security.ConvertSidToStringSid(items[&apos;user_sid&apos;]) ret[&apos;passwd&apos;] = items[&apos;password&apos;] ret[&apos;comment&apos;] = items[&apos;comment&apos;] ret[&apos;description&apos;] = items[&apos;comment&apos;] ret[&apos;active&apos;] = (not bool(items[&apos;flags&apos;] &amp; win32netcon.UF_ACCOUNTDISABLE)) ret[&apos;logonscript&apos;] = items[&apos;script_path&apos;] ret[&apos;profile&apos;] = items[&apos;profile&apos;] ret[&apos;failed_logon_attempts&apos;] = items[&apos;bad_pw_count&apos;] ret[&apos;successful_logon_attempts&apos;] = items[&apos;num_logons&apos;] secs = time.mktime(datetime.now().timetuple()) - items[&apos;password_age&apos;] ret[&apos;password_changed&apos;] = datetime.fromtimestamp(secs). \ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) if items[&apos;last_logon&apos;] == 0: ret[&apos;last_logon&apos;] = &apos;Never&apos; else: ret[&apos;last_logon&apos;] = datetime.fromtimestamp(items[&apos;last_logon&apos;]).\ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) ret[&apos;expiration_date&apos;] = datetime.fromtimestamp(items[&apos;acct_expires&apos;]).\ strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) ret[&apos;expired&apos;] = items[&apos;password_expired&apos;] == 1 if not ret[&apos;profile&apos;]: ret[&apos;profile&apos;] = _get_userprofile_from_registry(name, ret[&apos;uid&apos;]) ret[&apos;home&apos;] = items[&apos;home_dir&apos;] ret[&apos;homedrive&apos;] = items[&apos;home_dir_drive&apos;] if not ret[&apos;home&apos;]: ret[&apos;home&apos;] = ret[&apos;profile&apos;] ret[&apos;groups&apos;] = groups if items[&apos;flags&apos;] &amp; win32netcon.UF_DONT_EXPIRE_PASSWD == 0: ret[&apos;password_never_expires&apos;] = False else: ret[&apos;password_never_expires&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_ACCOUNTDISABLE == 0: ret[&apos;account_disabled&apos;] = False else: ret[&apos;account_disabled&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_LOCKOUT == 0: ret[&apos;account_locked&apos;] = False else: ret[&apos;account_locked&apos;] = True if items[&apos;flags&apos;] &amp; win32netcon.UF_PASSWD_CANT_CHANGE == 0: ret[&apos;disallow_change_password&apos;] = False else: ret[&apos;disallow_change_password&apos;] = True ret[&apos;gid&apos;] = &apos;&apos; return ret else: return &#123;&#125;def _get_userprofile_from_registry(user, sid): &apos;&apos;&apos; In case net user doesn&apos;t return the userprofile we can get it from the registry Args: user (str): The user name, used in debug message sid (str): The sid to lookup in the registry Returns: str: Profile directory &apos;&apos;&apos; profile_dir = __salt__[&apos;reg.read_value&apos;]( &apos;HKEY_LOCAL_MACHINE&apos;, &apos;SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\&#123;0&#125;&apos;.format(sid), &apos;ProfileImagePath&apos; )[&apos;vdata&apos;] log.debug( &apos;user %s with sid=%s profile is located at &quot;%s&quot;&apos;, user, sid, profile_dir ) return profile_dirdef list_groups(name): &apos;&apos;&apos; Return a list of groups the named user belongs to Args: name (str): The user name for which to list groups Returns: list: A list of groups to which the user belongs CLI Example: .. code-block:: bash salt &apos;*&apos; user.list_groups foo &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) ugrp = set() try: user = info(name)[&apos;groups&apos;] except KeyError: return False for group in user: ugrp.add(group.strip(&apos; *&apos;)) return sorted(list(ugrp))def getent(refresh=False): &apos;&apos;&apos; Return the list of all info for all users Args: refresh (bool, optional): Refresh the cached user information. Useful when used from within a state function. Default is False. Returns: dict: A dictionary containing information about all users on the system CLI Example: .. code-block:: bash salt &apos;*&apos; user.getent &apos;&apos;&apos; if &apos;user.getent&apos; in __context__ and not refresh: return __context__[&apos;user.getent&apos;] ret = [] for user in __salt__[&apos;user.list_users&apos;](): stuff = &#123;&#125; user_info = __salt__[&apos;user.info&apos;](user) stuff[&apos;gid&apos;] = &apos;&apos; stuff[&apos;groups&apos;] = user_info[&apos;groups&apos;] stuff[&apos;home&apos;] = user_info[&apos;home&apos;] stuff[&apos;name&apos;] = user_info[&apos;name&apos;] stuff[&apos;passwd&apos;] = user_info[&apos;passwd&apos;] stuff[&apos;shell&apos;] = &apos;&apos; stuff[&apos;uid&apos;] = user_info[&apos;uid&apos;] ret.append(stuff) __context__[&apos;user.getent&apos;] = ret return retdef list_users(): &apos;&apos;&apos; Return a list of all users on Windows Returns: list: A list of all users on the system CLI Example: .. code-block:: bash salt &apos;*&apos; user.list_users &apos;&apos;&apos; res = 0 user_list = [] dowhile = True try: while res or dowhile: dowhile = False (users, _, res) = win32net.NetUserEnum( None, 0, win32netcon.FILTER_NORMAL_ACCOUNT, res, win32netcon.MAX_PREFERRED_LENGTH ) for user in users: user_list.append(user[&apos;name&apos;]) return user_list except win32net.error: passdef rename(name, new_name): &apos;&apos;&apos; Change the username for a named user Args: name (str): The user name to change new_name (str): The new name for the current user Returns: bool: True if successful, otherwise False CLI Example: .. code-block:: bash salt &apos;*&apos; user.rename jsnuffy jshmoe &apos;&apos;&apos; if six.PY2: name = _to_unicode(name) new_name = _to_unicode(new_name) # Load information for the current name current_info = info(name) if not current_info: raise CommandExecutionError(&apos;User \&apos;&#123;0&#125;\&apos; does not exist&apos;.format(name)) # Look for an existing user with the new name new_info = info(new_name) if new_info: raise CommandExecutionError( &apos;User \&apos;&#123;0&#125;\&apos; already exists&apos;.format(new_name) ) # Rename the user account # Connect to WMI pythoncom.CoInitialize() c = wmi.WMI(find_classes=0) # Get the user object try: user = c.Win32_UserAccount(Name=name)[0] except IndexError: raise CommandExecutionError(&apos;User \&apos;&#123;0&#125;\&apos; does not exist&apos;.format(name)) # Rename the user result = user.Rename(new_name)[0] # Check the result (0 means success) if not result == 0: # Define Error Dict error_dict = &#123;0: &apos;Success&apos;, 1: &apos;Instance not found&apos;, 2: &apos;Instance required&apos;, 3: &apos;Invalid parameter&apos;, 4: &apos;User not found&apos;, 5: &apos;Domain not found&apos;, 6: &apos;Operation is allowed only on the primary domain controller of the domain&apos;, 7: &apos;Operation is not allowed on the last administrative account&apos;, 8: &apos;Operation is not allowed on specified special groups: user, admin, local, or guest&apos;, 9: &apos;Other API error&apos;, 10: &apos;Internal error&apos;&#125; raise CommandExecutionError( &apos;There was an error renaming \&apos;&#123;0&#125;\&apos; to \&apos;&#123;1&#125;\&apos;. Error: &#123;2&#125;&apos; .format(name, new_name, error_dict[result]) ) return info(new_name).get(&apos;name&apos;) == new_namedef current(sam=False): &apos;&apos;&apos; Get the username that salt-minion is running under. If salt-minion is running as a service it should return the Local System account. If salt is running from a command prompt it should return the username that started the command prompt. .. versionadded:: 2015.5.6 Args: sam (bool, optional): False returns just the username without any domain notation. True returns the domain with the username in the SAM format. Ie: ``domain\\username`` Returns: str: Returns username CLI Example: .. code-block:: bash salt &apos;*&apos; user.current &apos;&apos;&apos; try: if sam: user_name = win32api.GetUserNameEx(win32con.NameSamCompatible) else: user_name = win32api.GetUserName() except pywintypes.error as exc: log.error(&apos;Failed to get current user&apos;) log.error(&apos;nbr: %s&apos;, exc.winerror) log.error(&apos;ctx: %s&apos;, exc.funcname) log.error(&apos;msg: %s&apos;, exc.strerror) raise CommandExecutionError(&apos;Failed to get current user&apos;, info=exc) if not user_name: raise CommandExecutionError(&apos;Failed to get current user&apos;) return user_name 参考资料]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python win32net Windows Users</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat]]></title>
    <url>%2Ffilebeat.html</url>
    <content type="text"><![CDATA[filebeatfilebeat 是基于原先 logstash-forwarder 的源码改造出来的。换句话说：filebeat 就是新版的 logstash-forwarder，也会是 Elastic Stack 在 shipper 端的第一选择。 安装部署 deb: 12curl -L -O https://download.elastic.co/beats/filebeat/filebeat_5.0.0_amd64.debsudo dpkg -i filebeat_5.0.0_amd64.deb rpm: 1234curl -L -O https://download.elastic.co/beats/filebeat/filebeat-5.0.0-x86_64.rpm包可以去官网从新下载过https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.2.2-x86_64.rpmsudo rpm -vi filebeat-5.0.0-x86_64.rpm mac: 12curl -L -O https://download.elastic.co/beats/filebeat/filebeat-5.0.0-darwin.tgztar xzvf filebeat-5.0.0-darwin.tgz win: 12345678910下载 https://download.elastic.co/beats/filebeat/filebeat-5.0.0-windows.zip解压到 C:\Program Files重命名 filebeat-5.0.0-windows 目录为 Filebeat右键点击 PowerSHell 图标，选择『以管理员身份运行』运行下列命令，将 Filebeat 安装成 windows 服务：PS &gt; cd &apos;C:\Program Files\Filebeat&apos;PS C:\Program Files\Filebeat&gt; .\install-service-filebeat.ps1注意可能需要额外授予执行权限。命令为：PowerShell.exe -ExecutionPolicy RemoteSigned -File .\install-service-filebeat.ps1. filebeat 配置所有的 beats 组件在 output 方面的配置都是一致的，之前章节已经介绍过。这里只介绍 filebeat 在 input 段的配置，如下：1234567891011121314151617181920212223242526272829303132filebeat: spool_size: 1024 # 最大可以攒够 1024 条数据一起发送出去 idle_timeout: &quot;5s&quot; # 否则每 5 秒钟也得发送一次 registry_file: &quot;.filebeat&quot; # 文件读取位置记录文件，会放在当前工作目录下。所以如果你换一个工作目录执行 filebeat 会导致重复传输！ config_dir: &quot;path/to/configs/contains/many/yaml&quot; # 如果配置过长，可以通过目录加载方式拆分配置 prospectors: # 有相同配置参数的可以归类为一个 prospector - fields: ownfield: &quot;mac&quot; # 类似 logstash 的 add_fields paths: - /var/log/system.log # 指明读取文件的位置 - /var/log/wifi.log include_lines: [&quot;^ERR&quot;, &quot;^WARN&quot;] # 只发送包含这些字样的日志 exclude_lines: [&quot;^OK&quot;] # 不发送包含这些字样的日志 - document_type: &quot;apache&quot; # 定义写入 ES 时的 _type 值 ignore_older: &quot;24h&quot; # 超过 24 小时没更新内容的文件不再监听。在 windows 上另外有一个配置叫 force_close_files，只要文件名一变化立刻关闭文件句柄，保证文件可以被删除，缺陷是可能会有日志还没读完 scan_frequency: &quot;10s&quot; # 每 10 秒钟扫描一次目录，更新通配符匹配上的文件列表 tail_files: false # 是否从文件末尾开始读取 harvester_buffer_size: 16384 # 实际读取文件时，每次读取 16384 字节 backoff: &quot;1s&quot; # 每 1 秒检测一次文件是否有新的一行内容需要读取 paths: - &quot;/var/log/apache/*&quot; # 可以使用通配符 exclude_files: [&quot;/var/log/apache/error.log&quot;] - input_type: &quot;stdin&quot; # 除了 &quot;log&quot;，还有 &quot;stdin&quot; multiline: # 多行合并 pattern: &apos;^[[:space:]]&apos; negate: false match: afteroutput: ... 我们已完成了配置，当 sudo service filebeat start 之后，你就可以在 kibana 上看到你的日志了。 字段Filebeat 发送的日志，会包含以下字段： beat.hostname beat 运行的主机名 beat.name shipper 配置段设置的 name，如果没设置，等于 beat.hostname @timestamp 读取到该行内容的时间 type 通过 document_type 设定的内容 input_type 来自 “log” 还是 “stdin” source 具体的文件名全路径 offset 该行日志的起始偏移量 message 日志内容 fields 添加的其他固定字段都存在这个对象里面]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>filebeat install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sersync]]></title>
    <url>%2Fsersync.html</url>
    <content type="text"><![CDATA[date:Write by lyc at 2018-08-10 1.sersync介绍sersync的实时数据同步： sersync监控指定的目录，对监控路径下变化的文件进行实时同步到rsync的服务端。 整个过程相当于rsync+inotify，并且推送是通过rsync --delete的，所以使用的时候要谨慎。 2.下载安装 部署前需要在被同步端（rsync服务端）开启响应的ip allow权限，以及增加rsync demon模式的区块配置。一个区块配置对应一个sersync的进程。 1234cd /usr/local/srcwget -S http://nagios.bytech.boyihuyu.com/linux/tools/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gztar xvf sersync2.5.4_64bit_binary_stable_final.tar.gz -C /usr/local/ln -s /usr/local/sersync2.5.4 /usr/local/sersync 3.配置文件如果想要监控多个目录，拷贝多个配置文件对应起多个进程来实时监控。 12cd /usr/local/sersync/conf/cp confxml.xml yd_vhosts.xml 只需要配置配置文件yd_vhosts.xml下的&lt;sersync&gt;区块 12345678910111213141516171819202122&lt;sersync&gt; &lt;localpath watch=&quot;/usr/local/nginx/conf/vhosts/&quot;&gt; &lt;remote ip=&quot;x.x.x.x&quot; name=&quot;yd_web_nginx_config&quot;/&gt; # rsync服务端ip，区块名 &lt;!--&lt;remote ip=&quot;192.168.8.39&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;!--&lt;remote ip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params=&quot;-artuz&quot;/&gt; &lt;auth start=&quot;false&quot; users=&quot;root&quot; passwordfile=&quot;/etc/rsync.pas&quot;/&gt; # 如果需要密码，改成true，对应密码文件600 &lt;userDefinedPort start=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt; &lt;timeout start=&quot;true&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt; # 超时时间，可开可不开。 &lt;ssh start=&quot;false&quot;/&gt; &lt;/rsync&gt; # 错误日志路径 &lt;failLog path=&quot;/usr/local/sersync/log/yd_vhosts_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--default every 60mins execute once--&gt; &lt;crontab start=&quot;false&quot; schedule=&quot;600&quot;&gt;&lt;!--600mins--&gt; &lt;crontabfilter start=&quot;false&quot;&gt; &lt;exclude expression=&quot;*.php&quot;&gt;&lt;/exclude&gt; &lt;exclude expression=&quot;info/*&quot;&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start=&quot;false&quot; name=&quot;command&quot;/&gt;&lt;/sersync&gt; 4.启动12345/usr/local/sersync/bin/sersync2 -r -d -o /usr/local/sersync/conf/yd_vhosts.xml# -r 第一次启动进行一次推送# -d 守护进程# -o 指定配置文件]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>sersync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsyncd]]></title>
    <url>%2Flsyncd.html</url>
    <content type="text"><![CDATA[Write by zjModify by lyc官网文档：https://axkibe.github.io/lsyncd/ 一、lsyncd 介绍 Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。 二、lsyncd安装ubuntu安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过(安装的版本是2.1.5) 1apt-get install lsyncd Redhat可以手动去下载lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖 1yum install lua lua-devel -y 也可以通过在线安装，需要epel-release扩展包： 12rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install lsyncd -y 编译安装github上下载lsyncd-master.zip 的2.2.2版本使用的是 cmake 编译工具，无法./configure： 1234uzip lsyncd-master.zipcd lsyncd-mastercmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncdmake &amp;&amp; make install 三、lsyncd配置配置文件1234567891011121314151617181920212223shell &gt; cat lsyncd.conf.luasettings &#123; logfile = &quot;/data/logs/lsyncd/lsyncd.log&quot;, statusFile = &quot;/data/logs/lsyncd/lsyncd.status&quot;, inotifyMode = &quot;CloseWrite or Modify&quot;, maxProcesses = 8, -- nodaemon =true, &#125;sync &#123; default.rsync, source = &quot;/data/rsyslog&quot;, target = &quot;x.x.x.x::bgo_log_server&quot;, -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, delay = 30, init = false, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, append = true &#125; &#125; 配置文件说明 settings里面是全局设置，–开头表示注释，下面是几个常用选项说明： logfile 定义日志文件 stausFile 定义状态文件 nodaemon=true 表示不启用守护模式，默认 statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒 inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程 maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到 sync里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。 一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式： default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程； default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份； default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证 source 同步的源目录，使用绝对路径。 target 定义目的地址.对应不同的模式有几种写法： /tmp/dest ：本地目录同步，可用于direct和rsync模式 ip:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd –delete –include-from=- –exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步 ip::module ：同步到远程服务器目录，用于rsync模式 init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件） excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = “/etc/lsyncd.exclude”，如果是简单的排除，可以使用exclude = LIST。这里的排除规则写法与原生rsync有点不同，更为简单： 监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo 如果规则以斜线/开头，则从头开始要匹配全部 如果规则以/结尾，则要匹配监控路径的末尾 ?匹配任何字符，但不包括/ *匹配0或多个字符，但不包括/ **匹配0或多个字符，可以是/ delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。 创建配置文件1CONFIG=/etc/lsyncd/lsyncd.conf.lua 四、启动123/usr/local/lsyncd/bin/lsyncd -pidfile /var/run/lsyncd.pid /etc/lsyncd/lsyncd.conf.lua# 或者/etc/init.d/lsyncd start 五、遇到问题IO过大 运用场景 日志实时写，做到实时同步 每次同步，多会重新同步一次文件，造成io过高 解决方案 升级lsyncd 到2.x 版本 2.x版本才支持rsync append (追加同步减少io) 123456789101112131415/etc/init.d/lsyncd stopgit clone https://github.com/axkibe/lsyncd.gitapt-get remove lsyncdapt-get install liblua5.1-0-devcd lsyncd/cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncdmakemake install# 修改配置文件sync - rsyncvim /etc/lsyncd/lsyncd.conf.luaappend = true, # 修改启动文件 bin 路径vim /etc/init.d/lsyncd # 启动/etc/init.d/lsyncd start]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>lsyncd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisord]]></title>
    <url>%2FSupervisord.html</url>
    <content type="text"><![CDATA[date:create by CQ,modify by lyc at 2017.11参考博文：http://www.ttlsa.com/linux/using-supervisor-control-program/ 1.supervisord 介绍Supervisor (http://supervisord.org) 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。 除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。 2.supervisord 安装1.supervisor 是 Python 编写的，所以安装起来也很方便，可以直接用 pip123456shell&gt; yum install -y python-devel openssl openssl-develshell&gt; curl -O https://bootstrap.pypa.io/get-pip.pyshell&gt; python get-pip.pyshell&gt; pip install setuptoolsshell&gt; pip install -U setuptoolsshell&gt; pip install supervisor 2.安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件。 1shell&gt; echo_supervisord_conf &gt; /etc/supervisord.conf 3.修改配置文件，把 /etc/supervisord.conf 里 include 部分的的配置修改一下，目的是为了“一个进程对应一个管理的配置文件”，方便管理。 123shell&gt; mkdir /etc/supervisorshell&gt; sed -i &apos;s#\;\[include\]#\[include\]#&apos; /etc/supervisord.confshell&gt; sed -i &apos;/relative\/directory/a\files = /etc/supervisor/*.ini&apos; /etc/supervisord.conf 3.supervisord 管理进程配置3.1 /etc/supervisord.conf 主配置文件说明去除里面大部分注释和“不相关”的部分，我们可以先看这些配置： 123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini 3.1.管理进程配置说明路径：/etc/supervisor 12345678910111213141516[program:usercenter]directory = /home/leon/projects/usercenter ; 程序的启动目录command = gunicorn -c gunicorn.py wsgi:app ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = leon ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/usercenter_stdout.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 3.2 supervisord 进程管理配置文件示例 生产环境站点程序管理示例 12345678910111213[root@10 supervisor]# cat pc.yd.cc.ini[program:pc.yd.cc]directory = /data/wwwroot/pc.yd.cccommand = python3 /data/wwwroot/pc.yd.cc/application.pyautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/supervisord_logs/pc.yd.cc.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/supervisord_logs/pc.yd.cc.err 其他示例1 123456789101112[program:npc_filebeat_mysql]directory = /data/npcgame/npcgame_app_common/filebeat_mysqlcommand = /data/npcgame/npcgame_app_common/filebeat_mysql/filebeats -e -c /data/npcgame/npcgame_app_common/filebeat_mysql/filebeat_mysql.ymlautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/httplogs/npc_filebeat_mysql_access.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/httplogs/npc_filebeat_mysql_error.log 其他示例2 1234567891011[program:shadowsocks]command = /usr/local/bin/ssserver -c /etc/shadowsocks.jsonautostart = trueautorestart = truestartretries = 5stdout_logfile_maxbytes = 20MBstdout_logfile_backups = 20stdout_logfile = /data/shadowsocks/shadowsocks_access.logstderr_logfile_maxbytes = 20MBstderr_logfile_backups = 20stderr_logfile = /data/shadowsocks/shadowsocks_error.log 4.supervisord 使用Supervisord安装完成后有两个可用的命令行： supervisor supervisorctl 4.1.启动或关闭Supervisord1234567# 初始启动Supervisord，启动、管理配置中设置的进程。shell&gt; supervisord或shell&gt; /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf# 关闭supervisordshell&gt; supervisorctl shutdown 4.2.验证Supervisord进程是否启动123shell&gt; ps aux|grep -i supervisordroot 31932 0.0 0.0 103324 964 pts/1 S+ 09:57 0:00 grep -i supervisordroot 32383 0.0 0.0 210480 14500 ? Ss Nov03 3:16 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf Supervisord的管理方式分为： shell命令行管理 supervisorctl命令行管理 4.3.shell命令行管理supervisordshell&gt; supervisorctl 动作 进程名 12345678910111213141516171819# 当进程的独立配置文件有变化时（增删进程），载入最新的配置文件。shell&gt; supervisorctl update# 停止某一个进程(programxxx)，programxxx为[program:blogdemon]里配置的值，这个示例就是blogdemon。shell&gt; supervisorctl stopp programxxx# 启动某个进程shell&gt; supervisorctl start programxxx# 重启某个进程shell&gt; supervisorctl restart programxxx# 停止全部进程shell&gt; supervisorctl stop all&gt; 注：start、restart、stop都不会载入最新的配置文件。# 载入最新的配置文件，并按新的配置启动、管理所有进程。shell&gt; supervisorctl reload 4.4.supervisorctl命令行管理123456789# 会进入 supervisorctl 的shell界面，然后可以执行不同的命令了shell&gt; supervisorctl&gt; status # 查看进程状态&gt; stop programxxx # 关闭 usercenter 程序&gt; start programxxx # 启动 usercenter 程序&gt; restart programxxx # 重启 usercenter 程序&gt; reread # 读取有更新（增加）的配置文件，不会启动新添加的程序&gt; update # 重启配置文件修改过的程序 5.其他除了 supervisorctl 之外，还可以配置 supervisrod 启动 web 管理界面，这个 web 后台使用 Basic Auth 的方式进行身份认证。除了单个进程的控制，还可以配置 group，进行分组管理。经常查看日志文件，包括 supervisord 的日志和各个 pragram 的日志文件，程序 crash 或抛出异常的信息一半会输出到 stderr，可以查看相应的日志文件来查找问题。Supervisor 有很丰富的功能，还有其他很多项配置，可以在官方文档获取更多信息：http://supervisord.org/index.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-install]]></title>
    <url>%2Fphp-install.html</url>
    <content type="text"><![CDATA[Building PHP from Sources author by CQ 安装环境依赖包$ yum -y install gcc gcc+ gcc-c++ gcc-g77 flex bison autoconf snmp automake\ bzip2-devel zlib-devel readline-devel ncurses-devel libjpeg-devel \ libpng-devel libtiff-devel freetype-devel pam-devel openssl-devel \ mod_ssl libxml2-devel gettext-devel pcre-devel curl-devel mysql-devel \ libevent-devel libtool-ltdl gmp-devel openldap openldap-devel \ ImageMagick-devel libtool net-snmp-devel libwebp libwebp-devel 下载编译包 libiconv $ cd /usr/local/src $ wget https://ftp.gnu.org/gnu/libiconv/libiconv-1.15.tar.gz libmcrypt $ wget https://ncu.dl.sourceforge.net/project/mcrypt/Libmcrypt/2.5.8/libmcrypt-2.5.8.tar.gz mcrypt $ wget https://ncu.dl.sourceforge.net/project/mcrypt/MCrypt/2.6.8/mcrypt-2.6.8.tar.gz mhash $ wget https://ncu.dl.sourceforge.net/project/mhash/mhash/0.9.9.9/mhash-0.9.9.9.tar.gz php $ wget http://cn2.php.net/distributions/php-7.1.12.tar.gz 解压 $ tar zxf libiconv-1.15.tar.gz $ tar zxf libmcrypt-2.5.8.tar.gz $ tar zxf mcrypt-2.6.8.tar.gz $ tar zxf mhash-0.9.9.9.tar.gz $ tar zxf php-7.1.12.tar.gz 安装编译包 加载lib $ echo &quot;/usr/lib&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/lib64&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf $ echo &quot;/usr/local/lib64&quot; &gt;&gt; /etc/ld.so.conf $ /sbin/ldconfig 安装libiconv ## libiconv库为需要做转换的应用程序提供了一个iconv命令，以实现一个字符编码到另一个字符编码的转换，比如它可以将UTF8编码转换成GB18030编码，反过来也行 $ cd /usr/local/src/libiconv-1.15 $ ./configure --prefix=/usr/local $ make &amp;&amp; make install $ /sbin/ldconfig 安装libmcrypt $ cd /usr/local/src/libmcrypt-2.5.8 $ ./configure &amp;&amp; make &amp;&amp; make install $ /sbin/ldconfig $ cd libltdl/ $ ./configure --prefix=/usr/local --enable-ltdl-install $ make &amp;&amp; make install $ /sbin/ldconfig 安装mhash $ cd /usr/local/src/libmcrypt-2.5.8 $ ./configure $ make &amp;&amp; make install 安装mcrypt $ cd /usr/local/src/mhash-0.9.9.9 $ ./configure $ make &amp;&amp; make install $ /sbin/ldconfig 安装php 编译php $ cd /usr/local/src/php-7.1.12 $ ./configure --prefix=/usr/local/php-7.1.12 \ --with-config-file-path=/usr/local/php-7.1.12/etc \ --enable-fpm --enable-pcntl \ --with-pear=/usr/share/php \ --with-mysql --with-mysqli \ --with-pdo_mysql --with-iconv-dir=/usr/local \ --with-zlib --with-bz2 \ --with-curl --with-libxml-dir \ --with-gd --with-jpeg-dir \ --with-png-dir --with-zlib-dir \ --with-freetype-dir --with-openssl \ --with-gettext --with-snmp \ --with-mhash --with-mcrypt \ --enable-gd-native-ttf --enable-gd-jis-conv \ --enable-shmop --enable-sockets \ --enable-zip --enable-ftp \ --enable-bcmath --enable-soap \ --enable-calendar --enable-dba \ --disable-ipv6 --enable-opcache $ make &amp;&amp; make install php. $ /usr/bin/make ZEND_EXTRA_LIBS=&apos;-liconv&apos; &amp;&amp; /usr/bin/make install $ ln -s /usr/local/php-7.1.12 /usr/local/php 安装php module依赖包 ImageMagick ## 下载ImageMagick $ wget http://transloadit.imagemagick.org/download/ImageMagick-7.0.7-11.tar.gz or $ wget http://transloadit.imagemagick.org/download/ImageMagick-6.9.9-23.tar.gz $ ## 编译依赖库ImageMagick，centos自带的ImageMagick版本较低 $ cd /usr/local/src $ tar -zxf ImageMagick-7.0.7-11.tar.gz $ cd ImageMagick-7.0.7-11 $ ./configure $ make &amp;&amp; make install $ /sbin/ldconfig libevent ## 下载libevent $ wget https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz ## 编译拓展libevent $ cd /usr/local/src $ tar xzf libevent-${libevent_ver}-stable.tar.gz $ cd libevent-${libevent_ver}-stable $ ./configure --prefix=/usr/local $ make &amp;&amp; make install $ /sbin/ldconfig 安装php module安装php module有两种手动方式，追求最新的功能可以手动编译安装，或者使用pecl(类似于pip) 安装 手动安装 imagick ## 下载imagick $ cd /usr/local/src $ wget http://pecl.php.net/get/imagick-3.4.3.tgz ## 编译拓展imagick $ tar zxf imagick-3.4.3.tgz $ cd imagick-3.4.3 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make &amp;&amp; make install memcache ## 下载memcache $ wget http://pecl.php.net/get/memcache-3.0.8.tgz ## 编译拓展memcache $ cd /usr/local/src $ tar zxf memcache-3.0.8.tgz $ cd memcache-3.0.8 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config --with-zlib-dir --enable-memcache $ make &amp;&amp; make install phpredis ## 下载phpredis $ wget https://pecl.php.net/get/redis-3.1.4.tgz ## 编译拓展redis $ cd /usr/local/src $ tar zxf redis-3.1.4.tgz $ cd redis-3.1.4 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config --enable-redis $ make &amp;&amp; make install mongo ## 下载mongo $ wget https://pecl.php.net/get/mongo-1.6.16.tgz ## 编译拓展mongo $ cd /usr/local/src $ tar xzf mongo-1.6.16.tgz $ cd mongo-1.6.16 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make &amp;&amp; make install xdebug ## 下载xdebug $ wget https://xdebug.org/files/xdebug-2.5.5.tgz ## 编译拓展xdebug ### 如果需要将 Xdebug 扩展和 OPcache 一起使用，必须在 Xdebug 扩展之前加载 OPcache 扩展。 $ cd /usr/local/src $ tar xzf xdebug-2.5.5.tgz $ cd xdebug-2.5.5 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config # make &amp;&amp; make install $ make -j `grep processor /proc/cpuinfo | wc -l` &amp;&amp; make install pecl安装 $ /usr/local/php/bin/pecl install imagick $ /usr/local/php/bin/pecl install memcache $ /usr/local/php/bin/pecl install redis $ /usr/local/php/bin/pecl install mongo ### 如果需要将 Xdebug 扩展和 OPcache 一起使用，必须在 Xdebug 扩展之前加载 OPcache 扩展。 $ /usr/local/php/bin/pecl install xdebug 配置php 配置php # set php-fpm config file. $ cp /usr/local/php/etc/php-fpm.conf{.,default} $ cat &gt; /usr/local/php/etc/php-fpm.conf &lt;&lt;EOF [global] pid = /usr/local/php-7.1.12/var/run/php-fpm.pid error_log = /usr/local/php-7.1.12/var/log/php-fpm.log log_level = error [www] listen = /usr/local/php/etc/php-cgi.socket user = nginx group = nginx listen.owner = nginx listen.group = nginx listen.mode = 0660 pm = static pm.max_children = 200 pm.start_servers = 20 pm.min_spare_servers = 5 pm.max_spare_servers = 30 pm.max_requests = 5000 request_slowlog_timeout = 5s slowlog = /usr/local/php-7.1.12/var/log/php-fpm.log.slow rlimit_files = 51200 EOF # set php.ini config file. $ cp /usr/local/src/php-7.1.12/php.ini-production /usr/local/php-7.1.12/etc/php.ini $ cp /usr/local/php-7.1.12/etc/php.ini{.,default} $ ext_path=`ls /usr/local/php-7.1.12/lib/php/extensions/` $ cat &gt;&gt; /usr/local/php-7.1.12/etc/php.ini &lt;&lt;EOF extension_dir = /usr/local/php/lib/php/extensions/${ext_path} extension = &quot;memcache.so&quot; extension = &quot;imagick.so&quot; extension = &quot;redis.so&quot; zend_extension = &quot;opcache.so&quot; output_buffering = On cgi.fix_pathinfo=0 EOF # 修改文件上传大小 $ sed -i &quot;s#^upload_max_filesize = 2M#upload_max_filesize = 5M#&quot; /usr/local/php-7.1.12/etc/php.ini # 限制php运行目录 $ sed -i &quot;s#^;open_basedir =#open_basedir = /tmp:/data/wwwroot/:/data/ftp/:/www/web#&quot; /usr/local/php-7.1.12/etc/php.ini # 关闭php版本信息 $ sed -i &quot;s#^expose_php = On#expose_php = Off#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^allow_url_fopen = On#allow_url_fopen = Off#&quot; /usr/local/php-7.1.12/etc/php.ini # opcache $ sed -i &quot;s#^;opcache.enable=0#opcache.enable=1#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.enable_cli=0#opcache.enable_cli=1#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.memory_consumption=64#opcache.memory_consumption=128#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.interned_strings_buffer=4#opcache.memory_consumption=8#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.max_accelerated_files=2000#opcache.max_accelerated_files=4000#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.revalidate_freq=2#opcache.revalidate_freq=60#&quot; /usr/local/php-7.1.12/etc/php.ini $ sed -i &quot;s#^;opcache.fast_shutdown=0#opcache.fast_shutdown=1#&quot; /usr/local/php-7.1.12/etc/php.ini # disable_functions 本指令允许你基于安全原因禁止某些函数。接受逗号分隔的函数名列表作为参数。 # disable_functions 不受安全模式的影响。 本指令只能设置在 php.ini 中 $ sed -i &quot;s#^disable_functions =#disable_functions = passthru,ini_restore,eval#&quot; /usr/local/php-7.1.12/etc/php.ini # 修改时区,具体时区参考：http://php.net/manual/zh/timezones.php $ sed -i &quot;s#^;date.timezone =#date.timezone = Asia/Shanghai#&quot; /usr/local/php-7.1.12/etc/php.ini 配置php-fpm启动脚本 $ cat &gt; /etc/init.d/php-fpm &lt;&lt;EOF #! /bin/sh ### BEGIN INIT INFO # Provides: php-fpm # Required-Start: $remote_fs $network # Required-Stop: $remote_fs $network # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: starts php-fpm # Description: starts the PHP FastCGI Process Manager daemon ### END INIT INFO prefix=/usr/local/php exec_prefix=${prefix} php_fpm_BIN=${exec_prefix}/sbin/php-fpm php_fpm_CONF=${prefix}/etc/php-fpm.conf php_fpm_PID=${prefix}/var/run/php-fpm.pid php_opts=&quot;--fpm-config=${php_fpm_CONF}&quot; wait_for_pid () { try=0 while test $try -lt 35 ; do case &quot;$1&quot; in &apos;created&apos;) if [ -f &quot;$2&quot; ] ; then try=&apos;&apos; break fi ;; &apos;removed&apos;) if [ ! -f &quot;$2&quot; ] ; then try=&apos;&apos; break fi ;; esac echo -n . try=`expr $try + 1` sleep 1 done } case &quot;$1&quot; in start) echo -n &quot;Starting php-fpm &quot; $php_fpm_BIN --daemonize $php_opts &amp;&amp; chown -R nginx.nginx ${prefix}/etc/php-cgi.socket if [ &quot;$?&quot; != 0 ] ; then echo &quot; failed&quot; exit 1 fi wait_for_pid created $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; stop) echo -n &quot;Gracefully shutting down php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -QUIT `cat $php_fpm_PID` wait_for_pid removed $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed. Use force-quit&quot; exit 1 else echo &quot; done&quot; fi ;; status) if [ ! -r $php_fpm_PID ] ; then echo &quot;php-fpm is stopped&quot; exit 0 fi PID=`cat $php_fpm_PID` if ps -p $PID | grep -q $PID; then echo &quot;php-fpm (pid $PID) is running...&quot; else echo &quot;php-fpm dead but pid file exists&quot; fi ;; force-quit) echo -n &quot;Terminating php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -TERM `cat $php_fpm_PID` wait_for_pid removed $php_fpm_PID if [ -n &quot;$try&quot; ] ; then echo &quot; failed&quot; exit 1 else echo &quot; done&quot; fi ;; restart) $0 stop $0 start ;; reload) echo -n &quot;Reload service php-fpm &quot; if [ ! -r $php_fpm_PID ] ; then echo &quot;warning, no pid file found - php-fpm is not running ?&quot; exit 1 fi kill -USR2 `cat $php_fpm_PID` echo &quot; done&quot; ;; *) echo &quot;Usage: $0 {start|stop|force-quit|restart|reload|status}&quot; exit 1 ;; esac EOF $ chmod 755 /etc/init.d/php-fpm $ chkconfig --level 35 php-fpm on]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>PHP install from source</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TMG-error]]></title>
    <url>%2FTMG-error.html</url>
    <content type="text"><![CDATA[错误原因: 找不到证书。使用通过 IPSec 的 L2TP 协议的连接要求安装一个机器证书 window 2008 r2 系统安装TMG 2010 VPN 服务器报错，查看日志 错误原因: 找不到证书。使用通过 IPSec 的 L2TP 协议的连接要求安装一个机器证书，它也叫做计算机证书 客户只用到PPTP的连接，没用L2TP，于是决定将L2TP的IPsec策略禁用掉 开始-运行regedit.exe,打开注册表，找到 HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\Rasman\Parameters 新建一个DWORD值ProhibitIPsec，值设置为1 金山云搭建TMG 遇见的坑 问题1、内网地址是通过DHCP 获取的。 解决方案： 一、TMG-防火墙策略-需要添加允许DHCP 的协议 DHCP(答复) DHCP(允许) 二、开启启动时禁用和启用网卡12345C:\boot.bat （隐藏文件）set vif_name=lan(网卡名字)ping -n 20 127.0.0.1&gt;1.txtnetsh interface ip set interface &quot;%vif_name%&quot; disablednetsh interface ip set interface &quot;%vif_name%&quot; enabled 问题2、VPN网络无法访问其他主机，因为金山云没有回路由，现象就过去了，没反应。 解决方案: 增加路由 登入金山云控制台—虚拟私有网络—路由—新建路由 虚拟私有网络选择，云主机网段，目前网络写分配给VPN 自动获取的网段 下一条选择TMG 云主机]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>VPN 错误原因: 找不到证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各家云服务器商的对比]]></title>
    <url>%2Fcloud.html</url>
    <content type="text"><![CDATA[图仅共参考，在当下（随着时间，各家云都会发生变化），个人觉得还是比较靠谱的。 根据个人或者公司的情况，选择合适的云服务商。 按量分 量大就选择阿里腾讯，可以拿到比较好的折扣（月消耗在50万以上）（服务好，技术全） 量中等就选择金山云，白山云, ucloud等（技术还行，服务好） 友情介绍 需要的朋友，可以发邮件给我zj@s3v.cn, 可以给你们介绍，目前可以介绍金山云，腾讯云，白山云，七牛云, ucloud。这边因为公司有量，拿到不错的折扣。折扣可以对比，选择低的就好。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>各家云服务器商的对比</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-re]]></title>
    <url>%2Fpython-re.html</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/chuxiuhong/p/5885073.html Python 正则表达式入门（初级篇）引子 首先说 正则表达式是什么？ 正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成“regex”，单数有regexp、regex，复数有regexps、regexes、regexen。引用自维基百科https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F 定义是定义，太正经了就没法用了。我们来举个栗子：假如你在写一个爬虫，你得到了一个网页的HTML源码。其中有一段 1&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt; 你想要把这个hello world提取出来，但你这时如果只会python 的字符串处理，那么第一反应可能是 12s = &lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;start_index = s.find(&apos;&lt;h1&gt;&apos;) 然后从这个位置向下查找到下一个&lt;h1>出现这样做未尝不可，但是很麻烦不是吗。需要考虑多个标签，一不留神就多匹配到东西了，而如果想要非常准确的匹配到，又得多加循环判断，效率太低。 这时候，正则表达式就是首选的帮手。 干货开始入门级别 接着说我们刚才那个例子。我们如果拿正则处理这个表达式要怎么做呢？ 1234567import rekey = r&quot;&lt;html&gt;&lt;body&gt;&lt;h1&gt;hello world&lt;h1&gt;&lt;/body&gt;&lt;/html&gt;&quot;#这段是你要匹配的文本p1 = r&quot;(?&lt;=&lt;h1&gt;).+?(?=&lt;h1&gt;)&quot;#这是我们写的正则表达式规则，你现在可以不理解啥意思pattern1 = re.compile(p1)#我们在编译这段正则表达式matcher1 = re.search(pattern1,key)#在源文本中搜索符合正则表达式的部分print matcher1.group(0)#打印出来 你可以尝试运行上面的代码，看看是不是和我们想象的一样（博主是在python2.7环境下）发现代码挺少挺简单？往下看。而且正则表达式实际上要比看起来的那种奇形怪状要简单得多。 首先，从最基础的正则表达式说起。假设我们的想法是把一个字符串中的所有”python”给匹配到。我们试一试怎么做 1234567import rekey = r&quot;javapythonhtmlvhdl&quot;#这是源文本p1 = r&quot;python&quot;#这是我们写的正则表达式pattern1 = re.compile(p1)#同样是编译matcher1 = re.search(pattern1,key)#同样是查询print matcher1.group(0) 看完这段代码，你是不是觉得：卧槽？这就是正则表达式？直接写上去就行？确实，正则表达式并不像它表面上那么奇葩，如果不是我们故意改变一些符号的含义时，你看到的就是想要匹配的。所以，先把大脑清空，先认为正则表达式就是和想要匹配的字符串长得一样。在之后的练习中我们会逐步进化 初级 0.无论是python还是正则表达式都是区分大小写的，所以当你在上面那个例子上把”python”换成了”Python”，那就匹配不到你心爱的python了。 1.重新回到第一个例子中那个&lt;h1>hello world&lt;h1>匹配。假如我像这么写，会怎么样？ 123456import rekey = r&quot;&lt;h1&gt;hello world&lt;h1&gt;&quot;#源文本p1 = r&quot;&lt;h1&gt;.+&lt;h1&gt;&quot;#我们写的正则表达式，下面会将为什么pattern1 = re.compile(p1)print pattern1.findall(key)#发没发现，我怎么写成findall了？咋变了呢？ 有了入门级的经验，我们知道那两个&lt;h1>就是普普通通的字符，但是中间的是什么鬼？.字符在正则表达式代表着可以代表任何一个字符（包括它本身）findall返回的是所有符合要求的元素列表，包括仅有一个元素时，它还是给你返回的列表。 机智如你可能会突然问：那我如果就只是想匹配”.”呢？结果啥都给我返回了咋整？在正则表达式中有一个字符\，其实如果你编程经验较多的话，你就会发现这是好多地方的“转义符”。在正则表达式里，这个符号通常用来把特殊的符号转成普通的，把普通的转成特殊的23333（并不是特殊的“2333”，写完才发现会不会有脑洞大的想歪了）。举个栗子，你真的想匹配”chuxiuhong@hit.edu.cn“这个邮箱（我的邮箱），你可以把正则表达式写成下面这个样子： 123456import rekey = r&quot;afiouwehrfuichuxiuhong@hit.edu.cnaskdjhfiosueh&quot;p1 = r&quot;chuxiuhong@hit\.edu\.cn&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 发现了吧，我们在.的前面加上了转义符\，但是并不是代表匹配“.”的意思，而是只匹配“.”的意思！不知道你细不细心，有没有发现我们第一次用.时，后面还跟了一个+？那这个加号是干什么的呢？其实不难想，我们说了“.字符在正则表达式代表着可以代表任何一个字符（包括它本身）”，但是”hello world”可不是一个字符啊。+的作用是将前面一个字符或一个子表达式重复一遍或者多遍。比方说表达式“ab+”那么它能匹配到“abbbbb”，但是不能匹配到”a”，它要求你必须得有个b，多了不限，少了不行。你如果问我有没有那种“有没有都行，有多少都行的表达方式”，回答是有的。*跟在其他符号后面表达可以匹配到它0次或多次比方说我们在王叶内遇到了链接，可能既有http://开头的，又有https://开头的，我们怎么处理？ 123456import rekey = r&quot;http://www.nsfbuhwe.com and https://www.auhfisna.com&quot;#胡编乱造的网址，别在意p1 = r&quot;https*://&quot;#看那个星号！pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;http://&apos;, &apos;https://&apos;] 2.比方说我们有这么一个字符串”cat hat mat qat”，你会发现前面三个是实际的单词，最后那个是我胡编乱造的（上百度查完是昆士兰英语学院的缩写= =）。如果你本来就知道”at”前面是c、h、m其中之一时这才构成单词，你想把这样的匹配出来。根据已经学到的知识是不是会想到写出来三个正则表达式进行匹配？实际上不需要。因为有一种多字符匹方式[]代表匹配里面的字符中的任意一个还是举个栗子，我们发现啊，有的程序员比较过分，，在这对标签上，大小写混用，老害得我们抓不到想要的东西，我们该怎么应对？是写16*16种正则表达式挨个匹配？no 123456import rekey = r&quot;lalala&lt;hTml&gt;hello&lt;/Html&gt;heiheihei&quot;p1 = r&quot;&lt;[Hh][Tt][Mm][Ll]&gt;.+?&lt;/[Hh][Tt][Mm][Ll]&gt;&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;&lt;hTml&gt;hello&lt;/Html&gt;&apos;] 我们既然有了范围性的匹配，自然有范围性的排除。[^]代表除了内部包含的字符以外都能匹配还是cat,hat,mat,qat这个例子，我们想匹配除了qat以外的，那么就应该这么写： 123456import rekey = r&quot;mat cat hat pat&quot;p1 = r&quot;[^p]at&quot;#这代表除了p以外都匹配pattern1 = re.compile(p1)print pattern1.findall(key) 输出为了方便我们写简洁的正则表达式，它本身还提供下面这样的写法 &gt; 正则表达式 代表的匹配字符 [0-9] 0123456789任意之一 [a-z] 小写字母任意之一 [A-Z] 大写字母任意之一 \d 等同于[0-9] \D 等同于[^0-9]匹配非数字 \w 等同于[a-z0-9A-Z_]匹配大小写字母、数字和下划线 \W 等同于[^a-z0-9A-Z_]等同于上一条取非 3.介绍到这里，我们可能已经掌握了大致的正则表达式的构造方式，但是我们常常会在实战中遇到一些匹配的不准确的问题。比方说： 123456import rekey = r&quot;chuxiuhong@hit.edu.cn&quot;p1 = r&quot;@.+\.&quot;#我想匹配到@后面一直到“.”之间的，在这里是hitpattern1 = re.compile(p1)print pattern1.findall(key) 输出结果 1[&apos;@hit.edu.&apos;] 呦呵！你咋能多了呢？我理想的结果是@hit.，你咋还给我加量了呢？这是因为正则表达式默认是“贪婪”的，我们之前讲过，“+”代表是字符重复一次或多次。但是我们没有细说这个多次到底是多少次。所以它会尽可能“贪婪”地多给我们匹配字符，在这个例子里也就是匹配到最后一个“.”。我们怎么解决这种问题呢？只要在“+”后面加一个“？”就好了。 123456import rekey = r&quot;chuxiuhong@hit.edu.cn&quot;p1 = r&quot;@.+?\.&quot;#我想匹配到@后面一直到“.”之间的，在这里是hitpattern1 = re.compile(p1)print pattern1.findall(key) 输出结果 1[&apos;@hit.&apos;] 加了一个“?”我们就将贪婪的“+”改成了懒惰的“+”。这对于[abc]+,\w*之类的同样适用。 小测验：上面那个例子可以不使用懒惰匹配，想一种方法得到同样的结果 个人建议：在你使用”+”,”*”的时候，一定先想好到底是用贪婪型还是懒惰型，尤其是当你用到范围较大的项目上时，因为很有可能它就多匹配字符回来给你！！！ 为了能够准确的控制重复次数，正则表达式还提供{a,b}(代表a&lt;=匹配次数&lt;=b) 还是举个栗子，我们有sas,saas,saaas，我们想要sas和saas，我们怎么处理呢？ 123456import rekey = r&quot;saas and sas and saaas&quot;p1 = r&quot;sa&#123;1,2&#125;s&quot;pattern1 = re.compile(p1)print pattern1.findall(key) 输出 1[&apos;saas&apos;, &apos;sas&apos;] 如果你省略掉{1,2}中的2，那么就代表至少匹配一次，那么就等价于？如果你省略掉{1,2}中的1，那么就代表至多匹配2次。 下面列举一些正则表达式里的元字符及其作用 元字符 说明 . 代表任意字符 逻辑或操作符 [ ] 匹配内部的任一字符或子表达式 [^] 对字符集和取非 - 定义一个区间 \ 对下一字符取非（通常是普通变特殊，特殊变普通） * 匹配前面的字符或者子表达式0次或多次 *? 惰性匹配上一个 + 匹配前一个字符或子表达式一次或多次 +? 惰性匹配上一个 ? 匹配前一个字符或子表达式0次或1次重复 {n} 匹配前一个字符或子表达式 {m,n} 匹配前一个字符或子表达式至少m次至多n次 {n,} 匹配前一个字符或者子表达式至少n次 {n,}? 前一个的惰性匹配 ^ 匹配字符串的开头 \A 匹配字符串开头 $ 匹配字符串结束 [\b] 退格字符 \c 匹配一个控制字符 \d 匹配任意数字 \D 匹配数字以外的字符 \t 匹配制表符 \w 匹配任意数字字母下划线 \W 不匹配数字字母下划线]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python re 正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps-八荣八耻]]></title>
    <url>%2F8r8c.html</url>
    <content type="text"><![CDATA[随着云计算机告诉发展，现在的运维比以前维护起来更加方便了，做的事情也变得和原先运维做的事情不一样了，面临更多新的挑战。云运维，八荣八耻，节省时间和精力，从容应付业务增长，保持稳定的执行效率。 一、以可配置为荣，以硬编码为耻 本地配置,程序⽣生成 (txt/ini/cfg) 集中配置, 动态⽣生成(Yaml/Json) 环境变量量(代码⽆无侵⼊入&amp;语⾔言⽆无关性) 服务⾃自动发现,⾃自动注册(zookeeper/consul) 二、以互备为荣，以单点为耻 互容互备一直是优良架构的设计重点。 使用了LVS+Keeplived+VRRP做转换，这样可以方便负载均衡，动态升级，隔离故障。 Nginx可以加Haproxy或LVS做负载均衡。MySQL可以做主从切换，或者是MMM的高可用成熟解决方案。我们的消息队列之前用rabbitmq做，现在主要是redis和kafka集群化，其中kafka已经迁到了Mesos容器平台里。 服务的自动发现、注册，我们可以使用consul、etcd、doozer（Heroku公司产品），还有zookeeper。主要区别是算法不一样，zookeeper用的是paxos算法，而consul用的是raft算法。目前看来consul比较流行，因为consul的自动发现和自动注册更加容易使用。etcd主要是CoreOS在主推，CoreOS本身就是一个滚动发布的针对分布式部署的操作系统，大家可以去关注一下它。还有一个是hadoop和elk，大数据平台的可扩展性是标配，很容易互备。 三、以随时重启为荣，以不能迁移为耻 四、以整体交付为荣，以部分交付为耻五、以无状态为荣，以有状态为耻 六、以标准化为荣，以特殊化为耻 在标准化方面，我们在这几个方面改良： 1.统一输入输出 统一入口,我们用一个统一的文本，到现在也在用，然后推送到所有的边缘，服务器上面的组件，要用到的参数，都能从配置里读出来。代码管理方面我们也使用git，git wiki，批量部署我们用ansible（早在2012年，我做了一些比较后，就在公司里推行ansible，看来还是很明智的决定）。 2.统一的流程管理 运维中使用python最多，所以我们使用了yaml和playbook。跳板机，通过VPN登陆，目前我们也在试用一个带有审计功能的堡垒机，可以把每个人的操作录制下来，然后再去回放观察，改进我们的工作流程。 七、以自动化工具为荣，以手动+人肉为耻 用的是bash、sed、awk, bat ，python ,ansblie, go 八、以无人值守为荣，以人工介入为耻 运维部门要做的事情有三件： 1.运维自动化 运维平台自动化，django 搭建运维平台，网上特别多的列子，找找，结合自己的业务搭建，省去人工维护。 2.监控要常态 结合云平台监控，结合zabbix, prometheus 3.性能可视化 参考资料: https://blog.csdn.net/u013815546/article/details/61961104]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>八荣八耻 云运维 devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openswan]]></title>
    <url>%2Fopenswan.html</url>
    <content type="text"><![CDATA[安装 openswan 及其环境一、openswan 介绍 OpenSWan是linux选Ipsec及I2tp协议的一个不错的实现方案。他支持和ipsec相关的大多数的扩展（RFC+IETF drafts）。Openswan项目起源于FreeS/WAN 2.04项目，该项目的功能很强大，可以很大程度上保证数据在跨网传输中的安全性、完整性，特别是通过它，可以很好地实现跨机房或异地办公场所实现局域网互联解决方案，如果和openvpn工具配合，可以实现将注入门户网站的多机房互访及vpn的各种强大解决方案. ucloud和公司网络打通,实现内网互通：环境:服务器：(外) 106.75.x.x (内) 10.10.68.61公司:(外) 58.22.x.x（内）192.168.99.168 二、安装 openswan 及其环境(两台都要装)2.1 软件安装Centos:12yum install -y gmp gmp-devel gawk flex bison iproute2 iptables sed awk cut python xmlto lsofyum install -y openswan Ubuntu:12apt-get updateapt-get install -y openswan lsof (ubuntu 会交互安装，第一个询问启用 X.509 证书的时候选择 no，第二个只要点 ok 就可以。) 2.2、开启 linux 主机的路由功能（所有为ipsec vpn server 的主机都要开启）vim /etc/sysctl.conf123## Controls IP packet forwardingnet.ipv4.ip_forward = 1 （开启主机路由转发）12##Controls source route verificationnet.ipv4.conf.default.rp_filter = 0 （关闭源路由验证）修改 /etc/sysctl.conf文件，加入以下内容: 12net.ipv4.ip_forward = 1net.ipv4.conf.default.rp_filter = 0 修改完成后执行 sysctl -p 加载配置。 2.3、在控制台上的防火墙添加 ipsec vpn 所用的端口12云服务商（阿里 腾讯 金山）开放端口 UDP 500 4500两边服务器有限制，iptab 也要开放 2.4 测试udp端口1nc -vuz 58.22.x.x 500 Connection to 58.22.x.x 500 port [udp/isakmp] succeeded! 2.5 验证环境1ipsec verify （一个 N/A 和一个 DISABLED 不影响 ipsec vpn 的建立，Ubuntu 主机可能在checking /bin/sh 会多一个 warning，也不影响。） 123456789101112131415161718192021Verifying installed system and configuration filesVersion check and ipsec on-path [OK]Libreswan 3.15 (netkey) on 2.6.32-754.9.1.el6.x86_64Checking for IPsec support in kernel [OK] NETKEY: Testing XFRM related proc values ICMP default/send_redirects [OK] ICMP default/accept_redirects [OK] XFRM larval drop [OK]Pluto ipsec.conf syntax [OK]Hardware random device [N/A]Two or more interfaces found, checking IP forwarding [OK]Checking rp_filter [OK]Checking that pluto is running [OK] Pluto listening for IKE on udp 500 [OK] Pluto listening for IKE/NAT-T on udp 4500 [OK] Pluto ipsec.secret syntax [OK]Checking &apos;ip&apos; command [OK]Checking &apos;iptables&apos; command [OK]Checking &apos;prelink&apos; command does not interfere with FIPSChecking for obsolete ipsec.conf options [OK]Opportunistic Encryption [DISABLED] 三、配置服务3.1 检测服务正常（所有为 ipsec vpn server 的主机）12345service ipsec startStarting pluto IKE daemon for IPsec: [ OK ]service ipsec statuspluto (pid 1397) is running...IPsec connections: loaded 3, active 1 3.2 配置认证 key（所有为 ipsec vpn server 的主机）vim /etc/ipsec.secrets12345#include /etc/ipsec.d/*.secrets#源IP 目标IP: PSK &quot;(key)&quot; （0.0.0.0 即为所有 vpn 都使用这个 key）0.0.0.0 0.0.0.0 : PSK &quot;boyihuyu.com&quot; （注意空格格式不能错） 3.3 配置VPN主体3.3.1 跨外网云主机间（云主机和其他公司内网 linux 主机）互通192.168.99.168:cat /etc/ipsec.d/boyihuyu.conf12345678910111213141516171819conn BY-to-UC ike=3des-sha1 authby=secret phase2=esp phase2alg=3des-sha1 compress=no type=tunnel pfs=yes leftid=106.75.x.x left=106.75.x.x leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.x.x right=192.168.99.168 rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=start 106.75.x.x:cat /etc/ipsec.d/ucloud.conf 12345678910111213141516171819conn UC-to-BY ike=3des-sha1 authby=secret phase2=esp phase2alg=3des-sha1 compress=no type=tunnel pfs=yes leftid=106.75.x.x left=10.10.68.61 leftsubnet=10.10.0.0/16 leftnexthop=%defaultroute rightid=58.22.x.x. right=58.22.x.x rightsubnet=192.168.0.0/16 rightnexthop=%defaultroute auto=add 对端网络设备（B）配置参数：Peer 的 ip 为云主机的外网 ip 即 A.A.A.A第一阶段选择 ikev1 主模式（main mode），参数为 3des、sha、group2。第二阶段选择模式为 tunnel，参数为 esp、3des、sha。启用 pfs 和 nat-t（nat 穿越）。感兴趣流为 b.b.0.0/16 到 a.a.0.0/16，即用户端网段到云主机网段。 四、测试完成与错误定位4.1 测试12345ipsec auto --up BY-to-UC002 &quot;BY-to-UC&quot; #371: initiating Quick Mode PSK+ENCRYPT+TUNNEL+PFS+UP+IKEV1_ALLOW+IKEV2_ALLOW+SAREF_TRACK+IKE_FRAG_ALLOW &#123;using isakmp#370 msgid:76bf0615 proposal=3DES(3)_000-SHA1(2)_000 pfsgroup=OAKLEY_GROUP_MODP1536&#125;117 &quot;BY-to-UC&quot; #371: STATE_QUICK_I1: initiate002 &quot;BY-to-UC&quot; #371: transition from state STATE_QUICK_I1 to state STATE_QUICK_I2004 &quot;BY-to-UC&quot; #371: STATE_QUICK_I2: sent QI2, IPsec SA established tunnel mode &#123;ESP/NAT=&gt;0x26978c24 &lt;0xdf95b93d xfrm=3DES_0-HMAC_SHA1 NATOA=none NATD=106.75.x.x:4500 DPD=passive&#125; 这个状态即为启动成功，两端可互相 ping 通。1ping 10.10.68.61 4.2 VPN自动启动1chkconfig ipsec on 将/etc/ipsec.conf 文件中的 auto=add 改为 auto=start 4.3 其他主机路由其他云主机如果要通过 ipsec 访问对端要增加相应的路由，或者网关指向本地的 ipsec服务器。 4.4 故障排查 发生no connection named “xxxxx”的报错时基本为配置文件错误或者conn名字错误，检查conn名称、配置文件格式，并查看/var/log/messages中具体错误参数/格式提示。发生第一阶段（STATEMAINI1）或者第二阶段（STATEQUICKI1）初始化超时报错的时候，多为两端参数配置错误导致的协商失败，需要查看/var/log/secure以及对端的日志确定具体哪个参数协商错误。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>vpn openvpn Ipsec OpenSWan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Forefront TMG 2010]]></title>
    <url>%2FForefront-TMG-2010.html</url>
    <content type="text"><![CDATA[一、Forefront TMG 2010 介绍Forefront TMG 是一款全面的安全网关解决方案，可帮助员工抵御来自网络的威胁。通过集成防火墙、VPN、入侵防护、恶意软件检查和 URL 筛选功能，Forefront TMG 还可提供简单且统一的外围安全防护。 二、部署2.1、线上环境外网IP: a.x.x.x内网IP：b.x.x.x操作系统: windows 2008 r2 x64 2.2 安装 TMG注意点： 1、安装过程中会启动防火墙，建议修改远程登入端口。 2、为以防安装过程中登入不上服务器，建议先把服务器密码改的简单点，不行可以通过后台进行登入。后面记得改回来。 3、Windows Event Collector 和 Windows Firewall 服务要改成手动，不然后面服务器重启网卡会起不来，连不上服务器。 2.2.1 打补丁，重启服务器。（比较花时间）2.2.2 添加虚拟网卡ucloud 只有一个内网IP，要做TMG 需要另外在添加一卡虚拟网卡。1) 网络–属性–更多适配器设置 修改网卡名字为inner 2) 控制面板–操作–设备管理器–添加硬件–手动安装–网络设配器–microsoft–microsoft loopback adapter–完成 3) 控制面板–网络和共享中心–更多适配器–找到新的网卡 命名out 设置IP b.x.x.x 千万别重启了 2.2.3 安装下载相关安装包：TMG_CHS_EE_EVAL_amd64.exe运行 TMG_CHS_EE_EVAL_amd64.exe 安装程序默认下一步 选择运行准备工具 选择默认 安装 选择接受 填入单位 定义内部网络选择添加 添加内部网络段 安装过程有点久，可以先做点其他的事情 三、基础配置TMG3.1、网络配置 3.2、配置系统 默认按就好 3.3、自定义部署 选择不更新 3.4、web 访问策略 3.5 新建访问规则（最重要的一部，配置内网可以互通） 3.6 设置内网地址 切记要保存配置并运用，否则系统会进不去，网络连不上。 四、VPN 配置(包含权限控制)4.1、定义地址分配 4.2、启用pptp和l2tp/ipsec 启用VPN 4.3、创建用户和组 先创建组 把用户添加到相应的权限组 4、4 创建子网 4.5 创建用户集 4.6 创建防火墙规则 协议 所有出站通讯从 VPN 客户端到 ucloud_c用户 对应的权限集 基本配置都这样，其他的可以根据这些自行添加]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>TMG vpn windows Forefront TMG 2010</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-ssl]]></title>
    <url>%2Fnginx-ssl.html</url>
    <content type="text"><![CDATA[data:modify by lyc at 2018-05-21参考博文：【Nginx的SSL配置优化】https://www.linpx.com/p/ssl-configuration-optimization.html 一、SSL Labsssllabs：查看https网站的安全级别： https://www.ssllabs.com/ssltest/index.html 未加入ssl优化配置的安全级别F 配置了ssl优化参数的安全级别A+ 二、创建dhparam nginx.pem秘钥 一般网站使用的SSL证书都是RSA证书，这种证书基本都是2048位的密钥，但是证书密钥交换密钥必须要比证书密钥更长才能安全。 而默认的创建dhparam.pem只有1024位，所以我们需要手动生成一个更强的密钥4096位。 1234# 执行时间很长，建议使用screen生成mkdir -p /usr/local/nginx/ssl-key/dh_sslcd /usr/local/nginx/ssl-key/dh_sslopenssl dhparam -out nginx.pem 4096 三、ssl配置及优化配置如下，只包含ssl部分的配置，未包含其他比较重要的配置，如缓存、跳转、防盗链和强制HTTPS等等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162upstream www.test.com_ssl &#123; server 127.0.0.1 weight=20 max_fails=2 fail_timeout=8s;&#125;server&#123; listen 443 ssl; server_name www.test.com; # SSL base ssl on; ssl_certificate /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.crt; ssl_certificate_key /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.key; ssl_dhparam /usr/local/nginx/ssl-key/dh_ssl/nginx.pem; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets on; # SSL ciphers ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers &apos;ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS&apos;; ssl_prefer_server_ciphers on; # OCSP Stapling #ssl_trusted_certificate /usr/local/nginx/ssl-key/GlobalSign/chain.pem; #ssl_stapling on; #ssl_stapling_verify on; #resolver 8.8.8.8 8.8.4.4 valid=300s; #resolver 119.29.29.29 223.5.5.5 valid=300s; #resolver_timeout 5s; # HSTS add_header Strict-Transport-Security max-age=15768000; #add_header X-Frame-Options DENY; #add_header X-Content-Type-Options nosniff; location / &#123; proxy_redirect off; proxy_pass http://www.test.com_ssl; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream timeout invalid_header http_500 http_502 http_503 http_504; # http_404; &#125; client_max_body_size 100m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_read_timeout 90; proxy_send_timeout 90; proxy_buffer_size 64k; proxy_buffers 32 32k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 64k; large_client_header_buffers 4 16k; error_log /data/httplogs/www.test.com-ssl-error.log; access_log /data/httplogs/www.test.com-ssl-access.log weblog;&#125; 配置解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364server &#123; listen 443 ssl; # listen 443 ssl http2; # 使用HTTP/2，需要Nginx1.9.7以上版本 server_name www.test.com; # SSL base ssl基础配置区块，SSL证书文件位置 ssl on; ssl_certificate /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.crt; # https证书，其实是个公钥，它会被发送到连接服务器的每个客户端 ssl_certificate_key /usr/local/nginx/ssl-key/STAR.test.com/STAR.test.com.key; # 证书私钥是用来解密的，所以它的权限要得到保护。让nginx的主进程能够读取。当然私钥和证书可以放在一个证书文件中，这种方式也只有公钥证书才发送到client # SSL ciphers 加密算法及交换秘钥配置区块 ssl_dhparam /usr/local/nginx/ssl-key/dh_ssl/nginx.pem; # DH-Key交换密钥文件位置 ssl_ciphers &apos;ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS&apos;; # 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher &apos;RC4:HIGH:!aNULL:!MD5&apos;（后面是你所指定的套件加密算法） 来看所支持算法。 ssl_prefer_server_ciphers on; #由服务器协商最佳的加密算法 # OCSP Stapling OCSP配置区块 ssl_trusted_certificate /usr/local/nginx/ssl-key/GlobalSign/chain.pem; # OCSP Stapling的证书位置 ssl_stapling on; # OCSP Stapling开启,OCSP是用于在线查询证书吊销情况的服务，使用OCSP Stapling能将证书有效状态的信息缓存到服务器，提高TLS握手速度 ssl_stapling_verify on; # OCSP Stapling验证开启 #resolver 8.8.8.8 8.8.4.4 valid=300s; # 海外dns（美国） resolver 119.29.29.29 223.5.5.5 valid=300s; # 国内dns（腾讯和阿里） # 用于查询OCSP服务器的DNS resolver_timeout 5s; # 查询域名超时时间 # HSTS 配置区块 add_header Strict-Transport-Security max-age=10886400; # 开启HSTS，并设置有效期为“10886400秒”（最低不低于18周） # add_header Strict-Transport-Security &quot;max-age=6307200; includeSubdomains; preload&quot;; #开启HSTS，并设置有效期为“6307200秒”（6个月），包括子域名(根据情况可删掉)，预加载到浏览器缓存(根据情况可删掉) add_header X-Frame-Options DENY; # 禁止被嵌入框架 add_header X-Content-Type-Options nosniff; # 防止在IE9、Chrome和Safari中的MIME类型混淆攻击 # SSL optimize ssl优化配置区块 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 指令用于启动特定的加密协议，nginx在1.1.13和1.0.12版本后默认是ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2，TLSv1.1与TLSv1.2要确保OpenSSL &gt;= 1.0.1 ，SSLv3 现在还有很多地方在用但有不少被攻击的漏洞。 ssl_session_cache shared:SSL:50m; # Session Cache，将Session缓存到服务器，这可能会占用更多的服务器资源 # ssl_session_cache builtin:1000 shared:SSL:10m; # 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 ssl_session_tickets on; # 开启浏览器的Session Ticket缓存 ssl_session_timeout 1d; # SSL session过期时间，系统默认5分钟太短了，可以设成30m即30分钟甚至4h……&#125; ssl_ciphers加密套件配置ssl_ciphers加密套件配置可以直接通过这个链接来查看。https://mozilla.github.io/server-side-tls/ssl-config-generator/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>nginx ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-rewrite]]></title>
    <url>%2Fnginx-rewrite.html</url>
    <content type="text"><![CDATA[date:modify by lyc at 2017-11-21http://www.cnblogs.com/kevingrace/p/6398488.htmldate:modify by lyc at 2018-05-15 一、nginx rewrite规则1.rewrite语法 nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断，但不支持else。 该模块需要PCRE支持，因此应在编译nginx时指定PCRE源码目录, nginx安装方法。 12345678910rewrite regex replacement [flag]关键字 正则表达式 替换值 标志位例子：rewrite ^/(.*) http://www.etiantian.org/$1 permanent;解释：^/(.*) 表示匹配所有$1 取前面regex部分括号里的内容permanent 永久301重定向，即跳转到后面的http://www.etiantian.org/$1地址上 2.rewrite flags标记位 flag description last 本条规则匹配完成后，继续向下匹配新的location URL规则。（基本上都用这个Flag，表示rewrite。） break 本条规则匹配完成即终止，不在匹配后面的任何规则 redirect 返回302临时重定向，浏览器地址栏会显示跳转后的URL地址 permanent 返回301永久重定向，浏览器地址栏会显示跳转后的URL地址。原有的url支持正则，重写的url不支持正则 3.正则表达式匹配规则 ~ 为区分大小写匹配 ~* 为不区分大小写匹配 !~和!~* 分别为区分大小写不匹配及不区分大小写不匹配 4.文件及目录匹配 -f 和!-f 用来判断是否存在文件 -d 和!-d 用来判断是否存在目录 -e 和!-e 用来判断是否存在文件或目录 -x 和!-x 用来判断文件是否可执行 5.rewrite指令优先级rewrite可配置区块：rewrite一般配置在server全局区块，也经常搭配if条件区块来使用： server区块：配置在server区块的rewrite可以说是全局的，所有请求优先匹配该区块的rewrite指令。 if区块：通过正则或条件匹配，将命中的请求进行重写，再去匹配接下去的location进行处理请求。配置在if区块的目的就是更好的让下面的location命中，然后去处理请求。 location区块：可以配置在location区块，但没有多大意义，已经被location命中的请求一般直接进行处理了，再重写没意义。 rewrite指令优先级 执行server块的rewrite指令(这里的块指的是server关键字后{ }包围的区域，其它xx块类似) 执行if区块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步uri被重写，则重新循环执行1-3，直到找到真实存在的文件 如果循环超过10次，则返回500 Internal Server Error错误 通过配置break来停止 注意：在location里面的rewrite指令，应使用break而不是last , 使用last将循环10次匹配，然后返回500错误。 二、if指令规则不支持else，rewrite常搭配if条件语句来执行： 1.if指令语法123456# 语法：if (condition) &#123;...&#125; 默认值：无 作用域：server,location 对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。 2.if指令条件if条件(conditon)可以是如下任何内容: 12345671）一个变量名 false如果这个变量是空字符串或者以0开始的字符串；2）使用= != 比较的一个变量和字符串3）是用~ ~* 与正则表达式匹配的变量，如果这个正则表达式中包含&#125;，;则整个表达式需要用&quot; 或&apos; 包围4）使用-f !-f 检查一个文件是否存在5）使用-d !-d 检查一个目录是否存在6）使用-e !-e 检查一个文件、目录、符号链接是否存在7）使用-x !-x 检查一个文件是否可执行 3.if指令实例123456if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break; &#125; if ($request_method = POST) &#123; return 405; &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>nginx rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-tcp]]></title>
    <url>%2Fnginx-tcp.html</url>
    <content type="text"><![CDATA[wriren by: CQhttps://www.920430.comwriren time: 2017-7-4 15:52:2 Nginx TCP AND UDP LOAD BALANCER参考文档官方文档 1: ngx_stream_proxy_module 官方文档 2: tcp-load-balancing Nginx的TCP负载均衡介绍 nginx-database-load-balancer-mysql-or-mariadb-galera-cluster 前言Nginx从Nginx Plus(商业授权版) 1.7.7 开始支持 TCP和UDP的负载均衡;Nginx开源版本从1.9.0起开始支持TCP的负载均衡，从1.9.13版本开始支持UDP和UNIX-domain sockets。 Nginx开源版本默认没有开启TCP负载均衡，开启需要在编译构建的时候新增–with-stream 参数，而Nginx Plus则默认就已经开启不需要额外参数。 下面是几个简单的Nginx配置(Example Configuration) TCP server { listen 127.0.0.1:12345; proxy_pass 127.0.0.1:8080; } server { listen 12345; proxy_connect_timeout 1s; proxy_timeout 1m; proxy_pass example.com:12345; } UDP server { listen 53 udp; proxy_responses 1; proxy_timeout 20s; proxy_pass dns.example.com:53; } UNIX-domain sockets server { listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; } Nginx TCP负载均衡算法与Nginx http负载均衡一样，Nginx TCP负载均衡也支持如下负载均衡算法： Round Robin: 对所有的backend轮询发送请求，算是最简单的方式了，也是默认的分配方式；例如： upstream stream_backend { server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; ... } Least Connections(least_conn): 跟踪和backend当前的活跃连接数目，最少的连接数目说明这个backend负载最轻，将请求分配给他，这种方式会考虑到配置中给每个upstream分配的weight权重信息；例如： upstream dns_servers { least_conn; server 192.168.136.130:53; server 192.168.136.131:53; ... } Least Time(least_time): 请求会分配给响应最快和活跃连接数最少的backend；(该算法目前仅在Nginx Plus上支持)；例如： upstream stream_backend { least_time first_byte; server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; } Hash(hash key): client-server基于hash key计算hash值后,根据得到的hash值通过某种映射分配到backend。key值可以包括text, variables。例如： upstream stream_backend { hash $remote_addr; server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; } Nginx TCP健康检查开源版本的Nginx软件可以对上游服务器(upstream servers)的响应执行基本检查，尽可能重试失败的请求（也称为Passive Health Checks）。 NGINX Plus则额外增加了对外部应用程序运行状况检查（也称为Active Health Checks）和检查缓慢启动功能(slow‑start)，可以对负载平衡组中新增和恢复的服务器正常添加。 Passive Health Checks:Passive Health Checks (被动健康检查)意味着NGINX或NGINX Plus会监控服务通信是否可用，如果不可用，NGINX将尝试恢复。如果仍然无法恢复，NGINX会考虑该服务不可用，并暂时停止向该服务器发送请求，直到被再次被视为活动。 Nginx和Nginx Plus都支持下面指令，来判断服务是否不可用： fail_timeout - 设置考虑服务器不可用的多次失败尝试的时间，以及服务器不可用的时间（默认为10秒）。 max_fails - 在fail_timeout时间内设置失败尝试次数，以考虑服务器不可用（默认为1连接）尝试。 例1 该示例显示，如果NGINX无法向某个服务器发送请求或至少三次未收到此服务器的响应，则立即认为该服务器不可用30秒： upstream backend { server backend1.example.com; server backend2.example.com max_fails=3 fail_timeout=30s; } 例2 在该例显示，假设有7个连接，那么有5个连接将转到backend1.example.com:12345(因为权重为5，weight=5)，剩下的连接到第二和第三个服务器。如果在与服务器通信期间发生错误，则连接将被传递到下一个服务器，依此类推，直到所有正在运行的服务器都将被尝试。 如果与所有服务器的通信失败，则连接将关闭。 upstream backend { server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend2; server backend3.example.com:12345 resolve; server backup1.example.com:12345 backup; } Active Health ChecksNGINX Plus可以通过使用health_check指令包含在位置块中来配置最简单的运行状况检查。，并检查响应。 例1 以下示例 - 向每个服务发送带自定义的TCP请求。 返回良好的200的服务器被认为是健康的; 否则它们被标记为失败。 stream { ... upstream stream_backend { zone upstream_backend 64k; server backend1.example.com:12345; } match http { send &quot;GET / HTTP/1.0\r\nHost: localhost\r\n\r\n&quot;; expect ~* &quot;200 OK&quot;; } server { listen 12345; health_check match=http; proxy_pass stream_backend; } } 更多health-check参考资料http-health-check tcp-health-check 简单测试都在一个机器上， Nginx监听30003端口，然后开两个窗口，用nc监听 7773，7774端口。思路如下： / nc -l 7773 telnet--&gt; Nginx(30003) --&gt; \ nc -l 7774 使用nc监听端口 $ nc -l 7773 $ nc -l 7774 Nginx配置 stream { upstream backend { server 127.0.0.1:7773; server 127.0.0.1:7774; } server { listen 127.0.0.1:30003; proxy_timeout 20s; proxy_pass backend; } } 测试 $ telnet 127.0.0.1 30003 第一次访问会代理到 7773端口，第二次访问会到7774端口。 线上配置文件stream { upstream stream_backend { least_conn; server 127.0.0.1:8801 max_fails=2 fail_timeout=30s; server 127.0.0.1:8802 max_fails=2 fail_timeout=30s; server 127.0.0.1:8803 max_fails=2 fail_timeout=30s; } server { listen 8800; proxy_timeout 10m; proxy_connect_timeout 60; proxy_pass stream_backend; } } PS： 如果upstream组中只有一个服务器，max_fails，fail_timeout和slow_start参数都将被忽略，并且这样的服务器将永远不会被视为不可用。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>nginx tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-install]]></title>
    <url>%2Fnginx-install.html</url>
    <content type="text"><![CDATA[wriren by: CQhttps://www.920430.comwriren time: 2017-7-4 15:52:2 Building nginx from Sources http://nginx.org/en/docs/configure.html 下载对应版本的源码包。 $ cd /usr/local/src $ sudo wget http://nginx.org/download/nginx-1.12.0.tar.gz $ sudo wget https://ftp.pcre.org/pub/pcre/pcre-8.40.tar.gz $ sudo wget http://zlib.net/zlib-1.2.11.tar.gz 同级目录解压。 $ sudo tar xf nginx-1.12.0.tar.gz $ sudo tar xf pcre-8.40.tar.gz $ sudo tar xf zlib-1.2.11.tar.gz 安装相关的编译依赖包 $ sudo apt-get -y install autoconf automake build-essential pkg-config \ libperl-dev libxml2 libxslt1-dev libgeoip-dev zlib1g-dev 创建nginx用户,并禁止其登陆 $ sudo useradd -s /sbin/nologin nginx 编译安装 $ sudo cd /usr/local/src/nginx-1.12.0 $ sudo ./configure --user=nginx --group=nginx \ --prefix=/usr/local/nginx-1.12.0 \ --conf-path=/usr/local/nginx-1.12.0/conf/nginx.conf \ --pid-path=/var/log/nginx/nginx.pid \ --with-pcre=../pcre-8.40 \ --with-zlib=../zlib-1.2.11 \ --with-stream \ --with-stream_ssl_module \ --with-http_ssl_module \ --with-http_v2_module \ --with-http_geoip_module \ --with-http_realip_module \ --with-http_xslt_module \ --with-file-aio \ --with-http_perl_module \ --with-http_auth_request_module \ --with-http_gzip_static_module \ --with-http_secure_link_module \ --with-http_sub_module \ --with-http_stub_status_module $ sudo make &amp;&amp; make install $ sudo ln -s /usr/local/nginx-1.12.0 /usr/local/nginx 调整配置文件 $ sudo vim /usr/local/nginx/conf/nginx.conf user nginx nginx; worker_processes auto; ## Binds worker processes to the sets of CPUs. ## Each CPU set is represented by a bitmask of allowed CPUs. There should be a separate set defined for each of the worker processes. ## By default, worker processes are not bound to any specific CPUs. worker_cpu_affinity auto; error_log /var/log/nginx/error.log notice; pid /var/log/nginx/nginx.pid; ## Specifies the value for maximum file descriptors that can be opened by this process. worker_rlimit_nofile 51200; events { use epoll; ## Sets the maximum number of simultaneous connections that can be opened by a worker process. ## It should be kept in mind that this number includes all connections (e.g. connections with proxied servers, among others), not only connections with clients. Another consideration is that the actual number of simultaneous connections cannot exceed the current limit on the maximum number of open files, which can be changed by worker_rlimit_nofile. ## maxclient = worker_processes * worker_connections / cpu_number worker_connections 30000; } http { include mime.types; default_type application/octet-stream; log_format weblog &apos;$http_x_forwarded_for $remote_port &quot;$request&quot; $status [$time_local] &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_referer&quot; $body_bytes_sent &apos; &apos;$remote_addr $gzip_ratio&apos;; sendfile on; server_tokens off; tcp_nopush on; tcp_nodelay on; keepalive_timeout 60; request_pool_size 4k; ## Allows accurate tuning of per-connection memory allocations. ## This directive has minimal impact on performance and should not generally be used. ## By default, the size is equal to 256 bytes on 32-bit platforms and 512 bytes on 64-bit platforms. connection_pool_size 512; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 256k; large_client_header_buffers 4 1024k; client_max_body_size 10m; client_body_buffer_size 256k; output_buffers 4 32k; postpone_output 1460; server_names_hash_bucket_size 128; fastcgi_connect_timeout 180s; fastcgi_send_timeout 180s; fastcgi_read_timeout 180s; fastcgi_buffer_size 2048k; fastcgi_buffers 4 1024k; fastcgi_busy_buffers_size 2048k; fastcgi_temp_file_write_size 2048k; gzip on; gzip_http_version 1.1; gzip_comp_level 2; gzip_min_length 1100; gzip_buffers 16 8k; gzip_vary on; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain text/css application/json text/xml application/xml application/xml+rss text/javascript application/javascript application/x-javascript; ## The following includes are specified for virtual hosts include vhosts/*.conf; } server { listen 443 ssl default; # server_name silent.live www.silent.live blog.silent.live devops.silent.live; server_name silent.live www.silent.live; root /data/wwwroot/silent.live/webroot; index index.shtml index.html; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate /etc/letsencrypt/live/silent.live/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/silent.live/privkey.pem; ## Specifies that server ciphers should be preferred over client ciphers when the SSLv3 and TLS protocols are used. ssl_prefer_server_ciphers on; # ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH&quot;; ssl_ciphers &apos;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&apos;; ## Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits ssl_dhparam /usr/local/nginx/sslkey/dh_ssl/nginx_dh_2048.pem; ## The special value auto (1.11.0) instructs nginx to use a list built into the OpenSSL library when using OpenSSL 1.0.2 or higher, or prime256v1 with older versions. ## Prior to version 1.11.0, the prime256v1 curve was used by default. ssl_ecdh_curve auto; ## This will create a cache shared between all worker processes. ## The cache size is specified in bytes (in this example: 50 MB). ## According to the Nginx documentation can 1MB store about 4000 sessions, so for this example, we can store about 200000 sessions, and we will store them for 180 minutes. ## If you expect more traffic, increase the cache size accordingly. ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ## Requires nginx &gt;= 1.5.9 ssl_session_tickets off; # ssl_session_ticket_key /usr/local/nginx/sslkey/tls_session/tls_session_ticket.key; ## OCSP Stapling, Requires nginx &gt;= 1.3.7 ssl_stapling on; ssl_stapling_verify on; ## verify chain of trust of OCSP response using Root CA and Intermediate certs. # ssl_trusted_certificate /path/to/signed_cert_plus_intermediates; resolver 8.8.8.8 8.8.4.4 valid=300s; resolver_timeout 5s; ssi on; ssi_silent_errors off; ssi_types text/shtml; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; access_log off; } location = /favicon.ico { rewrite (.*) /static/favicon.ico; } # location = /robots.txt { # rewrite (.*) /static/robots.txt; # } location / { add_header Cache-Control no-cache; ## HSTS # add_header Strict-Transport-Security &quot;max-age=63072000; includeSubDomains; preload&quot;; add_header Strict-Transport-Security &quot;max-age=63072000&quot;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; } error_page 404 /static/404.html; access_log /data/httplog/silent.live_access_ssl.log weblog; error_log /data/httplog/silent.live_error_ssl.log; }]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>nginx install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-install]]></title>
    <url>%2Fjenkins-install.html</url>
    <content type="text"><![CDATA[Installing Jenkins wriren by: CQhttps://www.920430.comwriren time: 2017-7-4 15:52:2 PrefaceJenkins是一个用Java编写的开源的持续集成工具。在与Oracle发生争执后，项目从Hudson项目复刻。 Jenkins提供了软件开发的持续集成服务。它运行在Servlet容器中（例如Apache Tomcat）。 它支持软件配置管理（SCM）工具（包括AccuRev SCM、CVS、Subversion、Git、Perforce、Clearcase和RTC），可以执行基于Apache Ant和Apache Maven的项目，以及任意的Shell脚本和Windows批处理命令。Jenkins的主要开发者是川口耕介。Jenkins是在MIT许可证下发布的自由软件。 System requirement尽量使用Java 8, 还建议使用512MB以上RAM的系统。 Begin InstallJenkins 提供了多种安装方式。 Installing Jenkins with Docker 假设你已经安装好docker,那么你可以直接执行： $ sudo docker pull jenkins $ sudo docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins 这将把jenkins数据存储在主机/your/home上，因此请确保/your/home目录能够被容器中的jenkins用户访问（jenkins user - uid 1000）或在执行docker run时使用-u some_other_user参数。 您可能需要自定义运行Jenkins的JVM，通常是传递系统属性或调整堆内存设置。为此使用JAVA_OPTS环境变量： 例如: 下面为修改JVM默认的时区，则可以这样运行： $ sudo docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=-Duser.timezone=GMT jenkins or $ sudo docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=-Duser.timezone=&quot;Australia/Sydney&quot; jenkins 更多详情可以参考： https://hub.docker.com/r/library/jenkins https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+with+Docker Installing Jenkins on Ubuntu Installation $ wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add - $ sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos; $ sudo apt-get update $ sudo apt-get install jenkins Upgrade 一旦这样安装，您可以通过运行以下命令来更新到更高版本的Jenkins（当它出来时）： $ sudo apt-get update $ sudo apt-get install jenkins （aptitude或apt-get没有任何区别。） What does this package do? 开始时，jenkins将作为一个守护进程启动。更多详情请查看/etc/init.d/jenkins。 创建“jenkins“用户以运行此服务。 日志文件将被放入/var/log/jenkins/jenkins.log。如果您正在对Jenkins进行故障排除，请检查此文件。 /etc/default/jenkins 将预先配置参数，例如JENKINS_HOME。 如果您的服务器8080端口已经被占用，请编辑/etc/default/jenkins以替换该行 HTTP_PORT = 8080 默认情况下，Jenkins监听端口8080.使用浏览器访问此端口以开始配置。 更多详情可以参考：&lt;https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Ubuntu&gt; Installing Jenkins on Red Hat distributions RedHat和CentOS 在安装方式上区别并不大，这里以RedHat为例 Installation 将Jenkins源添加到yum repos，并且开始安装 $ sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo $ sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key $ sudo yum install jenkins Installation of a stable version(可选) 以上述方法安装的Jenkins默认是最新版，如果需要安装LTS版本(长期支持版)，则可以： $ sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo $ sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key $ sudo yum install jenkins Installation of Java Jenkins需要Java才能运行，但默认情况下，某些发行版不包括此类。要安装Open Java Development Kit（OpenJDK），请运行以下操作： $ sudo yum install java PS: 尽量安装Java 8,RedHat系列自带的JDK 基本都是java 7. What does this package do? 开始时，jenkins将作为一个守护进程启动。更多详情请查看/etc/init.d/jenkins。 创建“jenkins“用户以运行此服务,如果您通过配置文件将其更改为其他用户，则必须更改/var/ log/jenkins，/var/lib/jenkins和/var/cache/jenkins的所有者。 日志文件将被放入/var/log/jenkins/jenkins.log。如果您正在对Jenkins进行故障排除，请检查此文件。 /etc/sysconfig/jenkins 将预先配置参数 默认情况下，Jenkins监听端口8080.使用浏览器访问此端口以开始配置。请注意，内置防火墙可能需要打开才能从其他计算机访问此端口 添加了Jenkins RPM源: /etc/yum.repos.d/jenkins.repo 更多详情可以参考：https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Red+Hat+distributions Installing Jenkins on any system 经常看到有教程是这么写的： Tomcat + Jenkins,其实jenkins再带jetty，那么最简单的方式应该是 $ wet http://mirrors.jenkins.io/war-stable/latest/jenkins.war $ sudo java -jar jenkins.war 上述无论是docker安装 ，rpm安装，deb安装，还是Tomcat + Jenkins 都是对其的封装和润色。 Reference官方文档 | https://jenkins.io/doc/ 官方下载地址 | https://jenkins.io/download/ Jenkins Wiki | https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins 维基百科 | https://zh.wikipedia.org/wiki/Jenkins_(%E8%BD%AF%E4%BB%B6)]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka-REST-Proxy]]></title>
    <url>%2Fkafka-REST-Proxy.html</url>
    <content type="text"><![CDATA[Kafka REST Proxy 2018-0810 一、业务场景需求 某公司A，需要把游戏日志传给另外一家公司B。架构大致是，游戏服务器把日志传到kafka消息队列，kafka在到es进行数据分析。由于服务器是公司B自己提供，公司A就需要提供一个外网接口让对方把数据写到云ukafka。 由于ukafka只有内网IP，zookeeper中只能注册一个地址，通过nginx代理或者ssh端口转发都不能做到外网正常使用，除非节点本身有外网IP。这个时候就需要用到Kafka REST Proxy。 二、Kafka REST Proxy 介绍 Kafka REST代理为Kafka集群提供RESTful接口。它可以轻松生成和使用消息，查看集群状态，以及在不使用本机Kafka协议或客户端的情况下执行管理操作。用例示例包括从任何语言构建的任何前端应用程序向Kafka报告数据，将消息提取到尚不支持Kafka的流处理框架，以及脚本管理操作。 kafka rest proxy 是rest api接口，通过这个代理把数据转发到kafka的。主要有两部分组成 - Schema Registry提供元数据的存储和解析。 - Producer的序列化和Consumer的反序列化都会去Schema Registry读取对应的Schema 通过Kafka REST Proxy API接口做代理，把外网传输数据转发到内网kafka中。 相关资料1 https://github.com/confluentinc/kafka-rest相关资料2 https://docs.confluent.io/current/kafka-rest/docs/index.html 三、安装1、安装jdk1.8 以上 下载JDK12cd /usr/local/src/kafkawget -c http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm?AuthParam=1493105955_1f866324e85307d5f9b495e276577b05 安装JDK1234567891011121314# 检查jdk 是否安装rpm -qa | grep jdk# 安装jdkcd /usr/local/src/kafkarpm -ivh jdk-8u131-linux-x64.rpm# 设置环境cat &gt;&gt; /etc/profile&lt;&lt;&quot;EOF&quot;export JAVA_HOME=/usr/java/jdk1.8.0_131export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATHEOF# 加载环境变量. /etc/profile 2、添加相关源 vim /etc/yum.repos.d/confluent.repo12345678910111213[Confluent.dist]name=Confluent repository (dist)baseurl=http://packages.confluent.io/rpm/3.1/6gpgcheck=1gpgkey=http://packages.confluent.io/rpm/3.1/archive.keyenabled=1[Confluent]name=Confluent repositorybaseurl=http://packages.confluent.io/rpm/3.1gpgcheck=1gpgkey=http://packages.confluent.io/rpm/3.1/archive.keyenabled=1 3、安装1yum install confluent-kafka-rest confluent-schema-registry -y 4、修改confluent-schema-registry 配置 vim /etc/schema-registry/schema-registry.properties1234listeners=http://0.0.0.0:8080 ## 提供给kafka-rest 连接的端口kafkastore.connection.url=10.10.41.3x:2181,10.10.187.3x:2181,10.10.87.5x:2181 ## 实际kafka的zookeeperkafkastore.topic=_schemasdebug=false 启动1schema-registry-start /etc/schema-registry/schema-registry.properties 5、修改confluent-kafka-rest配置 vim /etc/kafka-rest/kafka-rest.properties12345#id=kafka-rest-test-server#port=9092 ## 自定义端口 默认 8082schema.registry.url=http://localhost:8080 ## 上面schema 端口zookeeper.connect=10.10.41.3x:2181,10.10.187.3x:2181,10.10.87.5x:2181## 实际kafka的zookeeper 启动1kafka-rest-start /etc/kafka-rest/kafka-rest.properties 测试 发送消息123curl -X POST -H &quot;Content-Type: application/vnd.kafka.json.v1+json&quot; --data &apos;&#123;&quot;records&quot;:[&#123;&quot;value&quot;:&#123;&quot;foo&quot;:&quot;bar2&quot;&#125;&#125;]&#125;&apos; &quot;http://x.x.x.x:8082/topics/opstest&quot; # 正常返回结果&#123;&quot;offsets&quot;:[&#123;&quot;partition&quot;:0,&quot;offset&quot;:5,&quot;error_code&quot;:null,&quot;error&quot;:null&#125;],&quot;key_schema_id&quot;:null,&quot;value_schema_id&quot;:null&#125; 接收消息1234./kafka-console-consumer.sh --zookeeper 10.10.x.x:2181 --from-beginning --topic opstest# 结果&#123;&quot;foo&quot;:&quot;bar&quot;&#125;&#123;&quot;foo&quot;:&quot;bar2&quot;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Kafka REST Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka-install]]></title>
    <url>%2Fkafka-install.html</url>
    <content type="text"><![CDATA[系统更新123sudo add-apt-repository ppa:openjdk-r/ppasudo apt-get update sudo apt-get install openjdk-8-jdk 安装 zookeeper1234567wget http://apache.fayea.com/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar xf zookeeper-3.4.10.tar.gz -C /usr/localcd /usr/local/zookeeper-3.4.10/confcp -pv zoo_sample.cfg zoo.cfgvim /usr/local/zookeeper/conf/zoo.cfgmkdir -p /data/zookeeper 安装 kafka1234567wget http://www-eu.apache.org/dist/kafka/0.10.2.1/kafka_2.12-0.10.2.1.tgztar xf kafka_2.12-0.10.2.1.tgz -C /usr/localcd /usr/local &amp;&amp; ln -s kafka_2.12-0.10.2.1 kafkavim /usr/local/kafka/config/server.propertiesnohup bin/kafka-server-start.sh config/server.properties &amp; 安装 supervisor 守护进程12345678910python get-pip.py pip install setuptoolspip install -U setuptoolspip install supervisorecho_supervisord_conf &gt; /etc/supervisord.confmkdir /etc/supervisorsed -i &apos;s#\;\[include\]#\[include\]#&apos; /etc/supervisord.confsed -i &apos;/relative\/directory/a\files = /etc/supervisor/*.ini&apos; /etc/supervisord.confmkdir /data/httplogssupervisord -c /etc/supervisord.conf kafka 启动12./kafka-console-producer.sh --broker-list 10.10.32.92:9092 --topic log./kafka-topics.sh --create --zookeeper 10.10.32.92:2181 --replication-factor 1 --partitions 1 --topic log swap 关闭123echo &quot;vm.swappiness = 1&quot; &gt;&gt; /etc/sysctl.confsysctl vm.swappiness=1swapoff -a &amp;&amp; swapon -a 安装 elasticsearch123456789wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpecho &quot;deb https://artifacts.elastic.co/packages/5.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-5.x.listsudo apt-get update &amp;&amp; sudo apt-get install elasticsearchcp -pv /etc/elasticsearch/elasticsearch.yml&#123;,.default&#125;vim /etc/elasticsearch/elasticsearch.ymlmkdir -m 755 -p /data/elasticsearch/&#123;elasticsearch_logs,elasticsearch_data&#125;chown -R elasticsearch:elasticsearch /data/elasticsearch/etc/init.d/elasticsearch start 安装 node12345wget https://nodejs.org/dist/v6.11.2/node-v6.11.2-linux-x64.tar.xztar xvf node-v6.11.2-linux-x64.tar.xz mv node-v6.11.2-linux-x64 /usr/local/cd /usr/local/ &amp;&amp; ln -s node-v6.11.2-linux-x64/ nodechown root:root -R node-v6.11.2-linux-x64/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>kafka install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS-Certbot]]></title>
    <url>%2FHTTPS-Certbot.html</url>
    <content type="text"><![CDATA[HTTPS-使用Certbot自动配置Let’s Encrypt证书1. HTTPS基本介绍 现在各大厂商都在推行HTTPS，比如谷歌要求多个顶级域名要用HTTPS来加密，苹果要求开发者全部采用HTTPS等等。那什么是HTTPS呢？其实HTTPS只是HTTP的一个拓展，是在HTTP的基础上利用SSL/TLS来加密数据包的。工作流程如下： An overview of the SSL or TLS handshake 图片来自IBM Knowledge Center: An overview of the SSL or TLS handshakehttps://www.ibm.com/support/knowledgecenter/en/SSFKSJ_7.1.0/com.ibm.mq.doc/sy10660_.htm 注意第(2)步Server给Client发送了一个Server certificates，这个里面包含有Server的一些信息，如域名、公司信息、序列号和签名信息组成等，这个证书可以个人生成，也可以由权威机构签发，当然个人的就不受大众信任，而权威机构签发的证书则会被信任。 具体的可以参考：细说 CA 和证书https://www.barretlee.com/blog/2016/04/24/detail-about-ca-and-certs/ 2. Let’s Encrypt CA的证书提供商有许多个，有收费的有免费的，而Let’s Encrypt就是其中之一的免费提供商。https://letsencrypt.org/ 2.1 如何获取Let’s Encript的证书呢？ 要从Let’s Encript获取某个域名的证书，需要证明那你对该域名拥有控制权，对于该证明你可以使用某个使用ACME协议的软件来实现，而Certbot就是官方出的一个ACME客户端。 3. Certbot介绍 先介绍一些Certbot相关概念。 3.1 Authenticators和Installers Certbot支持两种类型的plugin，一种是用来获取和安装证书的，成为称为Authenticators；另外一种是用来安装证书的，称为Installers。有的plugin支持一种，有的两种都支持，如nginx。 安装证书：自动修改配置文件，如修改nginx的某个.conf文件 Authenticators plugin使用certonly命令来获取证书，而Installers plugin使用install命令来安装证书。 3.2 plugin说明 下面列举几个常用的plugin作简要说明： Webroot：本地有运行webserver并且有能力修改其配置，就可以用该种方式（创建隐藏文件.well-known），获取证书时无需暂停webserver的运行。 Standalone：服务器未运行webserver可以使用该方式，要保持80或443端口开放。 Nginx：自动获取和安装证书（自动修改配置文件）。 3.3 Certbot使用流程 Certbot的使用包含以下几个部分： 安装Certbot 生成证书 配置Web Server 更新证书 3.4 Certbot安装 安装Certbot参考：Certbot，直接选择软件和操作系统即可。 https://certbot.eff.org/lets-encrypt/centosrhel7-apache centos 61234wget https://dl.eff.org/certbot-autosudo mv certbot-auto /usr/local/bin/certbotsudo chown root /usr/local/bin/certbotsudo chmod 0755 /usr/local/bin/certbot centos 71yum install python2-certbot-nginx 3.4 获取证书 对于nginx可以使用certbot –nginx来获取和安装证书。1certbot --nginx certonly 1234567891011121314151617181920212223Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator nginx, Installer nginxEnter email address (used for urgent renewal and security notices) (Enter &apos;c&apos; tocancel): 278202253@qq.com- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Please read the Terms of Service athttps://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You mustagree in order to register with the ACME server athttps://acme-v02.api.letsencrypt.org/directory- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(A)gree/(C)ancel: A- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Would you be willing to share your email address with the Electronic FrontierFoundation, a founding partner of the Let&apos;s Encrypt project and the non-profitorganization that develops Certbot? We&apos;d like to send you email about our workencrypting the web, EFF news, campaigns, and ways to support digital freedom.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: nWhich names would you like to activate HTTPS for?选择你需要证书的站点 自己编译安装的nginx 需要增加软连接报错1The error was: NoInstallationError(&quot;Could not find a usable &apos;nginx&apos; binary. Ensure nginx exists, the binary is executable, and your PATH is set correctly.&quot;,) 解决1ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx 报错1nginx: [emerg] open() &quot;/etc/nginx/nginx.conf&quot; failed (2: No such file or directory) 解决1ln -s /usr/local/nginx/conf /etc/nginx 报错123456789101112131415161718192021222324252627certbot --nginx certonlyTraceback (most recent call last): File &quot;/usr/bin/certbot&quot;, line 9, in &lt;module&gt; load_entry_point(&apos;certbot==0.24.0&apos;, &apos;console_scripts&apos;, &apos;certbot&apos;)() File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 378, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 2566, in load_entry_point return ep.load() File &quot;/usr/lib/python2.7/site-packages/pkg_resources.py&quot;, line 2260, in load entry = __import__(self.module_name, globals(),globals(), [&apos;__name__&apos;]) File &quot;/usr/lib/python2.7/site-packages/certbot/main.py&quot;, line 17, in &lt;module&gt; from certbot import account File &quot;/usr/lib/python2.7/site-packages/certbot/account.py&quot;, line 17, in &lt;module&gt; from acme import messages File &quot;/usr/lib/python2.7/site-packages/acme/messages.py&quot;, line 7, in &lt;module&gt; from acme import challenges File &quot;/usr/lib/python2.7/site-packages/acme/challenges.py&quot;, line 11, in &lt;module&gt; import requests File &quot;/usr/lib/python2.7/site-packages/requests/__init__.py&quot;, line 58, in &lt;module&gt; from . import utils File &quot;/usr/lib/python2.7/site-packages/requests/utils.py&quot;, line 32, in &lt;module&gt; from .exceptions import InvalidURL File &quot;/usr/lib/python2.7/site-packages/requests/exceptions.py&quot;, line 10, in &lt;module&gt; from .packages.urllib3.exceptions import HTTPError as BaseHTTPError File &quot;/usr/lib/python2.7/site-packages/requests/packages/__init__.py&quot;, line 95, in load_module raise ImportError(&quot;No module named &apos;%s&apos;&quot; % (name,))ImportError: No module named &apos;requests.packages.urllib3&apos; 解决1pip2.7 install --upgrade --force-reinstall &apos;requests==2.6.0&apos; urllib3 获取完之后可以通过certbot certificates命令查看证书： root@node01:~# certbot certificates Saving debug log to /var/log/letsencrypt/letsencrypt.log——————————————————————————-Found the following certs: Certificate Name: www.youdomain.com Domains: www.youdomain.com Expiry Date: 2018-09-03 02:08:54+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/www.youdomain.com/fullchain.pem Private Key Path: /etc/letsencrypt/live/www.youdomain.com/privkey.pem 3.5 配置Web Server 不同Web Server的配置方式不同，这里以Nginx为例，在配置文件youdomain.conf中添加：12345678910111213141516server &#123; listen [::]:80; root /var/www/youdomain; index index.html index.htm; server_name www.yourdomain.com; charset utf-8; #................. listen 443 ssl; ssl_certificate /etc/letsencrypt/live/www.yourdomain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.yourdomain.com/privkey.pem; &#125; 需要了解Nginx的使用 配置完之后更新配置即可(nginx -s reload)，到这里证书配置就完成了，正常情况下该域名HTTPS就可以访问了。 3.7 更新证书 由于Let’s Encrypt颁发的证书的有效期只有90天，这就需要更新证书。 Renewing certificateshttps://certbot.eff.org/docs/using.html#renewing-certificates 更新命令1certbot renew 计划任务自动更新12crontab -e15 2 20 */2 * certbot renew 如果使用了nginx plugin，则更新时需要使用certbot renew –quiet –installer node，否则会自动安装证书导致错误。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>https Certbot Let’s Encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-valine]]></title>
    <url>%2Fhexo-valine.html</url>
    <content type="text"><![CDATA[hexo 评论页面报错 Code 403: 访问被api域名白名单拒绝，请检查你的安全域名设置. 关于Valine和LeanCloud Valine是一款基于Leancloud的快速、简洁且高效的无后端评论系统。Valine诞生于2017年8月7日，理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo等博客程序在使用Valine。她完全不需要账号，一个昵称就够了，为了方便以后联系也可以留下邮箱，甚至可以如路人般水一下而不留一点痕迹，给人一种清新脱俗、小家碧玉的感觉，这多少符合现在互联网顶贴水楼的习惯。同时她又支持Gravatar的头像和Markdown的语法，方便大家展现个性化的头像和多变的评论样式。另外Valine还支持文章阅读量统计，next主题也是集成此功能的，如需要请在主题配置文件中搜索“leancloud_visitors”字段启用。具体请网络搜索或查看官方说明 .https://valine.js.org/visitor.html LeanCloud是行业领先的一站式后端云服务提供商，专注于为开发者提供一流的工具、平台和服务。LeanCloud于2013年9月发布，主要提供包括数据存储、文件存储与CDN、消息推送和实时通信在内的后端云服务，同时提供支撑后端代码的云引擎和云函数等开发工具，全面涵盖移动开发的需求；同时也提供了易于集成的全平台SDK，支持iOS、Android应用和游戏开发，以及包括微信小程序在内的web开发。帮助客户脱繁重的后端开发负担，最大限度地降低开发成本、缩短开发周期、加快迭代速度，在激烈的市场竞争中胜出。https://leancloud.cn/ 在snippet主题中启用Valine 本人使用的是Hexo博客系统的snippet（v6.0.5）版本主题，所有操作设置仅对应该系统和主题版本，其他博客系统或主题请参考官方说明。在此提一下next主题现在主要有v5.1.x和v6.x两个版本，其中v5.1.x版本现已停止更新并迁移到新的仓库升级为v6.x，具体请参考官方说明。https://github.com/shenliyang/hexo-theme-snippet 获取APP ID 和 APP Key注册LeanCloud （过程跳过），注册后请到注册邮箱内验证邮箱。登录后点击页面右上角的控制台，进去后点击创建应用，应用名称随便填(如valine)并创建，之后将鼠标移到应用标签上并点击设置按钮 进去后点击设置中的“应用Key”，就可以看到APP ID 和 APP Key了。 配置next主题 请打开next的配置文件_config.yml，搜索valine找到下面的字段，复制上面的APP ID和APP Key分别粘贴到appid和appkey，注意ID和Key是可以复制的，冒号后面空一格再粘贴。将enable: false改为enable: true即可启用Valine评论，其他的选项除非你知道是什么，否则请保持默认设置。如果已开启其他评论，请先关闭。然后执行hexo clean和 hexo s 两个命令进行本地预览，查看是否正常启用。1234567891011## Valine评论valine: enable: true appId: ID appKey: Key placeholder: 说点什么吧 notify: false verify: false avatar: mm meta: nick,mail pageSize: 10 管理评论数据 回到刚才的网页页面，点击“存储”(或者登录&gt;选择你创建的应用&gt;存储)，应该可以看到“Comment”文件，点击就可以查看管理评论数据了。如果没有“Comment”文件，你可以自己评论一条然后刷新管理页面。 关于自带的评论邮件提醒功能请谨慎使用，首先应”登录Leancloud&gt;选择你的评论应用&gt;设置&gt;邮件模板“，然后参照官方说明进行设置并保存。请注意修改链接为你的博客或者网站首页。由于邮件提醒功能使用的Leancloud的密码重置邮件提醒，只能传递昵称、邮箱两个属性，所以邮件提醒链接无法直达指定文章页。发送次数过多，可能会暂时被Leancloud 屏蔽邮件发送功能。https://valine.js.org/notify.html Valine目前使用的是Gravatar作为评论列表头像。请自行登录或注册Gravatar，然后修改自己的头像。评论的时候，留下在Gravatar注册时所使用的邮箱即可。如果你修改了头像后发现没有更新，请不要慌张，因为gravatar.cat.net 有七天的缓存期，安静的等待吧。 当然，你也可以配合使用 panjunwen 开发的 Valine-Admin (https://github.com/panjunwen/Valine-Admin)进行评论数据管理和邮件提醒等。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>hexo valine LeanCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+GitHub]]></title>
    <url>%2Fhexo-GitHub.html</url>
    <content type="text"><![CDATA[1、什么是 Hexo？ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 2、部署2.1 部署环境 centos 7.5 hexo nginx github git cloudflare （cdn + 域名） 2.2 安装Git Windows：下载并安装 git. Mac：使用 Homebrew, MacPorts 1brew install git Linux (Ubuntu, Debian)： 1sudo apt-get install git-core Linux (Fedora, Red Hat,CentOS)： 1sudo yum install git-core 2.3安装 Node.js 安装 Node.js 的最佳方式是使用 nvm。 cURL:1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh Wget:1$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js。1$ nvm install stable 或者您也可以下载 安装程序 来安装。 3、安装hexo 执行以下命令:1$ npm install -g hexo-cli 安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，指定文件夹的目录如下：1234567├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 接下来要做的就是修改配置文件了，在根目录下找到文件：_config.yml 安装自己的需要进行修改，一般修改下网站标题，作者就可以了12345678910111213# Sitetitle: Fenpho //网站标题subtitle: //网站副标题description://网站描述author: fenpho//网站作者language: zh-CN//语言timezone://时区# URLand root as &apos;/child/&apos;url: https://fenpho.github.io/ //网站链接root: / //网站根目录permalink: :year/:month/:day/:title/ //时间格式 具体的修改方法可以参考官网：Hexo 4、本地预览 生成静态文件123$ hexo generate //也可以使用缩写 : $ hexo g 启动服务器默认情况下，访问网址为：http://localhost:4000/。1$ hexo server 运行网上面的命令后，打开浏览器输入http://localhost:4000/即可看到页面了，有木有很激动 5、选取主题hexo链接 接下来你需要做进一步的网站美化工作，到官网去选取一个喜欢的主题吧！我采用了一个叫做TKL的主题： 5.1 下载 确定需要使用的主体之后，打开主题的官网下载安装主题即可： 运行如下命令（去主题的github页面找类似下面的命令）1$ git clone https://github.com/shenliyang/hexo-theme-snippet.git 命令中的后面的hexo-theme-snippet为存储的目录名字，可以随便修改 5.2 更新 更新主题相关文件12cd themes/hexo-theme-snippetgit pull 5.3 使用 修改根目录下的博客配置文件 _config.yml （不是主题下面的配置文件）主题属性 theme 为 hexo-theme-snippet.配置主题，这个需要根据不同主题的说明来配置，也可以不配置好了，主题安装好了，此时需要使用如下命令： 12hexo clean &amp;&amp; hexo ghexo server 完成后刷新页面看一下吧 6、添加文章 创建一条博文，运行下面的命令，或者直接新建一个Markdown文件，新建文件需要手动添加文章头部（注意目录source/_posts）1hexo new &quot;your-post-name&quot; 如果想要在新建的同时生成对应的文件夹，用于存放文档的资源文件，如图片，音视频等：将配置文件中的post_asset_folder的值从false改为true即可1post_asset_folder: true 7、文章分类7.1 categories 在根目录下scaffolds/post.md中，添加一行categories:（同理可应用在page.md和photo.md）123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;categories: &apos;工具&apos;top：100--- 7.2 tags 在文章的开头配置1234567891011---layout: posttitle: 标题date: 2017-05-26 09:00author: &quot;zj&quot;categories: &apos;工具&apos; - 目录名字 tags: - 标签1 - 标签2--- 7.3 归档展示样式 配置博客首页归档展示样式。修改主题的配置文件themes目录下对应的主题下面的_config.yml中:123456&gt; # 博客首页展示文本/访问路径/自定义归档名称menu: home: / essay: /categories/随笔 write: /categories/写作 about: /about 8、添加文章置顶功能 原理：在Hexo生成首页HTML时，将top值高的文章排在前面，达到置顶功能。修改Hexo文件夹下的node_modules/hexo-generator-index/lib/generator.js，在生成文章之前进行文章top值排序。以下是最终的generator.js12345678910111213141516171819202122232425262728&apos;use strict&apos;;var pagination = require(&apos;hexo-pagination&apos;);module.exports = function(locals)&#123; var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; if(a.top == b.top) return b.date - a.date; else return b.top - a.top; &#125; else if(a.top &amp;&amp; !b.top) &#123; return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; &#125;); var paginationDir = config.pagination_dir || &apos;page&apos;; return pagination(&apos;&apos;, posts, &#123; perPage: config.index_generator.per_page, layout: [&apos;index&apos;, &apos;archive&apos;], format: paginationDir + &apos;/%d/&apos;, data: &#123; __index: true &#125; &#125;);&#125;; 9、部署到GitHub9.1 在 GitHub 上的操作 新建一个 Repository在 Repository name 下填写 yourname.github.io,Description (optional) 下填写一些简单的描述（不写也没有关系），如图所示： 创建成功之后，进入仓库的设置（点击setting）界面如下图所示： 找到pages选项，选择master branch作为主页 简单两步 yourname.github.io 这个域名就配置成功了。 创建key服务器上生成key123ssh-keygen -t rsa -C &quot;xxx@qq.com&quot;cat /root/.ssh/id_rsa.pub 把上面cat 的key 添加 github 位置 settings deploy-keys注意上传的权限要给 测试1ssh -T git@github.com Ok1Hi xxxx! You ve successfully authenticated, but GitHub does not provide shell access. 9.2、本地操作 为 Hexo 安装 Git 插件安装 hexo-deployer-git，否则会报 ERROR Deployer not found: git 的错误。1npm install hexo-deployer-git --save 修改你的 _config.yml 配置文件，在结尾处加上如下内容：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:fenpho/fenpho.github.io.git branch: master 注意repo中的地址为你自己新建的仓库的路径 生成静态文件和部署：1hexo g &amp; d 最后出现如下提示就代表成功啦！1INFO Deploy done: git]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>hexo GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Charles]]></title>
    <url>%2FCharles.html</url>
    <content type="text"><![CDATA[charles是用java写的, 跨平台支持的很好, macOS下使用很方便. 安装方式官方4.1.2版本破解:charles.jar文件 破解方式 先把官方的4.1.2版本安装好以后 替换/Applications/Charles.app/Contents/Java/charles.jar 完成破解. iOS设备的抓包 1 在 Mac 中打开 Charles 应用. 2 设置手机HTTP代理: 确保iOS设备与Mac设备在同一局域网内, 添加代理ip地址(Mac内网ip)和端口号(8888),这里以iPhone为例 3 在iOS设备上访问接口数据, 在Charles弹出的确认窗(mac设备屏幕上)中选择Allow, 允许即可 https 抓包 1 如果要抓https的包, 还需要在iOS设备(手机端，需要抓包的程序端) 上多做一步, 用iOS设备的Safari浏览器访问: http://www.charlesproxy.com/getssl 浏览器会下载SSL证书并提示安装.2 安装后在Charles中选择需要代理地址, 右击, 选中 Enable SSL Proxying，这样就可以抓取 HTTPS 数据包了. 安卓设备的抓包 类似的设置 引用charles的破解方法]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>charles</tag>
      </tags>
  </entry>
</search>
